% Encoding: UTF-8

@Article{roediger2015r,
  author  = {Stefan R{\"o}diger and Micha{\l} Burdukiewicz and Konstantin A. Blagodatskikh and Peter Schierack},
  journal = {The R Journal},
  title   = {{R as an {Environment} for the {Reproducible} {Analysis} of {DNA} {Amplification} {Experiments}}},
  year    = {2015},
  number  = {2},
  pages   = {127--150},
  volume  = {7},
  url     = {http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf},
}

@Article{liaw_classification_2002,
  author  = {Andy Liaw and Matthew Wiener},
  journal = {R News},
  title   = {{Classification and {Regression} by {randomForest}}},
  year    = {2002},
  number  = {3},
  pages   = {18--22},
  volume  = {2},
  url     = {http://CRAN.R-project.org/doc/Rnews/},
}

@Article{breiman_random_2001,
  author  = {Leo Breiman},
  journal = {Machine learning},
  title   = {{Random forests}},
  year    = {2001},
  number  = {1},
  pages   = {5--32},
  volume  = {45},
}

@Book{noauthor_compstat_2008,
  editor     = {Paula Brito},
  publisher  = {Physica-Verlag Heidelberg},
  title      = {{{COMPSTAT} 2008: {Proceedings} in {Computational} {Statistics}}},
  year       = {2008},
  isbn       = {978-3-7908-2083-6},
  abstract   = {COMPSTAT 2008...},
  editor     = {Paula Brito},
  file       = {Snapshot:/home/tux/Work/Literatur/Zotero_DB/zotero/storage/FYA8ZYXJ/noauthor_compstat_2008 - COMPSTAT 2008_ Proceedings in Computational Statistics.html:text/html},
  language   = {en},
  localfile  = {//www.springer.com/us/book/9783790820836},
  shorttitle = {{COMPSTAT} 2008},
  urldate    = {2018-03-03},
}

@Article{pabinger_2014,
  author   = {Stephan Pabinger and Stefan R{\"o}diger and Albert Kriegner and Klemens Vierlinger and Andreas Weinh{\"a}usel},
  journal  = {Biomolecular Detection and Quantification},
  title    = {{A survey of tools for the analysis of quantitative {PCR} ({qPCR}) data}},
  year     = {2014},
  issn     = {2214-7535},
  month    = sep,
  note     = {00003},
  number   = {1},
  pages    = {23--33},
  volume   = {1},
  abstract = {Real-time quantitative polymerase-chain-reaction (qPCR) is a standard technique in most laboratories used for various applications in basic research. Analysis of qPCR data is a crucial part of the entire experiment, which has led to the development of a plethora of methods. The released tools either cover specific parts of the workflow or provide complete analysis solutions. Here, we surveyed 27 open-access software packages and tools for the analysis of qPCR data. The survey includes 8 Microsoft Windows, 5 web-based, 9 R-based and 5 tools from other platforms. Reviewed packages and tools support the analysis of different qPCR applications, such as RNA quantification, DNA methylation, genotyping, identification of copy number variations, and digital PCR. We report an overview of the functionality, features and specific requirements of the individual software tools, such as data exchange formats, availability of a graphical user interface, included procedures for graphical data presentation, and offered statistical methods. In addition, we provide an overview about quantification strategies, and report various applications of qPCR. Our comprehensive survey showed that most tools use their own file format and only a fraction of the currently existing tools support the standardized data exchange format RDML. To allow a more streamlined and comparable analysis of qPCR data, more vendors and tools need to adapt the standardized format to encourage the exchange of data between instrument software, analysis tools, and researchers.},
  doi      = {10.1016/j.bdq.2014.08.002},
  keywords = {Data analysis; MIQE; qPCR; RDML; Software; Tools},
  url      = {http://www.sciencedirect.com/science/article/pii/S2214753514000059},
  urldate  = {2015-04-02},
}

@Article{roediger_rkward_2012,
  author     = {Stefan R{\"o}diger and Thomas Friedrichsmeier and Prasenjit Kapat and Meik Michalke},
  journal    = {Journal of Statistical Software},
  title      = {{{RKWard}: a comprehensive graphical user interface and integrated development environment for statistical analysis with {R}}},
  year       = {2012},
  number     = {9},
  pages      = {1--34},
  volume     = {49},
  abstract   = {R is a free open-source implementation of the S statistical computing language and programming environment. The current status of R is a command line driven interface with no advanced cross-platform graphical user interface (GUI), but it includes tools for building such. Over the past years, proprietary and non-proprietary GUI solutions have emerged, based on internal or external tool kits, with different scopes and technological concepts. For example, Rgui.exe and Rgui.app have become the de facto GUI on the Microsoft Windows and Mac OS X platforms, respectively, for most users. In this paper we discuss RKWard which aims to be both a comprehensive GUI and an integrated development environment for R. RKWard is based on the KDE software libraries. Statistical procedures and plots are implemented using an extendable plugin architecture based on ECMAScript (JavaScript), R, and XML. RKWard provides an excellent tool to manage different types of data objects; even allowing for seamless editing of certain types. The objective of RKWard is to provide a portable and extensible R interface for both basic and advanced statistical and graphical analysis, while not compromising on flexibility and modularity of the R programming environment itself.},
  shorttitle = {{RKWard}},
  url        = {https://www.jstatsoft.org/article/view/v049i09/v49i09.pdf},
}

@Article{spiess_impact_2015,
  author   = {Andrej-Nikolai Spiess and Claudia Deutschmann and Micha{\l} Burdukiewicz and Ralf Himmelreich and Katharina Klat and Peter Schierack and Stefan R{\"o}diger},
  journal  = {Clinical Chemistry},
  title    = {{Impact of {Smoothing} on {Parameter} {Estimation} in {Quantitative} {DNA} {Amplification} {Experiments}}},
  year     = {2015},
  issn     = {0009-9147, 1530-8561},
  month    = feb,
  number   = {2},
  pages    = {379--388},
  volume   = {61},
  abstract = {BACKGROUND: Quantification cycle (Cq) and amplification efficiency (AE) are parameters mathematically extracted from raw data to characterize quantitative PCR (qPCR) reactions and quantify the copy number in a sample. Little attention has been paid to the effects of preprocessing and the use of smoothing or filtering approaches to compensate for noisy data. Existing algorithms largely are taken for granted, and it is unclear which of the various methods is most informative. We investigated the effect of smoothing and filtering algorithms on amplification curve data. METHODS: We obtained published high-replicate qPCR data sets from standard block thermocyclers and other cycler platforms and statistically evaluated the impact of smoothing on Cq and AE. RESULTS: Our results indicate that selected smoothing algorithms affect estimates of Cq and AE considerably. The commonly used moving average filter performed worst in all qPCR scenarios. The Savitzky--Golay smoother, cubic splines, and Whittaker smoother resulted overall in the least bias in our setting and exhibited low sensitivity to differences in qPCR AE, whereas other smoothers, such as running mean, introduced an AE-dependent bias. CONCLUSIONS: The selection of a smoothing algorithm is an important step in developing data analysis pipelines for real-time PCR experiments. We offer guidelines for selection of an appropriate smoothing algorithm in diagnostic qPCR applications. The findings of our study were implemented in the R packages chipPCR and qpcR as a basis for the implementation of an analytical strategy.},
  doi      = {10.1373/clinchem.2014.230656},
  language = {en},
  urldate  = {2016-12-03},
}

@Article{ruijter_amplification_2009,
  author     = {J M Ruijter and C Ramakers and W M H Hoogaars and Y Karlen and O Bakker and M J B van den Hoff and A F M Moorman},
  journal    = {Nucleic Acids Research},
  title      = {{Amplification efficiency: linking baseline and bias in the analysis of quantitative {PCR} data}},
  year       = {2009},
  issn       = {1362-4962},
  month      = apr,
  number     = {6},
  pages      = {e45},
  volume     = {37},
  abstract   = {Despite the central role of quantitative PCR (qPCR) in the quantification of mRNA transcripts, most analyses of qPCR data are still delegated to the software that comes with the qPCR apparatus. This is especially true for the handling of the fluorescence baseline. This article shows that baseline estimation errors are directly reflected in the observed PCR efficiency values and are thus propagated exponentially in the estimated starting concentrations as well as 'fold-difference' results. Because of the unknown origin and kinetics of the baseline fluorescence, the fluorescence values monitored in the initial cycles of the PCR reaction cannot be used to estimate a useful baseline value. An algorithm that estimates the baseline by reconstructing the log-linear phase downward from the early plateau phase of the PCR reaction was developed and shown to lead to very reproducible PCR efficiency values. PCR efficiency values were determined per sample by fitting a regression line to a subset of data points in the log-linear phase. The variability, as well as the bias, in qPCR results was significantly reduced when the mean of these PCR efficiencies per amplicon was used in the calculation of an estimate of the starting concentration per sample.},
  doi        = {10.1093/nar/gkp045},
  keywords   = {Algorithms; Animals; Chick Embryo; Fluorescence; Linear Models; Reverse Transcriptase Polymerase Chain Reaction},
  language   = {eng},
  pmcid      = {PMC2665230},
  pmid       = {19237396},
  shorttitle = {Amplification efficiency},
}

@Article{lefever_rdml_2009,
  author     = {Steve Lefever and Jan Hellemans and Filip Pattyn and Daniel R. Przybylski and Chris Taylor and Ren{\'e} Geurts and Andreas Untergasser and Jo Vandesompele and RDML on behalf of the Consortium},
  journal    = {Nucleic Acids Research},
  title      = {{{RDML}: structured language and reporting guidelines for real-time quantitative {PCR} data}},
  year       = {2009},
  issn       = {0305-1048, 1362-4962},
  month      = apr,
  note       = {00097},
  number     = {7},
  pages      = {2065--2069},
  volume     = {37},
  abstract   = {The XML-based Real-Time PCR Data Markup Language (RDML) has been developed by the RDML consortium (http://www.rdml.org) to enable straightforward exchange of qPCR data and related information between qPCR instruments and third party data analysis software, between colleagues and collaborators and between experimenters and journals or public repositories. We here also propose data related guidelines as a subset of the Minimum Information for Publication of Quantitative Real-Time PCR Experiments (MIQE) to guarantee inclusion of key data information when reporting experimental results.},
  doi        = {10.1093/nar/gkp056},
  language   = {en},
  pmid       = {19223324},
  shorttitle = {{RDML}},
  url        = {http://nar.oxfordjournals.org/content/37/7/2065},
  urldate    = {2015-04-01},
}

@Article{ruijter_rdml-ninja_2015,
  author   = {Jan M. Ruijter and Steve Lefever and Jasper Anckaert and Jan Hellemans and Michael W. Pfaffl and Vladimir Benes and Stephen A. Bustin and Jo Vandesompele and Andreas Untergasser and RDML on behalf of the Consortium},
  journal  = {BMC Bioinformatics},
  title    = {{{RDML}-{Ninja} and {RDMLdb} for standardized exchange of {qPCR} data}},
  year     = {2015},
  issn     = {1471-2105},
  month    = dec,
  number   = {1},
  pages    = {197},
  volume   = {16},
  abstract = {BackgroundThe universal qPCR data exchange file format RDML is today well accepted by the scientific community, part of the MIQE guidelines and implemented in many qPCR instruments. With the increased use of RDML new challenges emerge. The flexibility of the RDML format resulted in some implementations that did not meet the expectations of the consortium in the level of support or the use of elements.ResultsIn the current RDML version 1.2 the description of the elements was sharpened. The open source editor RDML-Ninja was released (http://sourceforge.net/projects/qpcr-ninja/). RDML-Ninja allows to visualize, edit and validate RDML files and thus clarifies the use of RDML elements. Furthermore RDML-Ninja serves as reference implementation for RDML and enables migration between RDML versions independent of the instrument software. The database RDMLdb will serve as an online repository for RDML files and facilitate the exchange of RDML data (http://www.rdmldb.org). Authors can upload their RDML files and reference them in publications by the unique identifier provided by RDMLdb. The MIQE guidelines propose a rich set of information required to document each qPCR run. RDML provides the vehicle to store and maintain this information and current development aims at further integration of MIQE requirements into the RDML format.ConclusionsThe editor RDML-Ninja and the database RDMLdb enable scientists to evaluate and exchange qPCR data in the instrument-independent RDML format. We are confident that this infrastructure will build the foundation for standardized qPCR data exchange among scientists, research groups, and during publication.},
  doi      = {10.1186/s12859-015-0637-6},
  language = {en},
  urldate  = {2017-09-04},
}

@Article{pabinger_qpcr:_2009,
  author     = {Stephan Pabinger and Gerhard G. Thallinger and Ren{\'e} Snajder and Heiko Eichhorn and Robert Rader and Zlatko Trajanoski},
  journal    = {BMC Bioinformatics},
  title      = {{{QPCR}: {Application} for real-time {PCR} data management and analysis}},
  year       = {2009},
  issn       = {1471-2105},
  month      = aug,
  number     = {1},
  pages      = {268},
  volume     = {10},
  abstract   = {Since its introduction quantitative real-time polymerase chain reaction (qPCR) has become the standard method for quantification of gene expression. Its high sensitivity, large dynamic range, and accuracy led to the development of numerous applications with an increasing number of samples to be analyzed. Data analysis consists of a number of steps, which have to be carried out in several different applications. Currently, no single tool is available which incorporates storage, management, and multiple methods covering the complete analysis pipeline. PMID: 19712446},
  copyright  = {2009 Pabinger et al; licensee BioMed Central Ltd.},
  doi        = {10.1186/1471-2105-10-268},
  language   = {en},
  pmid       = {19712446},
  shorttitle = {{QPCR}},
  url        = {http://www.biomedcentral.com/1471-2105/10/268/abstract},
  urldate    = {2014-07-01},
}

@Article{neve_unifiedwmwqpcr:_2014,
  author     = {Jan De Neve and Joris Meys and Jean-Pierre Ottoy and Lieven Clement and Olivier Thas},
  journal    = {Bioinformatics},
  title      = {{{unifiedWMWqPCR}: the unified {Wilcoxon}--{Mann}--{Whitney} test for analyzing {RT}-{qPCR} data in {R}}},
  year       = {2014},
  issn       = {1367-4803, 1460-2059},
  month      = sep,
  number     = {17},
  pages      = {2494--2495},
  volume     = {30},
  abstract   = {Motivation: Recently, De Neve et al. proposed a modification of the Wilcoxon--Mann--Whitney (WMW) test for assessing differential expression based on RT-qPCR data. Their test, referred to as the unified WMW (uWMW) test, incorporates a robust and intuitive normalization and quantifies the probability that the expression from one treatment group exceeds the expression from another treatment group. However, no software package for this test was available yet. Results: We have developed a Bioconductor package for analyzing RT-qPCR data with the uWMW test. The package also provides graphical tools for visualizing the effect sizes. Availability and implementation: The unifiedWMWqPCR package and its user documentation can be obtained through Bioconductor. Contact: JanR.DeNeve@UGent.be},
  doi        = {10.1093/bioinformatics/btu313},
  language   = {en},
  pmid       = {24794933},
  shorttitle = {{unifiedWMWqPCR}},
  url        = {http://bioinformatics.oxfordjournals.org/content/30/17/2494},
  urldate    = {2014-09-21},
}

@Article{mccall_non-detects_2014,
  author   = {Matthew N. McCall and Helene R. McMurray and Hartmut Land and Anthony Almudevar},
  journal  = {Bioinformatics},
  title    = {{On non-detects in {qPCR} data}},
  year     = {2014},
  issn     = {1367-4803},
  month    = aug,
  number   = {16},
  pages    = {2310--2316},
  volume   = {30},
  abstract = {Motivation: Quantitative real-time PCR (qPCR) is one of the most widely used methods to measure gene expression. Despite extensive research in qPCR laboratory protocols, normalization and statistical analysis, little attention has been given to qPCR non-detects---those reactions failing to produce a minimum amount of signal., Results: We show that the common methods of handling qPCR non-detects lead to biased inference. Furthermore, we show that non-detects do not represent data missing completely at random and likely represent missing data occurring not at random. We propose a model of the missing data mechanism and develop a method to directly model non-detects as missing data. Finally, we show that our approach results in a sizeable reduction in bias when estimating both absolute and differential gene expression., Availability and implementation: The proposed algorithm is implemented in the R package, nondetects. This package also contains the raw data for the three example datasets used in this manuscript. The package is freely available at http://mnmccall.com/software and as part of the Bioconductor project., Contact: mccallm@gmail.com},
  doi      = {10.1093/bioinformatics/btu239},
  pmcid    = {PMC4133581},
  pmid     = {24764462},
  url      = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4133581/},
  urldate  = {2016-09-28},
}

@Article{ruijter_removal_2015,
  author   = {Jan M. Ruijter and Adri{\'a}n {Ruiz Villalba} and Jan Hellemans and Andreas Untergasser and Maurice J. B. van den Hoff},
  journal  = {Biomolecular Detection and Quantification},
  title    = {{Removal of between-run variation in a multi-plate {qPCR} experiment}},
  year     = {2015},
  issn     = {2214-7535},
  month    = sep,
  pages    = {10--14},
  volume   = {5},
  abstract = {Quantitative PCR (qPCR) is the method of choice in gene expression analysis. However, the number of groups or treatments, target genes and technical replicates quickly exceeds the capacity of a single run on a qPCR machine and the measurements have to be spread over more than 1 plate. Such multi-plate measurements often show similar proportional differences between experimental conditions, but different absolute values, even though the measurements were technically carried out with identical procedures. Removal of this between-plate variation will enhance the power of the statistical analysis on the resulting data. Inclusion and application of calibrator samples, with replicate measurements distributed over the plates, assumes a multiplicative difference between plates. However, random and technical errors in these calibrators will propagate to all samples on the plate. To avoid this effect, the systematic bias between plates can be removed with a correction factor based on all overlapping technical and biological replicates between plates. This approach removes the requirement for all calibrator samples to be measured successfully on every plate. This paper extends an already published factor correction method to the use in multi-plate qPCR experiments. The between-run correction factor is derived from the target quantities which are calculated from the quantification threshold, PCR efficiency and observed Cq value. To enable further statistical analysis in existing qPCR software packages, an efficiency-corrected Cq value is reported, based on the corrected target quantity and a PCR efficiency per target. The latter is calculated as the mean of the PCR efficiencies taking the number of reactions per amplicon per plate into account. Export to the RDML format completes an RDML-supported analysis pipeline of qPCR data ranging from raw fluorescence data, amplification curve analysis and application of reference genes to statistical analysis.},
  doi      = {10.1016/j.bdq.2015.07.001},
  keywords = {Between-plate correction; Between-run variation; Multi-plate experiment; qPCR; RDML; Software},
  series   = {{Special {Issue}: {Advanced} {Molecular} {Diagnostics} for {Biomarker} {Discovery} -- {Part} {I}}},
  url      = {http://www.sciencedirect.com/science/article/pii/S2214753515300012},
  urldate  = {2016-11-08},
}

@Article{dvinge_htqpcr:_2009,
  author     = {Heidi Dvinge and Paul Bertone},
  journal    = {Bioinformatics},
  title      = {{{HTqPCR}: high-throughput analysis and visualization of quantitative real-time {PCR} data in {R}}},
  year       = {2009},
  issn       = {1367-4803, 1460-2059},
  month      = dec,
  number     = {24},
  pages      = {3325--3326},
  volume     = {25},
  abstract   = {Motivation: Quantitative real-time polymerase chain reaction (qPCR) is routinely used for RNA expression profiling, validation of microarray hybridization data and clinical diagnostic assays. Although numerous statistical tools are available in the public domain for the analysis of microarray experiments, this is not the case for qPCR. Proprietary software is typically provided by instrument manufacturers, but these solutions are not amenable to the tandem analysis of multiple assays. This is problematic when an experiment involves more than a simple comparison between a control and treatment sample, or when many qPCR datasets are to be analyzed in a high-throughput facility. Results: We have developed HTqPCR, a package for the R statistical computing environment, to enable the processing and analysis of qPCR data across multiple conditions and replicates. Availability: HTqPCR and user documentation can be obtained through Bioconductor or at http://www.ebi.ac.uk/bertone/software. Contact: bertone\{at\}ebi.ac.uk},
  doi        = {10.1093/bioinformatics/btp578},
  language   = {en},
  pmid       = {19808880},
  shorttitle = {{HTqPCR}},
  url        = {http://bioinformatics.oxfordjournals.org/content/25/24/3325},
  urldate    = {2017-01-03},
}

@Article{ronde_practical_2017,
  author   = {Maurice W. J. de Ronde and Jan M. Ruijter and David Lanfear and Antoni Bayes-Genis and Maayke G. M. Kok and Esther E. Creemers and Yigal M. Pinto and Sara-Joan Pinto-Sietsma},
  journal  = {RNA},
  title    = {{Practical data handling pipeline improves performance of {qPCR}-based circulating {miRNA} measurements}},
  year     = {2017},
  issn     = {1355-8382, 1469-9001},
  month    = may,
  number   = {5},
  pages    = {811--821},
  volume   = {23},
  abstract = {Since numerous miRNAs have been shown to be present in circulation, these so-called circulating miRNAs have emerged as potential biomarkers for disease. However, results of qPCR studies on circulating miRNA biomarkers vary greatly and many experiments cannot be reproduced. Missing data in qPCR experiments often occur due to off-target amplification, nonanalyzable qPCR curves and discordance between replicates. The low concentration of most miRNAs leads to most, but not all missing data. Therefore, failure to distinguish between missing data due to a low concentration and missing data due to randomly occurring technical errors partly explains the variation within and between otherwise similar studies. Based on qPCR kinetics, an analysis pipeline was developed to distinguish missing data due to technical errors from missing data due to a low concentration of the miRNA-equivalent cDNA in the PCR reaction. Furthermore, this pipeline incorporates a method to statistically decide whether concentrations from replicates are sufficiently concordant, which improves stability of results and avoids unnecessary data loss. By going through the pipeline's steps, the result of each measurement is categorized as ``valid, invalid, or undetectable.'' Together with a set of imputation rules, the pipeline leads to more robust and reproducible data as was confirmed experimentally. Using two validation approaches, in two cohorts totaling 2214 heart failure patients, we showed that this pipeline increases both the accuracy and precision of qPCR measurements. In conclusion, this statistical data handling pipeline improves the performance of qPCR studies on low-expressed targets such as circulating miRNAs.},
  doi      = {10.1261/rna.059063.116},
  keywords = {Data analysis; MicroRNA; qPCR},
  language = {en},
  pmid     = {28202710},
  url      = {http://rnajournal.cshlp.org/content/23/5/811},
  urldate  = {2017-06-14},
}

@Article{mallona_pcrefficiency:_2011,
  author     = {Izaskun Mallona and Julia Weiss and Marcos Egea-Cortines},
  journal    = {BMC Bioinformatics},
  title      = {{{pcrEfficiency}: a {Web} tool for {PCR} amplification efficiency prediction}},
  year       = {2011},
  issn       = {1471-2105},
  pages      = {404},
  volume     = {12},
  abstract   = {Relative calculation of differential gene expression in quantitative PCR reactions requires comparison between amplification experiments that include reference genes and genes under study. Ignoring the differences between their efficiencies may lead to miscalculation of gene expression even with the same starting amount of template. Although there are several tools performing PCR primer design, there is no tool available that predicts PCR efficiency for a given amplicon and primer pair.},
  doi        = {10.1186/1471-2105-12-404},
  shorttitle = {{pcrEfficiency}},
  urldate    = {2016-09-21},
}

@Article{bustin_reproducibility_2014,
  author     = {Stephen A. Bustin},
  journal    = {Biomolecular Detection and Quantification},
  title      = {{The reproducibility of biomedical research: {Sleepers} awake!}},
  year       = {2014},
  issn       = {2214-7535},
  month      = dec,
  pages      = {35--42},
  volume     = {2},
  abstract   = {There is increasing concern about the reliability of biomedical research, with recent articles suggesting that up to 85\% of research funding is wasted. This article argues that an important reason for this is the inappropriate use of molecular techniques, particularly in the field of RNA biomarkers, coupled with a tendency to exaggerate the importance of research findings.},
  doi        = {10.1016/j.bdq.2015.01.002},
  keywords   = {Biomedicine; Cancer; Microarrays; Next generation sequencing; qPCR; Reproducibility},
  shorttitle = {The reproducibility of biomedical research},
  url        = {http://www.sciencedirect.com/science/article/pii/S2214753515000030},
  urldate    = {2016-10-05},
}

@Article{bustin_continuing_2017,
  author   = {Stephen Bustin},
  journal  = {Biomolecular Detection and Quantification},
  title    = {{The continuing problem of poor transparency of reporting and use of inappropriate methods for {RT}-{qPCR}}},
  year     = {2017},
  issn     = {2214-7535},
  month    = jun,
  pages    = {7--9},
  volume   = {12},
  abstract = {Attendance at this year{\rq}s European Calcified Tissue Society{\rq}s (ECTS) Congress reveals that the methods used to obtain qPCR results continue to be significantly flawed and that and their reporting remain inadequate.},
  doi      = {10.1016/j.bdq.2017.05.001},
  keywords = {Bone; Expression profiling; qPCR; Reverse Transcription; RNA},
  url      = {http://www.sciencedirect.com/science/article/pii/S2214753517302000},
  urldate  = {2017-08-11},
}

@Article{wilson_good_2016,
  author   = {Greg Wilson and Jennifer Bryan and Karen Cranston and Justin Kitzes and Lex Nederbragt and Tracy K. Teal},
  journal  = {PLOS Computational Biology},
  title    = {{Good enough practices in scientific computing}},
  year     = {2017},
  issn     = {1553-7358},
  month    = jun,
  number   = {6},
  pages    = {e1005510},
  volume   = {13},
  abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
  doi      = {10.1371/journal.pcbi.1005510},
  keywords = {Reproducibility; Data management; Data processing; Computer software; Control systems; Programming languages; Software tools; Source code},
  url      = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
  urldate  = {2017-12-20},
}

@Article{todorov_object-oriented_2009,
  author   = {Valentin Todorov and Peter Filzmoser},
  journal  = {Journal of Statistical Software},
  title    = {{An {Object}-{Oriented} {Framework} for {Robust} {Multivariate} {Analysis}}},
  year     = {2009},
  issn     = {1548-7660},
  number   = {3},
  volume   = {32},
  language = {en},
  url      = {http://www.jstatsoft.org/v32/i03/},
  urldate  = {2017-09-21},
}

@Article{kuhn_building_2008,
  author   = {Max Kuhn},
  journal  = {Journal of Statistical Software},
  title    = {{Building {Predictive} {Models} in {R} {Using} the caret {Package}}},
  year     = {2008},
  issn     = {1548-7660},
  number   = {5},
  volume   = {28},
  language = {en},
  url      = {http://www.jstatsoft.org/v28/i05/},
  urldate  = {2017-09-30},
}

@Article{spiess_highly_2008,
  author    = {Andrej-Nikolai Spiess and Caroline Feig and Christian Ritz},
  journal   = {BMC Bioinformatics},
  title     = {{Highly accurate sigmoidal fitting of real-time {PCR} data by introducing a parameter for asymmetry}},
  year      = {2008},
  issn      = {1471-2105},
  month     = apr,
  number    = {1},
  pages     = {221},
  volume    = {9},
  abstract  = {Fitting four-parameter sigmoidal models is one of the methods established in the analysis of quantitative real-time PCR (qPCR) data. We had observed that these models are not optimal in the fitting outcome due to the inherent constraint of symmetry around the point of inflection. Thus, we found it necessary to employ a mathematical algorithm that circumvents this problem and which utilizes an additional parameter for accommodating asymmetrical structures in sigmoidal qPCR data. PMID: 18445269},
  copyright = {2008 Spiess et al; licensee BioMed Central Ltd.},
  doi       = {10.1186/1471-2105-9-221},
  language  = {en},
  pmid      = {18445269},
  url       = {http://www.biomedcentral.com/1471-2105/9/221/abstract},
  urldate   = {2014-07-01},
}

@InProceedings{gunay_machine_2016,
  author    = {Melih Gunay and Evgin Goceri and Rajarajeswari Balasubramaniyan},
  booktitle = {{Machine {Learning} and {Applications} ({ICMLA}), 2016 15th {IEEE} {International} {Conference} on Machine Learning and Applications (ICMLA)}},
  title     = {{Machine {Learning} for {Optimum} {CT}-{Prediction} for {qPCR}}},
  year      = {2016},
  pages     = {588--592},
  publisher = {IEEE},
  doi       = {10.1109/ICMLA.2016.0103},
  url       = {http://ieeexplore.ieee.org/abstract/document/7838207/},
  urldate   = {2017-10-03},
}

@Article{sauer_differentiation_2016,
  author   = {Eva Sauer and Ann-Kathrin Reinke and Cornelius Courts},
  journal  = {Forensic Science International: Genetics},
  title    = {{Differentiation of five body fluids from forensic samples by expression analysis of four {microRNAs} using quantitative {PCR}}},
  year     = {2016},
  issn     = {1872-4973},
  month    = may,
  pages    = {89--99},
  volume   = {22},
  doi      = {10.1016/j.fsigen.2016.01.018},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1872497316300187},
  urldate  = {2016-08-16},
}

@Article{martins_dna_2015,
  author   = {C. Martins and G. Lima and Mr. Carvalho and L. Cain{\'e} and Mj. Porto},
  journal  = {Forensic Science International: Genetics Supplement Series},
  title    = {{{DNA} quantification by real-time {PCR} in different forensic samples}},
  year     = {2015},
  issn     = {1875-1768},
  month    = dec,
  pages    = {e545--e546},
  volume   = {5},
  doi      = {10.1016/j.fsigss.2015.09.215},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1875176815301335},
  urldate  = {2016-12-22},
}

@Article{baebler_quantgenius:_2017,
  author     = {{\v S}pela Baebler and Miha Svalina and Marko Petek and Katja Stare and Ana Rotter and Maru{\v s}a Pompe-Novak and Kristina Gruden},
  journal    = {BMC Bioinformatics},
  title      = {{{quantGenius}: implementation of a decision support system for {qPCR}-based gene quantification}},
  year       = {2017},
  issn       = {1471-2105},
  month      = dec,
  number     = {1},
  volume     = {18},
  doi        = {10.1186/s12859-017-1688-7},
  language   = {en},
  shorttitle = {{quantGenius}},
  urldate    = {2017-09-26},
}

@Article{barratt_improving_2002,
  author   = {Kevin Barratt and John F. Mackay},
  journal  = {Journal of Clinical Microbiology},
  title    = {{Improving {Real}-{Time} {PCR} {Genotyping} {Assays} by {Asymmetric} {Amplification}}},
  year     = {2002},
  issn     = {0095-1137, 1098-660X},
  month    = apr,
  number   = {4},
  pages    = {1571--1572},
  volume   = {40},
  doi      = {10.1128/JCM.40.4.1571-1572.2002},
  language = {en},
  pmid     = {11923402},
  url      = {http://jcm.asm.org/content/40/4/1571},
  urldate  = {2017-08-06},
}

@Article{brenner_variation_1997,
  author  = {Hermann Brenner and Olaf Gefeller},
  journal = {Statistics in medicine},
  title   = {{Variation of sensitivity, specificity, likelihood ratios and predictive values with disease prevalence}},
  year    = {1997},
  number  = {9},
  pages   = {981--991},
  volume  = {16},
  url     = {http://www.floppybunny.org/robin/web/virtualclassroom/stats/basics/articles/odds_risks/odds_sensitivity)likelihood_ratios_validity_brenner_1997.pdf},
  urldate = {2017-09-30},
}

@Article{handt_digitale_2015,
  author   = {Gordon Handt and Mario Menschikowski and Werner Lehmann and Peter Schierack and Stefan R{\"o}diger},
  journal  = {BIOspektrum},
  title    = {{Digitale {PCR} in der {Labordiagnostik}}},
  year     = {2015},
  issn     = {0947-0867, 1868-6249},
  month    = sep,
  number   = {5},
  pages    = {507--510},
  volume   = {21},
  doi      = {10.1007/s12268-015-0610-y},
  language = {de},
  urldate  = {2017-06-18},
}

@Article{Ritz2008,
  author     = {Christian Ritz and Andrej-Nikolai Spiess},
  journal    = {Bioinformatics},
  title      = {{{qpcR}: an {R} package for sigmoidal model selection in quantitative real-time polymerase chain reaction analysis}},
  year       = {2008},
  issn       = {1367-4803, 1460-2059},
  month      = jul,
  number     = {13},
  pages      = {1549--1551},
  volume     = {24},
  abstract   = {Summary: The qpcR library is an add-on to the free R statistical environment performing sigmoidal model selection in real-time quantitative polymerase chain reaction (PCR) data analysis. Additionally, the package implements the most commonly used algorithms for real-time PCR data analysis and is capable of extensive statistical comparison for the selection and evaluation of the different models based on several measures of goodness of fit. Availability: www.dr-spiess.de/qpcR.html. Contact: a.spiess@uke.uni-hamburg.de Supplementary Information: Statistical evaluations of the implemented methods can be found at www.dr-spiess.de under {\lq}Supplemental Data{\rq}.},
  doi        = {10.1093/bioinformatics/btn227},
  language   = {en},
  pmid       = {18482995},
  shorttitle = {{qpcR}},
  url        = {http://bioinformatics.oxfordjournals.org/content/24/13/1549},
  urldate    = {2014-04-07},
}

@Article{roediger_enabling_2017,
  author     = {Stefan R{\"o}diger and Micha{\l} Burdukiewicz and Andrej-Nikolai Spiess and Konstantin Blagodatskikh},
  journal    = {Bioinformatics},
  title      = {{Enabling reproducible real-time quantitative {PCR} research: the {RDML} package}},
  year       = {2017},
  month      = aug,
  abstract   = {Motivation: Reproducibility, a cornerstone of research, requires defined data formats, which include the setup and output of experiments. The real-time PCR data markup language (RDML) is a recommended standard of the minimum information for publication of quantitative real-time PCR experiments guidelines. Despite the popularity of the RDML format for analysis of quantitative PCR data, handling of RDML files is not yet widely supported in all PCR curve analysis softwares. Results: This study describes the open-source RDML package for the statistical computing language R. RDML is compatible with RDML versions \leq 1.2 and provides functionality to (i) import RDML data; (ii) extract sample information (e.g. targets and concentration); (iii) transform data to various formats of the R environment; (iv) generate human-readable run summaries; and (v) to create RDML files from user data. In addition, RDML offers a graphical user interface to read, edit and create RDML files.Availability and implementation:https://cran.r-project.org/package=RDML. rdmlEdit server http://shtest.evrogen.net/rdmlEdit/. Documentation: http://kablag.github.io/RDML/.Contact:k.blag@yandex.ruSupplementary information:Supplementary data are available at Bioinformatics online.},
  doi        = {10.1093/bioinformatics/btx528},
  shorttitle = {Enabling reproducible real-time quantitative {PCR} research},
  urldate    = {2017-09-09},
}

@Article{ruijter_evaluation_2013,
  author     = {Jan M. Ruijter and Michael W. Pfaffl and Sheng Zhao and Andrej N. Spiess and Gregory Boggy and Jochen Blom and Robert G. Rutledge and Davide Sisti and Antoon Lievens and Katleen {De Preter} and Stefaan Derveaux and Jan Hellemans and Jo Vandesompele},
  journal    = {Methods},
  title      = {{Evaluation of {qPCR} curve analysis methods for reliable biomarker discovery: {Bias}, resolution, precision, and implications}},
  year       = {2013},
  issn       = {1046-2023},
  month      = jan,
  number     = {1},
  pages      = {32--46},
  volume     = {59},
  doi        = {10.1016/j.ymeth.2012.08.011},
  keywords   = {Benchmark; Bias; Precision; qPCR curve analysis; Resolution; Transcriptional biomarker},
  language   = {en},
  shorttitle = {Evaluation of {qPCR} curve analysis methods for reliable biomarker discovery},
  url        = {http://linkinghub.elsevier.com/retrieve/pii/S1046202312002290},
  urldate    = {2016-10-05},
}

@Article{spiess_system-specific_2016,
  author  = {Andrej-Nikolai Spiess and Stefan R{\"o}diger and Micha{\l} Burdukiewicz and Thomas Volksdorf and Joel Tellinghuisen},
  journal = {Scientific Reports},
  title   = {{System-specific periodicity in quantitative real-time polymerase chain reaction data questions threshold-based quantitation}},
  year    = {2016},
  issn    = {2045-2322},
  month   = dec,
  pages   = {38951},
  volume  = {6},
  doi     = {10.1038/srep38951},
  url     = {http://www.nature.com/articles/srep38951},
  urldate = {2016-12-14},
}

@Manual{pracma,
  title  = {{{pracma}: Practical Numerical Math Functions}},
  author = {Hans Werner Borchers},
  note   = {R package version 2.0.7},
  year   = {2017},
  url    = {https://CRAN.R-project.org/package=pracma},
}

@InProceedings{charpiat_shape_2003,
  author    = {Guillaume Charpiat and Olivier Faugeras and Renaud Keriven},
  booktitle = {{Image {Processing}, 2003. {ICIP} 2003. {Proceedings}. 2003 {International} {Conference} on}},
  title     = {{Shape metrics, warping and statistics}},
  year      = {2003},
  pages     = {II--627},
  publisher = {IEEE},
  volume    = {2},
  url       = {http://ieeexplore.ieee.org/abstract/document/1246758/},
  urldate   = {2017-07-30},
}

@Article{porzelius_easier_2009,
  author  = {Christine Porzelius and Harald Binder Jochen Knaus and Guido Schwarzer},
  journal = {The R Journal},
  title   = {{Easier {Parallel} {Computing} in {R} with snowfall and {sfCluster}}},
  year    = {2009},
  month   = jun,
  number  = {1},
  pages   = {54--59},
  volume  = {1},
  url     = {http://journal.r-project.org/archive/2009-1/RJournal_2009-1_Knaus+et+al.pdf},
}

@Article{schmidberger_2009,
  author  = {Markus Schmidberger and Martin Morgan and Dirk Eddelbuettel and Hao Yu and Luke Tierney and Ulrich Mansmann},
  journal = {Journal of Statistical Software},
  title   = {{State-of-the-art in {Parallel} {Computing} with {R}}},
  year    = {2009},
  number  = {1},
  volume  = {47},
}

@Article{eddelbuettel_cran_2017,
  author     = {Dirk Eddelbuettel},
  title      = {{{CRAN} {Task} {View}: {High}-{Performance} and {Parallel} {Computing} with {R}}},
  year       = {2017},
  month      = sep,
  shorttitle = {{CRAN} {Task} {View}},
  url        = {https://CRAN.R-project.org/view=HighPerformanceComputing},
  urldate    = {2017-11-03},
}

@Article{quinlan_induction_1986,
  author  = {J. Ross Quinlan},
  journal = {Machine learning},
  title   = {{Induction of decision trees}},
  year    = {1986},
  number  = {1},
  pages   = {81--106},
  volume  = {1},
  doi     = {10.1007/BF00116251},
  urldate = {2017-07-25},
}

@Article{luan_signal-detection_2011,
  author   = {Shenghua Luan and Lael J. Schooler and Gerd Gigerenzer},
  journal  = {Psychological Review},
  title    = {{A signal-detection analysis of fast-and-frugal trees.}},
  year     = {2011},
  issn     = {1939-1471, 0033-295X},
  number   = {2},
  pages    = {316--338},
  volume   = {118},
  doi      = {10.1037/a0022684},
  language = {en},
  url      = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0022684},
  urldate  = {2017-11-10},
}

@Article{richards_flexible_1959,
  author   = {F. J. Richards},
  journal  = {Journal of Experimental Botany},
  title    = {{A {Flexible} {Growth} {Function} for {Empirical} {Use}}},
  year     = {1959},
  issn     = {0022-0957},
  month    = jun,
  number   = {2},
  pages    = {290--301},
  volume   = {10},
  abstract = {The application of an extended form of von Bertalanffy's growth function to plant data is considered; the equation has considerable flexibility, but is used only to supply an empirical fit. In order to aid the biological analysis of such growth data as are capable of representation by the function, general rate parameters are deduced which are related in a simple manner to its constants.},
  doi      = {10.1093/jxb/10.2.290},
  url      = {https://academic.oup.com/jxb/article/10/2/290/528209},
  urldate  = {2017-12-30},
}

@Article{lanubile_collaboration_2010,
  author   = {F. Lanubile and C. Ebert and R. Prikladnicki and A. Vizca{\'i}no},
  journal  = {IEEE Software},
  title    = {{Collaboration {Tools} for {Global} {Software} {Engineering}}},
  year     = {2010},
  issn     = {0740-7459},
  month    = mar,
  number   = {2},
  pages    = {52--55},
  volume   = {27},
  abstract = {Software engineering involves people collaborating to develop better software. Collaboration is challenging, especially across time zones and without face-to-face meetings. We therefore use collaboration tools all along the product life cycle to let us work together, stay together, and achieve results together. This article summarizes experiences and trends chosen from recent IEEE International Conference on Global Software Engineering (IGSCE) conferences.},
  doi      = {10.1109/MS.2010.39},
  keywords = {collaboration; collaboration tools; Collaborative software; Collaborative tools; Collaborative work; global software development; global software engineering; groupware; IEEE international conference; International collaboration; Meetings; product life cycle; product life cycle management; software engineering; Software engineering},
}

@Article{knuth_literate_1984,
  author   = {D. E. Knuth},
  journal  = {The Computer Journal},
  title    = {{Literate {Programming}}},
  year     = {1984},
  issn     = {0010-4620, 1460-2067},
  month    = jan,
  number   = {2},
  pages    = {97--111},
  volume   = {27},
  abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
  doi      = {10.1093/comjnl/27.2.97},
  language = {en},
  url      = {http://comjnl.oxfordjournals.org/content/27/2/97},
  urldate  = {2015-10-26},
}

@Article{Killick_2014,
  author  = {Rebecca Killick and Idris A. Eckley},
  journal = {Journal of Statistical Software},
  title   = {{{changepoint}: An {R} Package for Changepoint Analysis}},
  year    = {2014},
  number  = {3},
  pages   = {1--19},
  volume  = {58},
  url     = {http://www.jstatsoft.org/v58/i03/},
}

@Article{erdman_bcp:_2007,
  author     = {Chandra Erdman and John W. Emerson and {others}},
  journal    = {Journal of Statistical Software},
  title      = {{{bcp}: an {R} package for performing a {Bayesian} analysis of change point problems}},
  year       = {2007},
  number     = {3},
  pages      = {1--13},
  volume     = {23},
  shorttitle = {bcp},
  url        = {https://www.jstatsoft.org/article/view/v023i03/v23i03.pdf},
  urldate    = {2017-08-13},
}

@Article{scott_cluster_1974,
  author  = {A. J. Scott and M. Knott},
  journal = {Biometrics},
  title   = {{A {Cluster} {Analysis} {Method} for {Grouping} {Means} in the {Analysis} of {Variance}}},
  year    = {1974},
  issn    = {0006-341X},
  month   = sep,
  number  = {3},
  pages   = {507},
  volume  = {30},
  doi     = {10.2307/2529204},
  url     = {http://www.jstor.org/stable/2529204?origin=crossref},
  urldate = {2017-08-07},
}

@Article{Baaaath_2012,
  author  = {Rasmus B{\aa}{\aa}th},
  journal = {{The R Journal}},
  title   = {{The State of Naming Conventions in {R}}},
  year    = {2012},
  month   = dec,
  number  = {2},
  pages   = {74--75},
  volume  = {4},
  url     = {http://journal.r-project.org/archive/2012-2/RJournal_2012-2_Baaaath.pdf},
}

@Manual{Chang_R6,
  title  = {{R6: Classes with Reference Semantics}},
  author = {Winston Chang},
  note   = {R package version 2.1.0},
  year   = {2015},
  url    = {http://CRAN.R-project.org/package=R6},
}

@Manual{FFTrees_package,
  title  = {{FFTrees: Generate, Visualise, and Evaluate Fast-and-Frugal Decision Trees}},
  author = {Nathaniel Phillips and Hansjoerg Neth and Jan Woike and Wolfgang Gaissmaer},
  note   = {R package version 1.3.5},
  year   = {2017},
  url    = {https://CRAN.R-project.org/package=FFTrees},
}

@Article{Febrero_Bande_2012,
  author     = {Manuel Febrero-Bande and Manuel {Oviedo de la Fuente}},
  journal    = {Journal of Statistical Software},
  title      = {{Statistical Computing in Functional Data Analysis: {The} {R} Package {fda.usc}}},
  year       = {2012},
  number     = {4},
  pages      = {1--28},
  volume     = {51},
  shorttitle = {Statistical computing in functional data analysis},
  url        = {http://www.jstatsoft.org/v51/i04/},
}

@Article{Fischer_HDF5,
  author  = {Bernd Fischer and Gregoire Pau},
  journal = {R package version 2.10.0},
  title   = {{{rhdf5}: {HDF5} interface to {R}}},
  year    = {2015},
  url     = {http://www.bioconductor.org/packages/release/bioc/html/rhdf5.html},
}

@Article{Horsman2007,
  author     = {Katie M. Horsman and Joan M. Bienvenue and Kiev R. Blasier and James P. Landers},
  journal    = {Journal of Forensic Sciences},
  title      = {{Forensic {DNA} {Analysis} on {Microfluidic} {Devices}: {A} {Review}}},
  year       = {2007},
  issn       = {0022-1198, 1556-4029},
  month      = jul,
  number     = {4},
  pages      = {784--799},
  volume     = {52},
  doi        = {10.1111/j.1556-4029.2007.00468.x},
  language   = {en},
  shorttitle = {Forensic {DNA} {Analysis} on {Microfluidic} {Devices}},
  urldate    = {2016-09-10},
}

@Manual{Lang_XML,
  title  = {{{XML}: Tools for Parsing and Generating {XML} Within {R} and {S-Plus}}},
  author = {Duncan Temple Lang and CRAN the Team},
  note   = {R package version 3.98-1.3},
  year   = {2015},
  url    = {http://CRAN.R-project.org/package=XML},
}

@Article{Leeper_2014,
  author  = {Thomas J. Leeper},
  journal = {The R Journal},
  title   = {{Archiving Reproducible Research and Dataverse with {R}}},
  year    = {2014},
  number  = {1},
  pages   = {151--158},
  volume  = {6},
  url     = {http://journal.r-project.org/archive/2014-1/leeper.pdf},
}

@Manual{Mersmann_2014_microbenchmark,
  title  = {{{microbenchmark}: Accurate Timing Functions}},
  author = {Mersmann Olaf and Beleites Claudia and Hurling Rainer and Friedman Ari},
  note   = {R package version 1.4-2},
  year   = {2014},
  url    = {http://CRAN.R-project.org/package=microbenchmark},
}

@Manual{RDCT2010c,
  title        = {{{R} Data {Import/Export}}},
  address      = {Vienna, Austria},
  author       = {{{R} Development Core Team}},
  note         = {{ISBN} 3-900051-10-0},
  organization = {{R} Foundation for Statistical Computing},
  year         = {2012},
  url          = {http://www.R-project.org/},
}

@Manual{R_language,
  title        = {{R: A Language and Environment for Statistical Computing}},
  address      = {Vienna, Austria},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  year         = {2017},
  url          = {https://www.R-project.org/},
}

@Manual{Radford_2014_microbenchmark,
  title  = {{Inaccurate results from microbenchmark}},
  author = {Neal Radford},
  note   = {https://web.archive.org/web/20140823221902/http://www.r-bloggers.com/inaccurate-results-from-microbenchmark/},
  year   = {2014},
  url    = {https://web.archive.org/web/20140823221902/http://www.r-bloggers.com/inaccurate-results-from-microbenchmark/},
}

@Manual{Ren_rlist,
  title  = {{{rlist}: A Toolbox for Non-Tabular Data Manipulation}},
  author = {Kun Ren},
  note   = {R package version 0.4.2.3},
  year   = {2015},
  url    = {http://CRAN.R-project.org/package=rlist},
}

@Manual{Schutten_2014_ods,
  title  = {{{readODS}: Read {ODS} files and puts them into data frames}},
  author = {Gerrit-Jan Schutten},
  note   = {R package version 1.4},
  year   = {2014},
  url    = {http://CRAN.R-project.org/package=readODS},
}

@Article{Tierney2017,
  author    = {Nicholas Tierney},
  journal   = {{The Journal of Open Source Software}},
  title     = {{{visdat}: Visualising Whole Data Frames}},
  year      = {2017},
  month     = aug,
  number    = {16},
  volume    = {2},
  publisher = {The Open Journal},
}

@Article{Valero_2012,
  author    = {Pedro M. Valero-Mora and Ruben Ledesma},
  journal   = {Journal of Statistical Software},
  title     = {{Graphical User Interfaces for {R}}},
  year      = {2012},
  issn      = {1548-7660},
  number    = {1},
  pages     = {1--8},
  volume    = {49},
  accepted  = {2012-06-03},
  bibdate   = {2012-06-03},
  coden     = {JSSOBK},
  day       = {30},
  submitted = {2012-06-03},
  url       = {http://www.jstatsoft.org/v49/i01},
}

@Manual{Warnes_2015_gdata,
  title  = {{{gdata}: Various {R} Programming Tools for Data Manipulation}},
  author = {Gregory R. Warnes and Ben Bolker and Gregor Gorjanc and Gabor Grothendieck and Ales Korosec and Thomas Lumley and Don MacQueen and Arni Magnusson and Jim Rogers and {others}},
  note   = {R package version 2.17.0},
  year   = {2015},
  url    = {http://CRAN.R-project.org/package=gdata},
}

@Manual{Wickham_Francois_dplyr,
  title  = {{{dplyr}: A Grammar of Data Manipulation}},
  author = {Hadley Wickham and Romain Francois},
  note   = {R package version 0.4.2},
  year   = {2015},
  url    = {http://CRAN.R-project.org/package=dplyr},
}

@Manual{Wickham_assertthat,
  title  = {{{assertthat}: Easy pre and post assertions.}},
  author = {Hadley Wickham},
  note   = {R package version 0.1},
  year   = {2013},
  url    = {http://CRAN.R-project.org/package=assertthat},
}

@Article{Wickham_plyr,
  author  = {Hadley Wickham},
  journal = {Journal of Statistical Software},
  title   = {{The Split-Apply-Combine Strategy for Data Analysis}},
  year    = {2011},
  number  = {1},
  pages   = {1--29},
  volume  = {40},
  url     = {http://www.jstatsoft.org/v40/i01/},
}

@Manual{Wickham_tidyr,
  title  = {{{tidyr}: Easily Tidy Data with spread() and gather() Functions.}},
  author = {Hadley Wickham},
  note   = {R package version 0.2.0},
  year   = {2014},
  url    = {http://CRAN.R-project.org/package=tidyr},
}

@Article{achard_xml_2001,
  author   = {Fr{\'e}d{\'e}ric Achard and Guy Vaysseix and Emmanuel Barillot},
  journal  = {{Bioinformatics}},
  title    = {{{XML}, bioinformatics and data integration}},
  year     = {2001},
  issn     = {1367-4803, 1460-2059},
  number   = {2},
  pages    = {115--125},
  volume   = {17},
  doi      = {10.1093/bioinformatics/17.2.115},
  language = {en},
  pmid     = {11238067},
  url      = {http://bioinformatics.oxfordjournals.org/content/17/2/115},
}

@Article{alonso_real-time_2007,
    author  = {Antonio Alonso and Oscar Garc{\'i}a},
  journal = {Molecular Forensics},
  title   = {{Real-time quantitative {PCR} in forensic science}},
  year    = {2007},
  pages   = {59},
  urldate = {2016-12-20},
}

@Article{andreasson_sensitive_2005,
  author     = {Hanna Andr{\'e}asson},
  title      = {{Sensitive {Forensic} {DNA} {Analysis} : {Application} of {Pyrosequencing} and {Real}-time {PCR} {Quantification}}},
  year       = {2005},
  abstract   = {The field of forensic genetics is growing fast and the development and optimisation of more sensitive, faster and more discriminating forensic DNA analysis methods is highly important. In this thes ...},
  language   = {eng},
  shorttitle = {Sensitive {Forensic} {DNA} {Analysis}},
  url        = {http://uu.diva-portal.org/smash/record.jsf?pid=diva2:166330},
  urldate    = {2016-12-16},
}

@Article{arlot_survey_2010,
  author   = {Sylvain Arlot and Alain Celisse},
  journal  = {Statistics Surveys},
  title    = {{A survey of cross-validation procedures for model selection}},
  year     = {2010},
  issn     = {1935-7516},
  note     = {Mathematical Reviews number (MathSciNet) MR2602303, Zentralblatt MATH identifier1190.62080},
  pages    = {40--79},
  volume   = {4},
  abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
  doi      = {10.1214/09-SS054},
  keywords = {cross-validation; leave-one-out; Model selection},
  language = {EN},
  url      = {http://projecteuclid.org/euclid.ssu/1268143839},
  urldate  = {2014-04-23},
}

@Article{athamanolap_trainable_2014,
  author   = {Pornpat Athamanolap and Vishwa Parekh and Stephanie I. Fraley and Vatsal Agarwal and Dong J. Shin and Michael A. Jacobs and Tza-Huei Wang and Samuel Yang},
  journal  = {PLoS ONE},
  title    = {{Trainable {High} {Resolution} {Melt} {Curve} {Machine} {Learning} {Classifier} for {Large}-{Scale} {Reliable} {Genotyping} of {Sequence} {Variants}}},
  year     = {2014},
  issn     = {1932-6203},
  month    = oct,
  number   = {10},
  pages    = {e109094},
  volume   = {9},
  doi      = {10.1371/journal.pone.0109094},
  editor   = {John Z. Metcalfe},
  language = {en},
  urldate  = {2017-06-24},
}

@Article{baker_quantitative_2012,
  author     = {Monya Baker},
  journal    = {Nature Methods},
  title      = {{Quantitative data: learning to share}},
  year       = {2012},
  issn       = {1548-7091},
  number     = {1},
  pages      = {39--41},
  volume     = {9},
  abstract   = {Adaptive technologies are helping researchers combine and organize experimental results.},
  copyright  = {{\copyright} 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  doi        = {10.1038/nmeth.1815},
  shorttitle = {Quantitative data},
  url        = {http://www.nature.com/nmeth/journal/v9/n1/full/nmeth.1815.html},
  urldate    = {2015-08-08},
}

@Article{barber_utility_2006,
  author   = {Amy L. Barber and David R. Foran},
  journal  = {Journal of Forensic Sciences},
  title    = {{The {Utility} of {Whole} {Genome} {Amplification} for {Typing} {Compromised} {Forensic} {Samples}}},
  year     = {2006},
  issn     = {1556-4029},
  month    = nov,
  number   = {6},
  pages    = {1344--1349},
  volume   = {51},
  abstract = {ABSTRACT: Biological evidence has become invaluable in the crime laboratory; however, it may exist in limited quantity and/or quality. Given this, the ability to amplify total DNA obtained from evidence, in an unbiased manner, would be highly advantageous. Methods for whole genome amplification (WGA) have the potential to fulfill this role, resulting in a virtually unlimited supply of DNA. In the research presented, two WGA methods, improved primer extension preamplification and multiple displacement amplification (MDA), were tested using commercial kits. Control DNA, artificially degraded DNA, and DNA from fresh blood, aged blood, hair shafts, and aged bones underwent WGA, followed by short tandem repeat and mitochondrial DNA analysis. The methods did amplify DNA, but performed poorly on forensically relevant samples; the maximum amplicon size was reduced, and MDA often resulted in extraneous bands following polymerase chain reaction. Taken together, WGA appears to be of limited forensic utility unless the samples are of a very high quality.},
  doi      = {10.1111/j.1556-4029.2006.00262.x},
  keywords = {Degraded DNA; DNA typing; forensic science; improved primer extension preamplification; mitochondrial DNA; multiple displacement amplification; short tandem repeat},
  language = {en},
  urldate  = {2016-12-03},
}

@Article{beer_bestimmung_1852,
  author   = {{Beer}},
  journal  = {Annalen der Physik},
  title    = {{Bestimmung der {Absorption} des rothen {Lichts} in farbigen {Fl{\"u}ssigkeiten}}},
  year     = {1852},
  issn     = {1521-3889},
  month    = jan,
  number   = {5},
  pages    = {78--88},
  volume   = {162},
  doi      = {10.1002/andp.18521620505},
  language = {en},
  urldate  = {2017-12-22},
}

@Article{berg_dna_2002,
  author   = {Jeremy M. Berg and John L. Tymoczko and Lubert Stryer},
  title    = {{{DNA}, {RNA}, and the {Flow} of {Genetic} {Information}}},
  year     = {2002},
  abstract = {Genes must be expressed to exert an effect, and proteins regulate such expression. One such regulatory protein, a zinc-finger protein (zinc ion is blue, protein is red), is shown bound to a control or promoter region of DNA (black). [Barnaby Hall/Photonica.]},
  language = {en},
  url      = {https://www.ncbi.nlm.nih.gov/books/NBK21171/},
  urldate  = {2017-12-22},
}

@Article{bianchi_forensic_2007,
  author   = {Lucia Bianchi and Pietro Li{\`o}},
  journal  = {Briefings in Bioinformatics},
  title    = {{Forensic {DNA} and bioinformatics}},
  year     = {2007},
  issn     = {1467-5463, 1477-4054},
  month    = mar,
  number   = {2},
  pages    = {117--128},
  volume   = {8},
  abstract = {The field of forensic science is increasingly based on biomolecular data and many European countries are establishing forensic databases to store DNA profiles of crime scenes of known offenders and apply DNA testing. The field is boosted by statistical and technological advances such as DNA microarray sequencing, TFT biosensors, machine learning algorithms, in particular Bayesian networks, which provide an effective way of evidence organization and inference. The aim of this article is to discuss the state of art potentialities of bioinformatics in forensic DNA science. We also discuss how bioinformatics will address issues related to privacy rights such as those raised from large scale integration of crime, public health and population genetic susceptibility-to-diseases databases.},
  doi      = {10.1093/bib/bbm006},
  keywords = {Bayesian networks; CODIS; DNA microarray; DNA testing; forensic science},
  language = {en},
  pmid     = {17384432},
  url      = {http://bib.oxfordjournals.org/content/8/2/117},
  urldate  = {2016-11-01},
}

@Book{bischl_mlr:_2010,
  author     = {Bernd Bischl and Michel Lang and Lars Kotthoff and Julia Schiffner and Jakob Richter and Erich Studerus and Giuseppe Casalicchio and Zachary M. Jones},
  title      = {{{mlr}: {Machine} learning in {R}}},
  year       = {2010},
  shorttitle = {mlr},
  url        = {http://www.jmlr.org/papers/volume17/15-066/source/15-066.pdf},
  urldate    = {2017-06-25},
}

@Article{boehringer_dynamic_2013,
  author  = {Stefan Boehringer},
  journal = {The R Journal},
  title   = {{Dynamic {Parallelization} of {R} {Functions}}},
  year    = {2013},
  month   = dec,
  number  = {2},
  pages   = {88--97},
  volume  = {5},
  url     = {http://journal.r-project.org/archive/2013-2/RJournal_2013-2_boehringer.pdf},
}

@Article{burdukiewicz_methods_2016,
  author   = {Micha{\l} Burdukiewicz and Stefan R{\"o}diger and Piotr Sobczyk and Mario Menschikowski and Peter Schierack and Pawe{\l} Mackiewicz},
  journal  = {Biomolecular Detection and Quantification},
  title    = {{Methods for comparing multiple digital {PCR} experiments}},
  year     = {2016},
  issn     = {2214-7535},
  month    = sep,
  pages    = {14--19},
  volume   = {9},
  abstract = {The estimated mean copy per partition (\lambda) is the essential information from a digital PCR (dPCR) experiment because \lambda can be used to calculate the target concentration in a sample. However, little information is available how to statistically compare dPCR runs of multiple runs or reduplicates. The comparison of \lambda values from several runs is a multiple comparison problem, which can be solved using the binary structure of dPCR data. We propose and evaluate two novel methods based on Generalized Linear Models (GLM) and Multiple Ratio Tests (MRT) for comparison of digital PCR experiments. We enriched our MRT framework with computation of simultaneous confidence intervals suitable for comparing multiple dPCR runs. The evaluation of both statistical methods support that MRT is faster and more robust for dPCR experiments performed in large scale. Our theoretical results were confirmed by the analysis of dPCR measurements of dilution series. Both methods were implemented in the dpcR package (v. 0.2) for the open source R statistical computing environment.},
  doi      = {10.1016/j.bdq.2016.06.004},
  keywords = {Digital PCR; generalized linear models; dPCR; GLM; Multiple comparison},
  language = {eng},
  pmid     = {27551672},
}

@Article{bustin_miqe_2009,
  author       = {Stephen A. Bustin and Vladimir Benes and Jeremy A. Garson and Jan Hellemans and Jim Huggett and Mikael Kubista and Reinhold Mueller and Tania Nolan and Michael W. Pfaffl and Gregory L. Shipley and Jo Vandesompele and Carl T. Wittwer},
  journal      = {Clinical Chemistry},
  title        = {{The {MIQE} Guidelines: Minimum Information for Publication of Quantitative Real-Time {PCR} Experiments}},
  year         = {2009},
  issn         = {0009-9147, 1530-8561},
  month        = jan,
  number       = {4},
  pages        = {611--622},
  volume       = {55},
  abstract     = {Background: Currently, a lack of consensus exists on how best to perform and interpret quantitative real-time {PCR} ({qPCR}) experiments. The problem is exacerbated by a lack of sufficient experimental detail in many publications, which impedes a reader{\rq}s ability to evaluate critically the quality of the results presented or to repeat the experiments. Content: The Minimum Information for Publication of Quantitative Real-Time {PCR} Experiments ({MIQE}) guidelines target the reliability of results to help ensure the integrity of the scientific literature, promote consistency between laboratories, and increase experimental transparency. {MIQE} is a set of guidelines that describe the minimum information necessary for evaluating {qPCR} experiments. Included is a checklist to accompany the initial submission of a manuscript to the publisher. By providing all relevant experimental conditions and assay characteristics, reviewers can assess the validity of the protocols used. Full disclosure of all reagents, sequences, and analysis methods is necessary to enable other investigators to reproduce results. {MIQE} details should be published either in abbreviated form or as an online supplement. Summary: Following these guidelines will encourage better experimental practice, allowing more reliable and unequivocal interpretation of {qPCR} results.},
  doi          = {10.1373/clinchem.2008.112797},
  journaltitle = {Clinical Chemistry},
  langid       = {english},
  pmid         = {19246619},
  shortjournal = {Clinical Chemistry},
  shorttitle   = {The {MIQE} Guidelines},
  url          = {http://www.clinchem.org/content/55/4/611},
  urldate      = {2014-09-11},
}

@InProceedings{choi_study_2011,
  author    = {Y Choi and A S Ralhan and S Ko},
  title     = {{A {Study} on {Machine} {Learning} {Algorithms} for {Fall} {Detection} and {Movement} {Classification}}},
  year      = {2011},
  month     = apr,
  pages     = {1--8},
  publisher = {IEEE},
  doi       = {10.1109/ICISA.2011.5772404},
  isbn      = {978-1-4244-9222-0},
  url       = {http://ieeexplore.ieee.org/document/5772404/},
  urldate   = {2017-06-30},
}

@Book{cook_interactive_2007,
  author     = {Dianne Cook and Deborah F. Swayne},
  publisher  = {Springer},
  title      = {{Interactive and {Dynamic} {Graphics} for {Data} {Analysis}: {With} {R} and {GGobi}}},
  year       = {2007},
  address    = {New York},
  edition    = {2007 edition},
  isbn       = {978-0-387-71761-6},
  month      = dec,
  series     = {{1}},
  abstract   = {This book is about using interactive and dynamic plots on a computer screen as part of data exploration and modeling, both alone and as a partner with static graphics and non-graphical computational methods. The area of inter- active and dynamic data visualization emerged within statistics as part of research on exploratory data analysis in the late 1960s, and it remains an active subject of research today, as its use in practice continues to grow. It now makes substantial contributions within computer science as well, as part of the growing fields of information visualization and data mining, especially visual data mining.},
  doi        = {10.1007/978-0-387-71762-3},
  language   = {English},
  shorttitle = {Interactive and {Dynamic} {Graphics} for {Data} {Analysis}},
  url        = {http://www.springer.com/us/book/9780387717616},
}

@Article{curran_statistics_2009,
  author   = {James M. Curran},
  journal  = {Wiley Interdisciplinary Reviews: Computational Statistics},
  title    = {{Statistics in forensic science}},
  year     = {2009},
  issn     = {1939-0068},
  month    = sep,
  number   = {2},
  pages    = {141--156},
  volume   = {1},
  abstract = {Statistical thinking and computation are taking an increasing role in the field of forensic science. Heavy emphasis on Bayesian reasoning and logic over the last 20 years has revolutionized the interpretation of DNA evidence, glass evidence, and fingerprint evidence. This revolution has led to an increased demand for statistical software that makes the methodology accessible and usable. Interpretation of evidence is one part of forensic science where statistics is making a contribution. There are strong efforts, especially in the field of DNA, being made toward developing probabilistic expert systems which can aid investigators through intelligence-led policing. This paper will attempt to review the advances that have been made in the field of forensic science through statistical methodology. Copyright {\copyright} 2009 John Wiley \& Sons, Inc. For further resources related to this article, please visit the WIREs website.},
  doi      = {10.1002/wics.33},
  language = {en},
  urldate  = {2016-08-15},
}

@Manual{dataMaid,
  title  = {{dataMaid: A Suite of Checks for Identification of Potential Errors in a Data Frame as Part of the Data Cleaning Process}},
  author = {Anne Helby Petersen and Claus Thorn Ekstr{\o}m},
  note   = {R package version 0.9.2},
  year   = {2017},
  url    = {https://CRAN.R-project.org/package=dataMaid},
}

@Manual{dragulescu_xlsx_2014,
  title      = {{xlsx: {Read}, write, format {Excel} 2007 and {Excel} 97/2000/{XP}/2003 files}},
  author     = {Adrian A. Dragulescu},
  year       = {2014},
  abstract   = {Provide R functions to read/write/format Excel 2007 and Excel 97/2000/XP/2003 file formats.},
  copyright  = {GPL-3},
  shorttitle = {xlsx},
  url        = {https://cran.r-project.org/web/packages/xlsx/index.html},
  urldate    = {2015-08-13},
}

@Article{feuer_lemming:_2015,
  author     = {Ronny Feuer and Sebastian Vlaic and Janine Arlt and Oliver Sawodny and Uta Dahmen and Ulrich M. Zanger and Maria Thomas},
  journal    = {PLOS ONE},
  title      = {{{LEMming}: {A} {Linear} {Error} {Model} to {Normalize} {Parallel} {Quantitative} {Real}-{Time} {PCR} ({qPCR}) {Data} as an {Alternative} to {Reference} {Gene} {Based} {Methods}}},
  year       = {2015},
  issn       = {1932-6203},
  month      = sep,
  number     = {9},
  pages      = {e0135852},
  volume     = {10},
  abstract   = {Background Gene expression analysis is an essential part of biological and medical investigations. Quantitative real-time PCR (qPCR) is characterized with excellent sensitivity, dynamic range, reproducibility and is still regarded to be the gold standard for quantifying transcripts abundance. Parallelization of qPCR such as by microfluidic Taqman Fluidigm Biomark Platform enables evaluation of multiple transcripts in samples treated under various conditions. Despite advanced technologies, correct evaluation of the measurements remains challenging. Most widely used methods for evaluating or calculating gene expression data include geNorm and \Delta\Delta Ct , respectively. They rely on one or several stable reference genes (RGs) for normalization, thus potentially causing biased results. We therefore applied multivariable regression with a tailored error model to overcome the necessity of stable RGs. Results We developed a RG independent data normalization approach based on a tailored linear error m odel for parallel qPCR data, called LEMming. It uses the assumption that the mean Ct values within samples of similarly treated groups are equal. Performance of LEMming was evaluated in three data sets with different stability patterns of RGs and compared to the results of geNorm normalization. Data set 1 showed that both methods gave similar results if stable RGs are available. Data set 2 included RGs which are stable according to geNorm criteria, but became differentially expressed in normalized data evaluated by a t-test. geNorm -normalized data showed an effect of a shifted mean per gene per condition whereas LEMming-normalized data did not. Comparing the decrease of standard deviation from raw data to geNorm and to LEMming, the latter was superior. In data set 3 according to geNorm calculated average expression stability and pairwise variation, stable RGs were available, but t-tests of raw data contradicted this. Normalization with RGs resulted in distorted data contradicting literature, while LEMming normalized data did not. Conclusions If RGs are coexpressed but are not independent of the experimental conditions the stability criteria based on inter- and intragroup variation fail. The linear error model developed, LEMming, overcomes the dependency of using RGs for parallel qPCR measurements, besides resolving biases of both technical and biological nature in qPCR. However, to distinguish systematic errors per treated group from a global treatment effect an additional measurement is needed. Quantification of total cDNA content per sample helps to identify systematic errors.},
  doi        = {10.1371/journal.pone.0135852},
  keywords   = {Complementary DNA; Data processing; Gene Expression; Microfluidics; Polymerase chain reaction; Reverse Transcription; RNA extraction; RNA synthesis},
  shorttitle = {{LEMming}},
  url        = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0135852},
  urldate    = {2016-06-15},
}

@Article{forsberg_high-throughput_2016,
  author   = {Christina Forsberg and Linda Jansson and Ricky Ansell and Johannes Hedman},
  journal  = {Forensic Science International: Genetics},
  title    = {{High-throughput {DNA} extraction of forensic adhesive tapes}},
  year     = {2016},
  issn     = {1872-4973},
  month    = sep,
  pages    = {158--163},
  volume   = {24},
  doi      = {10.1016/j.fsigen.2016.06.004},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1872497316301053},
  urldate  = {2017-04-11},
}

@InProceedings{fu_cluster_2008,
  author    = {Huaiguo Fu},
  booktitle = {{Proceedings of the 7th {WSEAS} international conference on artificial intelligence, knowledge engineering and data bases ({AIKED}{\rq}08)}},
  title     = {{Cluster analysis and association analysis for the same data}},
  year      = {2008},
  pages     = {576--581},
  url       = {http://www.wseas.us/e-library/conferences/2008/uk/AIKED/AIKED-88.pdf},
  urldate   = {2017-07-25},
}

@Article{geng_minimizing_2015,
  author   = {Tao Geng and Richard A. Mathies},
  journal  = {Forensic Science International: Genetics},
  title    = {{Minimizing inhibition of {PCR}-{STR} typing using digital agarose droplet microfluidics}},
  year     = {2015},
  issn     = {1872-4973},
  month    = jan,
  pages    = {203--209},
  volume   = {14},
  doi      = {10.1016/j.fsigen.2014.10.007},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1872497314002233},
  urldate  = {2016-10-25},
}

@Article{geng_single-cell_2014,
  author   = {Tao Geng and Richard Novak and Richard A. Mathies},
  journal  = {Analytical Chemistry},
  title    = {{Single-{Cell} {Forensic} {Short} {Tandem} {Repeat} {Typing} within {Microfluidic} {Droplets}}},
  year     = {2014},
  issn     = {0003-2700},
  month    = jan,
  number   = {1},
  pages    = {703--712},
  volume   = {86},
  abstract = {A short tandem repeat (STR) typing method is developed for forensic identification of individual cells. In our strategy, monodisperse 1.5 nL agarose-in-oil droplets are produced with a high frequency using a microfluidic droplet generator. Statistically dilute single cells, along with primer-functionalized microbeads, are randomly compartmentalized in the droplets. Massively parallel single-cell droplet polymerase chain reaction (PCR) is performed to transfer replicas of desired STR targets from the single-cell genomic DNA onto the coencapsulated microbeads. These DNA-conjugated beads are subsequently harvested and reamplified under statistically dilute conditions for conventional capillary electrophoresis (CE) STR fragment size analysis. The 9-plex STR profiles of single cells from both pure and mixed populations of GM09947 and GM09948 human lymphoid cells show that all alleles are correctly called and allelic drop-in/drop-out is not observed. The cell mixture study exhibits a good linear relationship between the observed and input cell ratios in the range of 1:1 to 10:1. Additionally, the STR profile of GM09947 cells could be deduced even in the presence of a high concentration of cell-free contaminating 9948 genomic DNA. Our method will be valuable for the STR analysis of samples containing mixtures of cells/DNA from multiple contributors and for low-concentration samples.},
  doi      = {10.1021/ac403137h},
  urldate  = {2016-12-04},
}

@Article{gentleman_2004,
  author     = {Robert C Gentleman and Vincent J Carey and Douglas M Bates and Ben Bolstad and Marcel Dettling and Sandrine Dudoit and Byron Ellis and Laurent Gautier and Yongchao Ge and Jeff Gentry and Kurt Hornik and Torsten Hothorn and Wolfgang Huber and Stefano Iacus and Rafael Irizarry and Friedrich Leisch and Cheng Li and Martin Maechler and Anthony J Rossini and Gunther Sawitzki and Colin Smith and Gordon Smyth and Luke Tierney and Jean Y H Yang and Jianhua Zhang},
  journal    = {Genome Biology},
  title      = {{Bioconductor: open software development for computational biology and bioinformatics}},
  year       = {2004},
  issn       = {1465-6914},
  note       = {{PMID:} 15461798 {PMCID:} {PMC545600}},
  number     = {10},
  pages      = {R80},
  volume     = {5},
  abstract   = {The Bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. The goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. We describe details of our aims and methods, identify current challenges, compare Bioconductor to other open bioinformatics projects, and provide working examples.},
  doi        = {10.1186/gb-2004-5-10-r80},
  keywords   = {Computational Biology; Internet; Reproducibility of Results; Software},
  language   = {eng},
  shorttitle = {Bioconductor},
}

@Article{george_development_2016,
  author   = {Sandra George and Stefan R{\"o}diger and Christian Schr{\"o}der and Michael Knaut and Jan-Heiner K{\"u}pper},
  journal  = {Journal of Cellular Biotechnology},
  title    = {{Development of multiplex {PCR} systems for expression profiling of human cardiomyocytes induced to proliferate by lentivirus transduction of upcyte genes}},
  year     = {2016},
  issn     = {2352-3689},
  month    = jan,
  number   = {1},
  pages    = {35--55},
  volume   = {2},
  abstract = {Severe heart diseases such as myocarditis and cardiomyopathy are often characterized by progressive damages of contractile heart tissue which ultimately can lead to terminal heart failure. There is a need for relevant in vitro cultures of human cardiomyocytes to study pathogenic processes and to perform pharmacological testing of new heart drugs. By using the upcyte/EPCC (enhanced primary cell culture) approach for direct multiplication of organ-specific cells, we established proliferating human cardiomyocyte cultures derived from atrial appendages. For qualitative cardiac expression profiling we established a comprehensive set of multiplex PCR assays, selected from a panel of 32 genes, to rapidly screen changes at the transcriptional level in human ventricular and atrial cardiomyocytes. Our multiplex PCR approach revealed some donor variability of native atrial heart tissue that need to be confirmed by further studies with more samples. Our initial studies further indicated that characteristic heart muscle cell markers such as MLC-2 a , MLC-2v , CHRM2 , ADRB1 , DES , EDRNB , C x40 and KCNA5 were down-regulated when isolated cardiomyocytes were taken into primary cell culture. Compared to native heart tissue, proliferating atrial cardiomyocytes lacked expression of those cardiac markers but still expressed MYCD , GATA-4 , Cx43 , SERCA2 , BNP , Tbx5 , EDNRA and ACTB . Surprisingly, atrium-derived cardiomyocytes started to express NFAc4 in passage three, and cardiomyocyte marker expressions of Cx43 and BNP were even increased over cultivation time. In conclusion, our novel multiplex PCR assays should be useful for expression profiling of native heart tissues from patients with different disease conditions and for characterization of in vitro cardiomyocyte cultures.},
  doi      = {10.3233/JCB-15025},
  url      = {http://content.iospress.com/articles/journal-of-cellular-biotechnology/jcb15025},
  urldate  = {2016-09-16},
}

@Article{greene_big_2014,
  author    = {Casey S. Greene and Jie Tan and Matthew Ung and Jason H. Moore and Chao Cheng},
  journal   = {Journal of Cellular Physiology},
  title     = {{Big {Data} {Bioinformatics}}},
  year      = {2014},
  issn      = {1097-4652},
  number    = {12},
  pages     = {1896--1900},
  volume    = {229},
  abstract  = {Recent technological advances allow for high throughput profiling of biological systems in a cost-efficient manner. The low cost of data generation is leading us to the ``big data'' era. The availability of big data provides unprecedented opportunities but also raises new challenges for data mining and analysis. In this review, we introduce key concepts in the analysis of big data, including both ``machine learning'' algorithms as well as ``unsupervised'' and ``supervised'' examples of each. We note packages for the R programming language that are available to perform machine learning analyses. In addition to programming based solutions, we review webservers that allow users with limited or no programming background to perform these analyses on large data compendia. J. Cell. Physiol. 229: 1896--1900, 2014. {\copyright} 2014 Wiley Periodicals, Inc.},
  copyright = {{\copyright} 2014 Wiley Periodicals, Inc.},
  doi       = {10.1002/jcp.24662},
  language  = {en},
  urldate   = {2015-10-04},
}

@Article{halpern_str_2011,
  author   = {Micah D. Halpern and Jack Ballantyne},
  journal  = {Journal of Forensic Sciences},
  title    = {{An {STR} {Melt} {Curve} {Genotyping} {Assay} for {Forensic} {Analysis} {Employing} an {Intercalating} {Dye} {Probe} {FRET}*}},
  year     = {2011},
  issn     = {1556-4029},
  month    = jan,
  number   = {1},
  pages    = {36--45},
  volume   = {56},
  abstract = {Abstract: The most common markers used in forensic genetics are short tandem repeats (STRs), the alleles of which are separated and analyzed by length using capillary electrophoresis (CE). In this work, proof of concept of a unique STR genotyping approach has been demonstrated using asymmetric PCR and a fluorescence resonance energy transfer (FRET)-based hybridization analysis that combines fluorophore-labeled allele-specific probes and a DNA intercalating dye (dpFRET) in a melt match/mismatch analysis format. The system was successfully tested against both a simple (TPOX) and a complex (D3S1358) loci, demonstrated a preliminary detection limit of {\textless}10 genomic equivalents with no allelic dropout and mixture identification in both laboratory-generated and clinical samples. With additional development, this approach has the potential to contribute to advancing the use of STR loci for forensic applications and related fields.},
  doi      = {10.1111/j.1556-4029.2010.01549.x},
  keywords = {Fluorescence Resonance Energy Transfer; forensic science; DNA typing; short tandem repeat; intercalating dye; fluorophore probe; melt curve analysis},
  language = {en},
  urldate  = {2016-12-21},
}

@Article{hedman_applying_2011,
  author   = {J. Hedman and C. Dufva and L. Nor{\'e}n and C. Ansell and L. Albinsson and R. Ansell},
  journal  = {Forensic Science International: Genetics Supplement Series},
  title    = {{Applying a {PCR} inhibitor tolerant {DNA} polymerase blend in forensic {DNA} profiling}},
  year     = {2011},
  issn     = {1875-1768},
  month    = dec,
  number   = {1},
  pages    = {e349--e350},
  volume   = {3},
  doi      = {10.1016/j.fsigss.2011.09.037},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1875176811001752},
  urldate  = {2017-05-17},
}

@Article{hedman_synergy_2010,
  author   = {Johannes Hedman and Anders Nordgaard and Charlotte Dufva and Birgitta Rasmusson and Ricky Ansell and Peter R{\aa}dstr{\"o}m},
  journal  = {Analytical Biochemistry},
  title    = {{Synergy between {DNA} polymerases increases polymerase chain reaction inhibitor tolerance in forensic {DNA} analysis}},
  year     = {2010},
  issn     = {0003-2697},
  month    = oct,
  number   = {2},
  pages    = {192--200},
  volume   = {405},
  doi      = {10.1016/j.ab.2010.06.028},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S0003269710003817},
  urldate  = {2017-05-17},
}

@Article{hellemans_2007,
  author   = {Jan Hellemans and Geert Mortier and Anne {De Paepe} and Frank Speleman and Jo Vandesompele},
  journal  = {Genome Biology},
  title    = {{{qBase} relative quantification framework and software for management and automated analysis of real-time quantitative {PCR} data}},
  year     = {2007},
  issn     = {1465-6906},
  number   = {2},
  pages    = {R19},
  volume   = {8},
  abstract = {{qBase}, a free program for the management and automated analysis of {qPCR} data, is described, Although quantitative {PCR} ({qPCR}) is becoming the method of choice for expression profiling of selected genes, accurate and straightforward processing of the raw measurements remains a major hurdle. Here we outline advanced and universally applicable models for relative quantification and inter-run calibration with proper error propagation along the entire calculation track. These models and algorithms are implemented in {qBase}, a free program for the management and automated analysis of {qPCR} data.},
  doi      = {10.1186/gb-2007-8-2-r19},
  pmcid    = {PMC1852402},
  pmid     = {17291332},
  url      = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1852402/},
  urldate  = {2014-09-11},
}

@Book{herrera_multiple_2016,
  author    = {Francisco Herrera and Sebasti{\'a}n Ventura and Rafael Bello and Chris Cornelis and Amelia Zafra and D{\'a}nel S{\'a}nchez-Tarrag{\'o} and Sarah Vluymans},
  publisher = {Springer International Publishing},
  title     = {{Multiple {Instance} {Learning}}},
  year      = {2016},
  address   = {Cham},
  isbn      = {978-3-319-47758-9 978-3-319-47759-6},
  doi       = {10.1007/978-3-319-47759-6},
  language  = {en},
  urldate   = {2017-07-31},
}

@Article{hofmann_2013,
  author   = {Heike Hofmann and Antony Unwin and Dianne Cook},
  journal  = {The R Journal},
  title    = {{Let Graphics Tell the Story - Datasets in R}},
  year     = {2013},
  month    = jun,
  number   = {1},
  pages    = {117--130},
  volume   = {5},
  abstract = {Graphics are good for showing the information in datasets and for complementing modelling. Sometimes graphics show information models miss, sometimes graphics help to make model results more understandable, and sometimes models show whether information from graphics has statistical support or not. It is the interplay of the two approaches that is valuable. Graphics could be used a lot more in R examples and we explore this idea with some datasets available in R packages.},
  url      = {http://journal.r-project.org/archive/2013-1/RJournal_2013-1_hofmann-unwin-cook.pdf},
}

@Article{hopwood_integrated_2010,
  author     = {Andrew J. Hopwood and Cedric Hurth and Jianing Yang and Zhi Cai and Nina Moran and John G. Lee-Edghill and Alan Nordquist and Ralf Lenigk and Matthew D. Estes and John P. Haley and Colin R. McAlister and Xiaojia Chen and Carla Brooks and Stan Smith and Keith Elliott and Pieris Koumi and Frederic Zenhausern and Gillian Tully},
  journal    = {Analytical Chemistry},
  title      = {{Integrated {Microfluidic} {System} for {Rapid} {Forensic} {DNA} {Analysis}: {Sample} {Collection} to {DNA} {Profile}}},
  year       = {2010},
  issn       = {0003-2700, 1520-6882},
  month      = aug,
  number     = {16},
  pages      = {6991--6999},
  volume     = {82},
  doi        = {10.1021/ac101355r},
  language   = {en},
  shorttitle = {Integrated {Microfluidic} {System} for {Rapid} {Forensic} {DNA} {Analysis}},
  urldate    = {2016-10-25},
}

@Article{hornik_strucplot_2006,
  author     = {Kurt Hornik and Achim Zeileis and David Meyer},
  journal    = {Journal of Statistical Software},
  title      = {{The strucplot framework: visualizing multi-way contingency tables with vcd}},
  year       = {2006},
  number     = {3},
  pages      = {1--48},
  volume     = {17},
  shorttitle = {The strucplot framework},
  url        = {http://epub.wu.ac.at/id/eprint/3984},
  urldate    = {2017-08-28},
}

@Book{hothorn_handbook_2014,
  author    = {Torsten Hothorn and Brian S. Everitt},
  publisher = {Chapman and Hall/CRC},
  title     = {{A {Handbook} of {Statistical} {Analyses} using {R}, {Third} {Edition}}},
  year      = {2014},
  address   = {Oakville},
  edition   = {3rd},
  isbn      = {978-1-4822-0458-2},
  month     = jun,
  note      = {OCLC: 885455227},
  language  = {English},
}

@Article{hothorn_unbiased_2006,
  author     = {Torsten Hothorn and Kurt Hornik and Achim Zeileis},
  journal    = {Journal of Computational and Graphical Statistics},
  title      = {{Unbiased {Recursive} {Partitioning}: {A} {Conditional} {Inference} {Framework}}},
  year       = {2006},
  issn       = {1061-8600, 1537-2715},
  month      = sep,
  number     = {3},
  pages      = {651--674},
  volume     = {15},
  doi        = {10.1198/106186006X133933},
  language   = {en},
  shorttitle = {Unbiased {Recursive} {Partitioning}},
  urldate    = {2017-07-25},
}

@Article{huggett_2013,
  author     = {Jim F Huggett and Carole A Foy and Vladimir Benes and Kerry Emslie and Jeremy A Garson and Ross Haynes and Jan Hellemans and Mikael Kubista and Reinhold D Mueller and Tania Nolan and Michael W Pfaffl and Gregory L Shipley and Jo Vandesompele and Carl T Wittwer and Stephen A Bustin},
  journal    = {Clinical {C}hemistry},
  title      = {{The digital {MIQE} guidelines: Minimum Information for Publication of Quantitative Digital {PCR} Experiments}},
  year       = {2013},
  issn       = {1530-8561},
  month      = jun,
  note       = {{PMID:} 23570709},
  number     = {6},
  pages      = {892--902},
  volume     = {59},
  abstract   = {There is growing interest in digital {PCR} ({dPCR)} because technological progress makes it a practical and increasingly affordable technology. {dPCR} allows the precise quantification of nucleic acids, facilitating the measurement of small percentage differences and quantification of rare variants. {dPCR} may also be more reproducible and less susceptible to inhibition than quantitative real-time {PCR} ({qPCR).} Consequently, {dPCR} has the potential to have a substantial impact on research as well as diagnostic applications. However, as with {qPCR}, the ability to perform robust meaningful experiments requires careful design and adequate controls. To assist independent evaluation of experimental data, comprehensive disclosure of all relevant experimental details is required. To facilitate this process we present the Minimum Information for Publication of Quantitative Digital {PCR} Experiments guidelines. This report addresses known requirements for {dPCR} that have already been identified during this early stage of its development and commercial implementation. Adoption of these guidelines by the scientific community will help to standardize experimental protocols, maximize efficient utilization of resources, and enhance the impact of this promising new technology.},
  doi        = {10.1373/clinchem.2013.206375},
  keywords   = {Computers; Guidelines as Topic; Real-Time Polymerase Chain Reaction},
  language   = {eng},
  shorttitle = {The digital {MIQE} guidelines},
}

@Book{igual_introduction_2017,
  author    = {Laura Igual and Santi Segu{\'i}},
  publisher = {Springer International Publishing},
  title     = {{Introduction to {Data} {Science}}},
  year      = {2017},
  address   = {Cham},
  isbn      = {978-3-319-50016-4 978-3-319-50017-1},
  series    = {{Undergraduate {Topics} in {Computer} {Science}}},
  doi       = {10.1007/978-3-319-50017-1},
  urldate   = {2017-07-26},
}

@InProceedings{jambukia_classification_2015,
  author     = {Shweta H. Jambukia and Vipul K. Dabhi and Harshadkumar B. Prajapati},
  booktitle  = {{Computer {Engineering} and {Applications} ({ICACEA}), 2015 {International} {Conference} on {Advances} in {Computer Engineering} and {Applications}}},
  title      = {{Classification of {ECG} signals using machine learning techniques: {A} survey}},
  year       = {2015},
  pages      = {714--721},
  publisher  = {IEEE},
  shorttitle = {Classification of {ECG} signals using machine learning techniques},
  url        = {http://ieeexplore.ieee.org/abstract/document/7164783/},
  urldate    = {2017-06-25},
}

@Article{james_ecp:_2013,
  author     = {Nicholas A. James and David S. Matteson},
  journal    = {arXiv preprint arXiv:1309.3295},
  title      = {{{ecp}: {An} {R} package for nonparametric multiple change point analysis of multivariate data}},
  year       = {2013},
  shorttitle = {ecp},
  url        = {https://arxiv.org/abs/1309.3295},
  urldate    = {2017-06-25},
}

@Book{james_introduction_2013,
  author    = {Gareth James and Daniela Witten and Trevor Hastie and Robert Tibshirani},
  publisher = {Springer New York},
  title     = {{An {Introduction} to {Statistical} {Learning}}},
  year      = {2013},
  address   = {New York, NY},
  isbn      = {978-1-4614-7137-0 978-1-4614-7138-7},
  series    = {{Springer {Texts} in {Statistics}}},
  volume    = {103},
  doi       = {10.1007/978-1-4614-7138-7},
  urldate   = {2017-10-12},
}

@Article{jeffreys_individual-specific_1985,
  author    = {A. J. Jeffreys and V. Wilson and S. L. Thein},
  journal   = {Nature},
  title     = {{Individual-specific {\lq}fingerprints{\rq} of human {DNA}}},
  year      = {1985},
  issn      = {1476-4687},
  month     = jul,
  number    = {6023},
  pages     = {76},
  volume    = {316},
  abstract  = {Individual-specific {\lq}fingerprints{\rq} of human DNA},
  copyright = {1985 Nature Publishing Group},
  doi       = {10.1038/316076a0},
  language  = {En},
  url       = {https://www.nature.com/articles/316076a0},
  urldate   = {2017-12-21},
}

@Article{jobling_y_1997,
  author   = {M. A. Jobling and A. Pandya and C. Tyler-Smith},
  journal  = {International Journal of Legal Medicine},
  title    = {{The {Y} chromosome in forensic analysis and paternity testing}},
  year     = {1997},
  issn     = {0937-9827},
  number   = {3},
  pages    = {118--124},
  volume   = {110},
  abstract = {The male specificity of the human Y chromosome makes it potentially useful in forensic studies and paternity testing, and markers are now available which will allow its usefulness to be assessed in practice. However, while it can be used confidently for exclusions, the unusual properties of the Y mean that inclusions will be very difficult to make: haplotypes are confined within lineages, so population sub-structuring is a major problem, and many male relatives of a suspect will share his Y chromosome. Y haplotyping is most likely to find application in special instances, such as deficiency cases in paternity testing and in the analysis of mixtures of male and female DNA, or in combination with autosomal markers.},
  keywords = {Humans; Female; Male; Genetics; Population; Genetic Markers; Haplotypes; Gene Frequency; Paternity; Polymorphism; Genetic; Y Chromosome},
  language = {eng},
  pmid     = {9228562},
}

@Manual{kmlShape,
  title  = {{kmlShape: K-Means for Longitudinal Data using Shape-Respecting Distance}},
  author = {Christophe Genolini},
  note   = {R package version 0.9.5},
  year   = {2016},
  url    = {https://CRAN.R-project.org/package=kmlShape},
}

@Article{kowarik_sparktable:_2014,
  author     = {Alexander Kowarik and Bernhard Meindl and Matthias Templ},
  journal    = {The R Journal},
  title      = {{{sparkTable}: {Generating} graphical tables for websites and documents with {R}}},
  year       = {2014},
  number     = {1},
  pages      = {24--37},
  volume     = {7},
  shorttitle = {{sparkTable}},
  url        = {https://publik.tuwien.ac.at/files/PubDat_228663.pdf},
  urldate    = {2017-06-25},
}

@Article{kruschke_bayesian_2013,
  author  = {John K. Kruschke},
  journal = {Journal of Experimental Psychology: General},
  title   = {{Bayesian estimation supersedes the t test.}},
  year    = {2013},
  number  = {2},
  pages   = {573},
  volume  = {142},
  url     = {http://psycnet.apa.org/journals/xge/142/2/573/},
  urldate = {2017-06-26},
}

@Article{kyoda_biological_2015,
  author     = {Koji Kyoda and Yukako Tohsato and Kenneth H. L. Ho and Shuichi Onami},
  journal    = {Bioinformatics},
  title      = {{Biological {Dynamics} {Markup} {Language} ({BDML}): an open format for representing quantitative biological dynamics data}},
  year       = {2015},
  issn       = {1367-4803, 1460-2059},
  number     = {7},
  pages      = {1044--1052},
  volume     = {31},
  abstract   = {Motivation: Recent progress in live-cell imaging and modeling techniques has resulted in generation of a large amount of quantitative data (from experimental measurements and computer simulations) on spatiotemporal dynamics of biological objects such as molecules, cells and organisms. Although many research groups have independently dedicated their efforts to developing software tools for visualizing and analyzing these data, these tools are often not compatible with each other because of different data formats. Results: We developed an open unified format, Biological Dynamics Markup Language (BDML; current version: 0.2), which provides a basic framework for representing quantitative biological dynamics data for objects ranging from molecules to cells to organisms. BDML is based on Extensible Markup Language (XML). Its advantages are machine and human readability and extensibility. BDML will improve the efficiency of development and evaluation of software tools for data visualization and analysis. Availability and implementation: A specification and a schema file for BDML are freely available online at http://ssbd.qbic.riken.jp/bdml/. Contact: sonami@riken.jp Supplementary Information: Supplementary data are available at Bioinformatics online.},
  doi        = {10.1093/bioinformatics/btu767},
  pmid       = {25414366},
  shorttitle = {Biological {Dynamics} {Markup} {Language} ({BDML})},
  url        = {http://bioinformatics.oxfordjournals.org/content/31/7/1044},
}

@Book{lee_statistical_2010,
  author    = {Jae K. Lee},
  publisher = {Wiley-Blackwell},
  title     = {{Statistical {Bioinformatics}: {For} {Biomedical} and {Life} {Science} {Researchers}}},
  year      = {2010},
  isbn      = {978-0-471-69272-0},
  url       = {https://www.wiley.com/en-sg/Statistical+Bioinformatics%3A+For+Biomedical+and+Life+Science+Researchers-p-9780471692720},
}

@Article{liu_direct_2014,
  author   = {Jason Yingjie Liu},
  journal  = {Forensic Science International: Genetics},
  title    = {{Direct {qPCR} quantification of unprocessed forensic casework samples}},
  year     = {2014},
  issn     = {1872-4973},
  month    = jul,
  pages    = {96--104},
  volume   = {11},
  doi      = {10.1016/j.fsigen.2014.03.003},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1872497314000441},
  urldate  = {2017-06-23},
}

@Article{liu_r_2014,
  author    = {Zhifa Liu and Stan Pounds},
  journal   = {BMC Bioinformatics},
  title     = {{An {R} package that automatically collects and archives details for reproducible computing}},
  year      = {2014},
  issn      = {1471-2105},
  month     = may,
  number    = {1},
  pages     = {138},
  volume    = {15},
  abstract  = {It is scientifically and ethically imperative that the results of statistical analysis of biomedical research data be computationally reproducible in the sense that the reported results can be easily recapitulated from the study data. Some statistical analyses are computationally a function of many data files, program files, and other details that are updated or corrected over time. In many applications, it is infeasible to manually maintain an accurate and complete record of all these details about a particular analysis. PMID: 24886202},
  copyright = {2014 Liu and Pounds; licensee BioMed Central Ltd.},
  doi       = {10.1186/1471-2105-15-138},
  language  = {en},
  pmid      = {24886202},
  url       = {http://www.biomedcentral.com/1471-2105/15/138/abstract},
  urldate   = {2014-07-01},
}

@InCollection{lundberg_unified_2017,
  author    = {Scott M Lundberg and Su-In Lee},
  booktitle = {{Advances in {Neural} {Information} {Processing} {Systems} 30}},
  publisher = {Curran Associates, Inc.},
  title     = {{A {Unified} {Approach} to {Interpreting} {Model} {Predictions}}},
  year      = {2017},
  editor    = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {4768--4777},
  url       = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf},
  urldate   = {2017-12-25},
}

@Article{m_romeika_recent_2014,
  author  = {jennifer m romeika},
  journal = {journal of forensic research},
  title   = {{recent {advances} in {forensic} {dna} {analysis}}},
  year    = {2014},
  issn    = {2157-7145},
  number  = {01},
  volume  = {s12},
  doi     = {10.4172/2157-7145.s12-001},
  url     = {http://www.omicsonline.org/open-access/recent-advances-in-forensic-dna-analysis-2157-7145.s12-001.php?aid=20400},
  urldate = {2016-12-04},
}

@Article{mallona_chainy:_nodate,
  author     = {Izaskun Mallona and Anna D{\'i}ez-Villanueva and Berta Mart{\'i}n and Miguel A. Peinado},
  journal    = {Bioinformatics},
  title      = {{Chainy: an universal tool for standardized relative quantification in real-time {PCR}}},
  year       = {2017},
  doi        = {10.1093/bioinformatics/btw839},
  shorttitle = {Chainy},
  urldate    = {2017-04-23},
}

@Article{mao_characterization_2007,
  author   = {Fei Mao and Wai-Yee Leung and Xing Xin},
  journal  = {BMC Biotechnology},
  title    = {{Characterization of {EvaGreen} and the implication of its physicochemical properties for {qPCR} applications}},
  year     = {2007},
  issn     = {1472-6750},
  month    = nov,
  pages    = {76},
  volume   = {7},
  abstract = {Background EvaGreen (EG) is a newly developed DNA-binding dye that has recently been used in quantitative real-time PCR (qPCR), post-PCR DNA melt curve analysis and several other applications. However, very little is known about the physicochemical properties of the dye and their relevance to the applications, particularly to qPCR and post PCR DNA melt curve analysis. In this paper, we characterized EG along with a widely used qPCR dye, SYBR Green I (SG), for their DNA-binding properties and stability, and compared their performance in qPCR under a variety of conditions. Results This study systematically compared the DNA binding profiles of the two dyes under different conditions and had these findings: a) EG had a lower binding affinity for both double-stranded DNA (dsDNA) and single-stranded DNA (ssDNA) than SG; b) EG showed no apparent preference for either GC- or AT-rich sequence while SG had a slight preference for AT-rich sequence; c) both dyes showed substantially lower affinity toward ssDNA than toward dsDNA and even lower affinity toward shorter ssDNA fragments except that this trend was more pronounced for EG. Our results also demonstrated that EG was stable both under PCR condition and during routine storage and handling. In the comparative qPCR study, both EG and SG exhibited PCR interference when used at high dye concentration, as evident from delayed Ct and/or nonspecific product formation. The problem worsened when the chain extension time was shortened or when the amplicon size was relatively long ({\textgreater}500 bp). However, qPCR using EG tolerated a significantly higher dye concentration, thus permitting a more robust PCR signal as well as a sharper and stronger DNA melt peak. These differences in qPCR performance between the two dyes are believed to be attributable to their differences in DNA binding profiles. Conclusion These findings suggest that an ideal qPCR dye should possess several DNA-binding characteristics, including a {"}just right{"} affinity for dsDNA and low or no affinity for ssDNA and short DNA fragments. The favorable DNA-binding profile of EG, coupled with its good stability and instrument-compatibility, should make EG a promising dye for qPCR and related applications.},
  doi      = {10.1186/1472-6750-7-76},
  pmcid    = {PMC2213645},
  pmid     = {17996102},
  url      = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2213645/},
  urldate  = {2014-03-23},
}

@Article{matz_no_2013,
  author     = {Mikhail V. Matz and Rachel M. Wright and James G. Scott},
  journal    = {PLoS ONE},
  title      = {{No {Control} {Genes} {Required}: {Bayesian} {Analysis} of {qRT}-{PCR} {Data}}},
  year       = {2013},
  month      = aug,
  number     = {8},
  pages      = {e71448},
  volume     = {8},
  abstract   = {BackgroundModel-based analysis of data from quantitative reverse-transcription PCR (qRT-PCR) is potentially more powerful and versatile than traditional methods. Yet existing model-based approaches cannot properly deal with the higher sampling variances associated with low-abundant targets, nor do they provide a natural way to incorporate assumptions about the stability of control genes directly into the model-fitting process.ResultsIn our method, raw qPCR data are represented as molecule counts, and described using generalized linear mixed models under Poisson-lognormal error. A Markov Chain Monte Carlo (MCMC) algorithm is used to sample from the joint posterior distribution over all model parameters, thereby estimating the effects of all experimental factors on the expression of every gene. The Poisson-based model allows for the correct specification of the mean-variance relationship of the PCR amplification process, and can also glean information from instances of no amplification (zero counts). Our method is very flexible with respect to control genes: any prior knowledge about the expected degree of their stability can be directly incorporated into the model. Yet the method provides sensible answers without such assumptions, or even in the complete absence of control genes. We also present a natural Bayesian analogue of the ``classic'' analysis, which uses standard data pre-processing steps (logarithmic transformation and multi-gene normalization) but estimates all gene expression changes jointly within a single model. The new methods are considerably more flexible and powerful than the standard delta-delta Ct analysis based on pairwise t-tests.ConclusionsOur methodology expands the applicability of the relative-quantification analysis protocol all the way to the lowest-abundance targets, and provides a novel opportunity to analyze qRT-PCR data without making any assumptions concerning target stability. These procedures have been implemented as the MCMC.qpcr package in R.},
  doi        = {10.1371/journal.pone.0071448},
  shorttitle = {No {Control} {Genes} {Required}},
  urldate    = {2015-05-04},
}

@Article{mcnevin_assessment_2013,
  author   = {D. McNevin and C. Santos and A. G{\'o}mez-Tato and J. {\'A}lvarez-Dios and M. Casares de Cal and R. Daniel and C. Phillips and M.V. Lareu},
  journal  = {Forensic Science International: Genetics Supplement Series},
  title    = {{An assessment of {Bayesian} and multinomial logistic regression classification systems to analyse admixed individuals}},
  year     = {2013},
  issn     = {1875-1768},
  number   = {1},
  pages    = {e63--e64},
  volume   = {4},
  doi      = {10.1016/j.fsigss.2013.10.032},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1875176813000334},
  urldate  = {2017-02-10},
}

@Article{millard_adaptive_2011,
  author    = {Bjorn L. Millard and Mario Niepel and Michael P. Menden and Jeremy L. Muhlich and Peter K. Sorger},
  journal   = {Nature Methods},
  title     = {{Adaptive informatics for multifactorial and high-content biological data}},
  year      = {2011},
  issn      = {1548-7091},
  number    = {6},
  pages     = {487--492},
  volume    = {8},
  abstract  = {Whereas genomic data are universally machine-readable, data from imaging, multiplex biochemistry, flow cytometry and other cell- and tissue-based assays usually reside in loosely organized files of poorly documented provenance. This arises because the relational databases used in genomic research are difficult to adapt to rapidly evolving experimental designs, data formats and analytic algorithms. Here we describe an adaptive approach to managing experimental data based on semantically typed data hypercubes (SDCubes) that combine hierarchical data format 5 (HDF5) and extensible markup language (XML) file types. We demonstrate the application of SDCube-based storage using ImageRail, a software package for high-throughput microscopy. Experimental design and its day-to-day evolution, not rigid standards, determine how ImageRail data are organized in SDCubes. We applied ImageRail to collect and analyze drug dose-response landscapes in human cell lines at single-cell resolution.},
  copyright = {{\copyright} 2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  doi       = {10.1038/nmeth.1600},
  url       = {http://www.nature.com/nmeth/journal/v8/n6/full/nmeth.1600.html},
}

@Article{pan_real-time_1985,
  author   = {J. Pan and W. J. Tompkins},
  journal  = {IEEE Transactions on Biomedical Engineering},
  title    = {{A {Real}-{Time} {QRS} {Detection} {Algorithm}}},
  year     = {1985},
  issn     = {0018-9294},
  month    = mar,
  number   = {3},
  pages    = {230--236},
  volume   = {BME-32},
  abstract = {We have developed a real-time algorithm for detection of the QRS complexes of ECG signals. It reliably recognizes QRS complexes based upon digital analyses of slope, amplitude, and width. A special digital bandpass filter reduces false detections caused by the various types of interference present in ECG signals. This filtering permits use of low thresholds, thereby increasing detection sensitivity. The algorithm automatically adjusts thresholds and parameters periodically to adapt to such ECG changes as QRS morphology and heart rate. For the standard 24 h MIT/BIH arrhythmia database, this algorithm correctly detects 99.3 percent of the QRS complexes.},
  doi      = {10.1109/TBME.1985.325532},
  keywords = {Analog-Digital Conversion; Band pass filters; Computer displays; Databases; Detection algorithms; Detectors; Digital filters; Electrocardiography; Evaluation Studies as Topic; Filtering; Filtration; Humans; Interference; Mathematics; Noise reduction},
}

@Article{perkins_readqpcr_2012,
  author     = {James R. Perkins and John M. Dawes and Steve B. McMahon and David LH Bennett and Christine Orengo and Matthias Kohl},
  journal    = {BMC Genomics},
  title      = {{{ReadqPCR} and {NormqPCR}: {R} packages for the reading, quality checking and normalisation of {RT}-{qPCR} quantification cycle ({Cq}) data}},
  year       = {2012},
  issn       = {1471-2164},
  month      = jul,
  number     = {1},
  pages      = {296},
  volume     = {13},
  abstract   = {Measuring gene transcription using real-time reverse transcription polymerase chain reaction (RT-qPCR) technology is a mainstay of molecular biology. Technologies now exist to measure the abundance of many transcripts in parallel. The selection of the optimal reference gene for the normalisation of this data is a recurring problem, and several algorithms have been developed in order to solve it. So far nothing in R exists to unite these methods, together with other functions to read in and normalise the data using the chosen reference gene(s). PMID: 22748112},
  copyright  = {2012 Perkins et al.; licensee BioMed Central Ltd.},
  doi        = {10.1186/1471-2164-13-296},
  language   = {en},
  pmid       = {22748112},
  shorttitle = {{ReadqPCR} and {NormqPCR}},
  url        = {http://www.biomedcentral.com/1471-2164/13/296/abstract},
  urldate    = {2014-04-27},
}

@Article{pilhoefer_new_2013,
  author     = {Alexander Pilhoefer and Antony Unwin and {others}},
  journal    = {Journal of Statistical Software},
  title      = {{New approaches in visualization of categorical data: {R} package extracat}},
  year       = {2013},
  number     = {7},
  pages      = {1--25},
  volume     = {53},
  shorttitle = {New approaches in visualization of categorical data},
  url        = {https://www.jstatsoft.org/article/view/v053i07/v53i07.pdf},
  urldate    = {2017-08-28},
}

@Article{reed_high-resolution_2007,
  author       = {Gudrun H. Reed and Jana O. Kent and Carl T. Wittwer},
  journal      = {Pharmacogenomics},
  title        = {{High-resolution {DNA} melting analysis for simple and efficient molecular diagnostics}},
  year         = {2007},
  issn         = {1744-8042},
  month        = jun,
  number       = {6},
  pages        = {597--608},
  volume       = {8},
  abstract     = {High-resolution melting of {DNA} is a simple solution for genotyping, mutation scanning and sequence matching. The melting profile of a {PCR} product depends on its {GC} content, length, sequence and heterozygosity and is best monitored with saturating dyes that fluoresce in the presence of double-stranded {DNA}. Genotyping of most variants is possible by the melting temperature of the {PCR} products, while all variants can be genotyped with unlabeled probes. Mutation scanning and sequence matching depend on sequence differences that result in heteroduplexes that change the shape of the melting curve. High-resolution {DNA} melting has several advantages over other genotyping and scanning methods, including an inexpensive closed tube format that is homogenous, accurate and rapid. Owing to its simplicity and speed, the method is a good fit for personalized medicine as a rapid, inexpensive method to predict therapeutic response.},
  doi          = {10.2217/14622416.8.6.597},
  keywords     = {Animals; {DNA} Mutational Analysis; Hot Temperature; Humans; Molecular Diagnostic Techniques; Nucleic Acid Denaturation},
  pmid         = {17559349},
  shortjournal = {Pharmacogenomics},
}

@Article{reja_screenclust:_2010,
  author     = {Valin Reja and Alister Kwok and Glenn Stone and Linsong Yang and Andreas Missel and Christoph Menzel and Brant Bassam},
  journal    = {Methods},
  title      = {{{ScreenClust}: {Advanced} statistical software for supervised and unsupervised high resolution melting ({HRM}) analysis}},
  year       = {2010},
  issn       = {1046-2023},
  month      = apr,
  number     = {4},
  pages      = {S10--S14},
  volume     = {50},
  doi        = {10.1016/j.ymeth.2010.02.006},
  language   = {en},
  shorttitle = {{ScreenClust}},
  url        = {http://linkinghub.elsevier.com/retrieve/pii/S1046202310000563},
  urldate    = {2017-06-29},
}

@Manual{ripley_rodbc_2015,
  title      = {{{RODBC}: {ODBC} {Database} {Access}}},
  author     = {Brian Ripley and Michael Lapsley (1999 Oct to 2002)},
  year       = {2015},
  abstract   = {An ODBC database interface.},
  copyright  = {GPL-2 {\textbar} GPL-3},
  shorttitle = {{RODBC}},
  url        = {https://cran.r-project.org/web/packages/RODBC/index.html},
  urldate    = {2015-08-13},
}

@InCollection{rodiger_alternative_2011,
  author    = {Stefan R{\"o}diger and Sandra George and Carsten Schmidt and Ulrike Fr{\"o}mmel and Mirko Ruhland and Ingolf Schimke and Peter Schierack and Christian Schr{\"o}der},
  booktitle = {{Multiparameteranalytik in {Forschung} und {Praxis}}},
  publisher = {Pabst Science Publishers},
  title     = {{Alternative {Nukleins{\"a}ureamplifikationsverfahren} f{\"u}r die {Multiparameteranalytik}}},
  year      = {2011},
  isbn      = {978-3-89967-703-4},
  pages     = {133--146},
  abstract  = {Im Zeitalter der sequenzierten Genome ist der spezifische Nachweis von DNA und RNA Sequenzen eine zentrale Aufgabe molekularer Diagnostik. Die qualitative und quantitative Analyse von Nukleins{\"a}uresequenzen findet unter anderem Anwendung in der Krankheitserregerdetektion, der medizinischen Diagnostik, dem Wirkstoff-Screening in der Pharmazie und im Bereich der Systembiologie. F{\"u}r den Nachweis von Nukleins{\"a}ureanalyten existieren grundlegend zwei Ans{\"a}tze. Zum einen ist es m{\"o}glich Methoden zu verwenden, die nicht auf einer Analytvervielf{\"a}ltigung beruhen, sondern den Analyt direkt detektieren. Allerdings erfordern solche Verfahren eine Signalverst{\"a}rkung. Hier ist die Hybridisierung markierter Nachweissonden an die Zielsequenz zu nennen. Zum anderen k{\"o}nnen spezifisch Analyten in einem Reaktionsraum amplifiziert und nachgewiesen werden. Die Amplifikation erfolgt in der Regel enzymatisch, sodass eine indirekte Quantifizierung des Analyten m{\"o}glich ist. Als Erweiterung solcher Einzelparametermessungen sind Multiparameteranalysen zu betrachten, die simultan mehrere unabh{\"a}ngige Analyten in einem Reaktionsraum sowohl qualitativ als auch quantitativ erfassen. Gegen{\"u}ber Einzelmessungen bieten Multiparameteranalysen eine h{\"o}here Wirtschaftlichkeit, eine Steigerung der Bearbeitungsgeschwindigkeit, eine Reduktion des notwendigen Probenvolumens und eine Steigerung der Vergleichbarkeit der ermittelten Parameter untereinander. Der modernen Multiparameteranalytik stehen diverse Amplifikationsmethoden zur Verf{\"u}gung. Eine zentrale Rolle nimmt die PCR mit ihren zahlreichen Variationen ein. Daneben haben sich weitere Technologien etabliert, die sich grunds{\"a}tzlich von der konventionellen PCR bez{\"u}glich Reaktionsprinzip und Reaktionsbedingungen unterscheiden. Eine vergleichende Betrachtung der aktuellen Methoden ist Gegenstand dieser Abhandlung.},
  doi       = {10.13140/RG.2.1.2766.1681},
  language  = {de},
}

@Article{roediger_highly_2013,
  author   = {Stefan R{\"o}diger and Peter Schierack and Alexander B{\"o}hm and J{\"o}rg Nitschke and Ingo Berger and Ulrike Fr{\"o}mmel and Carsten Schmidt and Mirko Ruhland and Ingolf Schimke and Dirk Roggenbuck and Werner Lehmann and Christian Schr{\"o}der},
  journal  = {Advances in Biochemical Engineering/Biotechnology},
  title    = {{A highly versatile microscope imaging technology platform for the multiplex real-time detection of biomolecules and autoimmune antibodies}},
  year     = {2013},
  issn     = {0724-6145},
  pages    = {35--74},
  volume   = {133},
  abstract = {The analysis of different biomolecules is of prime importance for life science research and medical diagnostics. Due to the discovery of new molecules and new emerging bioanalytical problems, there is an ongoing demand for a technology platform that provides a broad range of assays with a user-friendly flexibility and rapid adaptability to new applications. Here we describe a highly versatile microscopy platform, VideoScan, for the rapid and simultaneous analysis of various assay formats based on fluorescence microscopic detection. The technological design is equally suitable for assays in solution, microbead-based assays and cell pattern recognition. The multiplex real-time capability for tracking of changes under dynamic heating conditions makes it a useful tool for PCR applications and nucleic acid hybridization, enabling kinetic data acquisition impossible to obtain by other technologies using endpoint detection. The paper discusses the technological principle of the platform regarding data acquisition and processing. Microbead-based and solution applications for the detection of diverse biomolecules, including antigens, antibodies, peptides, oligonucleotides and amplicons in small reaction volumes, are presented together with a high-content detection of autoimmune antibodies using a HEp-2 cell assay. Its adaptiveness and versatility gives VideoScan a competitive edge over other bioanalytical technologies.},
  doi      = {10.1007/10_2011_132},
  keywords = {Antibodies; Biological Assay; Computer Systems; Microscopy; Fluorescence; Microspheres; Nucleic Acid Hybridization; Pathology; Molecular; Polymerase chain reaction},
  language = {eng},
  pmid     = {22437246},
}

@Article{rodiger_nucleic_2014,
  author     = {Stefan R{\"o}diger and Claudia Liebsch and Carsten Schmidt and Werner Lehmann and Ute Resch-Genger and Uwe Schedler and Peter Schierack},
  journal    = {Microchimica Acta},
  title      = {{Nucleic acid detection based on the use of microbeads: a review}},
  year       = {2014},
  issn       = {0026-3672, 1436-5073},
  month      = aug,
  number     = {11-12},
  pages      = {1151--1168},
  volume     = {181},
  abstract   = {Microbead-based technologies represent elegant and versatile approaches for highly parallelized quantitative multiparameter assays. They also form the basis of various techniques for detection and quantification of nucleic acids and proteins. Nucleic acid-based methods include hybridization assays, solid-phase PCR, sequencing, and trapping assays. Microbead assays have been improved in the past decades and are now important tools in routine and point-of-care diagnostics as well as in life science. Its advances include low costs, low workload, high speed and high-throughput automation. The potential of microbead-based assays therefore is apparent, and commercial applications can be found in the detection and discrimination of single nucleotide polymorphism, of pathogens, and in trapping assays. This review provides an overview on microbead-based platforms for biosensing with a main focus on nucleic acid detection (including amplification strategies and on selected probe systems using fluorescent labeling). Specific sections cover chemical properties of microbeads, the coupling of targets onto solid surfaces, microbead probe systems (mainly oligonucleotide probes), microbead detection schemes (with subsections on suspension arrays, microfluidic devices, and immobilized microbeads), quantification of nucleic acids, PCR in solution and the detection of amplicons, and methods for solid-phase amplification. We discuss selected trends such as microbead-coupled amplification, heterogeneous and homogenous DNA hybridization assays, real-time assays, melting curve analysis, and digital microbead assays. We finally discuss the relevance and trends of the methods in terms of high-level multiplexed analysis and their potential in diagnosis and personalized medicine. Contains 211 references. Figure},
  doi        = {10.1007/s00604-014-1243-4},
  keywords   = {Nanochemistry; Nanotechnology; Characterization and Evaluation of Materials; Analytical Chemistry; Microengineering; Microbead; Microbead array; PCR; Microfluidic; Real-time; Multiplex},
  language   = {en},
  shorttitle = {Nucleic acid detection based on the use of microbeads},
  urldate    = {2014-09-23},
}

@Article{roediger2015chippcr,
  author   = {Stefan R{\"o}diger and Micha{\l} Burdukiewicz and Peter Schierack},
  journal  = {Bioinformatics},
  title    = {{chipPCR: an R package to pre-process raw data of amplification curves}},
  year     = {2015},
  number   = {17},
  pages    = {2900--2902},
  volume   = {31},
  abstract = {Motivation: Both the quantitative real-time polymerase chain reaction (qPCR) and quantitative isothermal amplification (qIA) are standard methods for nucleic acid quantification. Numerous real-time read-out technologies have been developed. Despite the continuous interest in amplification-based techniques, there are only few tools for pre-processing of amplification data. However, a transparent tool for precise control of raw data is indispensable in several scenarios, for example, during the development of new instruments.Results: chipPCR is an R package for the pre-processing and quality analysis of raw data of amplification curves. The package takes advantage of R{\rq}s S4 object model and offers an extensible environment. chipPCR contains tools for raw data exploration: normalization, baselining, imputation of missing values, a powerful wrapper for amplification curve smoothing and a function to detect the start and end of an amplification curve. The capabilities of the software are enhanced by the implementation of algorithms unavailable in R, such as a 5-point stencil for derivative interpolation. Simulation tools, statistical tests, plots for data quality management, amplification efficiency/quantification cycle calculation, and datasets from qPCR and qIA experiments are part of the package. Core functionalities are integrated in GUIs (web-based and standalone shiny applications), thus streamlining analysis and report generation.Availability and implementation: http://cran.r-project.org/web/packages/chipPCR. Source code: https://github.com/michbur/chipPCR.Contact: stefan.roediger@b-tu.deSupplementary information: Supplementary data are available at Bioinformatics online.},
  doi      = {10.1093/bioinformatics/btv205},
  eprint   = {http://bioinformatics.oxfordjournals.org/content/31/17/2900.full.pdf+html},
  url      = {http://bioinformatics.oxfordjournals.org/content/31/17/2900.abstract},
}

@Article{roediger_RJ_2013,
  author  = {Stefan R{\"o}diger and Alexander B{\"o}hm and Ingolf Schimke},
  journal = {The R Journal},
  title   = {{Surface Melting Curve Analysis with {R}}},
  year    = {2013},
  number  = {2},
  pages   = {37--53},
  volume  = {5},
  url     = {http://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf},
}

@Article{rover_profille_2015,
  author   = {T. Rover and R. Borges and D.A. Silva and E.F. Carvalho},
  journal  = {Forensic Science International: Genetics Supplement Series},
  title    = {{Profille mapping {DNA} laboratories overlooking the forensic field and use of quality systems}},
  year     = {2015},
  issn     = {1875-1768},
  month    = dec,
  pages    = {e409--e411},
  volume   = {5},
  doi      = {10.1016/j.fsigss.2015.09.162},
  language = {en},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1875176815302195},
  urldate  = {2016-12-22},
}

@Manual{rpart_2017,
  title  = {{{rpart}: Recursive Partitioning and Regression Trees}},
  author = {Terry Therneau and Beth Atkinson and Brian Ripley},
  note   = {R package version 4.1-11},
  year   = {2017},
  url    = {https://CRAN.R-project.org/package=rpart},
}

@Article{ruijter_2014,
  author   = {Jan M. Ruijter and Peter Lorenz and Jari M. Tuomi and Michael Hecker and Maurice J. B. van den Hoff},
  journal  = {Microchimica Acta},
  title    = {{Fluorescent-increase kinetics of different fluorescent reporters used for {qPCR} depend on monitoring chemistry, targeted sequence, type of {DNA} input and {PCR} efficiency}},
  year     = {2014},
  issn     = {0026-3672, 1436-5073},
  pages    = {1--8},
  abstract = {The analysis of quantitative {PCR} data usually does not take into account the fact that the increase in fluorescence depends on the monitoring chemistry, the input of ds-{DNA} or ss-{cDNA}, and the directionality of the targeting of probes or primers. The monitoring chemistries currently available can be categorized into six groups: (A) {DNA-binding} dyes; (B) hybridization probes; (C) hydrolysis probes; (D) {LUX} primers; (E) hairpin primers; and (F) the {QZyme} system. We have determined the kinetics of the increase in fluorescence for each of these groups with respect to the input of both ds-{DNA} and ss-{cDNA.} For the latter, we also evaluated {mRNA} and {cDNA} targeting probes or primers. This analysis revealed three situations. Hydrolysis probes and {LUX} primers, compared to {DNA-binding} dyes, do not require a correction of the observed quantification cycle. Hybridization probes and hairpin primers require a correction of -1 cycle (dubbed C-lag), while the {QZyme} system requires the C-lag correction and an efficiency-dependent C-shift correction. A {PCR} efficiency value can be derived from the relative increase in fluorescence in the exponential phase of the amplification curve for all monitoring chemistries. In case of hydrolysis probes, {LUX} primers and hairpin primers, however, this should be performed after cycle 12, and for the {QZyme} system after cycle 19, to keep the overestimation of the {PCR} efficiency below 0.5 \%. Figure The {qPCR} monitoring chemistries form six groups with distinct fluorescence kinetics. The displacement of the amplification curve depends on the chemistry, {DNA} input and probe-targeting. The observed shift in Cq values can be corrected and {PCR} efficiencies can be derived.},
  doi      = {10.1007/s00604-013-1155-8},
  keywords = {Analytical Chemistry; Characterization and Evaluation of Materials; {DNA-binding} dyes; Hybridization probes; Hydrolysis probes; Microengineering; Monitoring chemistry; Nanochemistry; Nanotechnology; {PCR} efficiency; Quantitative {PCR}},
  language = {en},
  urldate  = {2014-04-08},
}

@Article{saeys_review_2007,
  author   = {Y. Saeys and I. Inza and P. Larranaga},
  journal  = {Bioinformatics},
  title    = {{A review of feature selection techniques in bioinformatics}},
  year     = {2007},
  issn     = {1367-4803, 1460-2059},
  month    = oct,
  number   = {19},
  pages    = {2507--2517},
  volume   = {23},
  doi      = {10.1093/bioinformatics/btm344},
  language = {en},
  urldate  = {2017-08-22},
}

@PhdThesis{senkel_entwicklung_2017,
  author   = {Roy-Arne Senkel},
  school   = {Brandenburg University of Technology Cottbus - Senftenberg, Supervisor: Stefan R{\"o}diger},
  title    = {{Entwicklung eines multiparametrischen {Systems} zur {Detektion} und {Quantifizierung} von {Humanen} {Papillomviren} mittels digitaler {PCR} und einer {Mikropartikel}-basierten {Echtzeit}-{PCR}}},
  year     = {2017},
  address  = {Senftenberg},
  month    = jun,
  type     = {Bachelor},
  language = {German},
}

@Article{sheikh_2015,
  author   = {Farah Sheikh and Robert C. Lyon and Ju Chen},
  journal  = {Gene},
  title    = {{Functions of myosin light chain-2 ({MYL}2) in cardiac muscle and disease}},
  year     = {2015},
  issn     = {0378-1119},
  number   = {1},
  pages    = {14--20},
  volume   = {569},
  abstract = {Myosin light chain-2 (MYL2, also called MLC-2) is an {\textasciitilde} 19 kDa sarcomeric protein that belongs to the EF-hand calcium binding protein superfamily and exists as three major isoforms encoded by three distinct genes in mammalian striated muscle. Each of the three different MLC-2 genes (MLC-2f; fast twitch skeletal isoform, MLC-2v; cardiac ventricular and slow twitch skeletal isoform, MLC-2a; cardiac atrial isoform) has a distinct developmental expression pattern in mammals. Genetic loss-of-function studies in mice demonstrated an essential role for cardiac isoforms of MLC-2, MLC-2v and MLC-2a, in cardiac contractile function during early embryogenesis. In the adult heart, MLC-2v function is regulated by phosphorylation, which displays a specific 1`expression pattern (high in epicardium and low in endocardium) across the heart. These data along with new data from computational models, genetic mouse models, and human studies have revealed a direct role for MLC-2v phosphorylation in cross-bridge cycling kinetics, calcium-dependent cardiac muscle contraction, cardiac torsion, cardiac function and various cardiac diseases. This review focuses on the regulatory functions of MLC-2 in the embryonic and adult heart, with an emphasis on phosphorylation-driven actions of MLC-2v in adult cardiac muscle, which provide new insights into mechanisms regulating myosin cycling kinetics and human cardiac diseases.},
  doi      = {10.1016/j.gene.2015.06.027},
  keywords = {Cardiac disease; Cardiac function; Cardiac muscle; Cardiac torsion; Contraction; Heart; Myosin light chain-2 (MYL2/MLC-2); Myosin light chain kinase; Phosphorylation; Sarcomere; Ventricular myosin light chain-2},
  url      = {http://www.sciencedirect.com/science/article/pii/S0378111915007350},
  urldate  = {2015-08-13},
}

@Article{shin_deep_2016,
  author        = {Hoo-Chang Shin and Holger R. Roth and Mingchen Gao and Le Lu and Ziyue Xu and Isabella Nogues and Jianhua Yao and Daniel Mollura and Ronald M. Summers},
  title         = {{Deep {Convolutional} {Neural} {Networks} for {Computer}-{Aided} {Detection}: {CNN} {Architectures}, {Dataset} {Characteristics} and {Transfer} {Learning}}},
  year          = {2016},
  month         = feb,
  abstract      = {Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and the revival of deep CNN. CNNs enable learning data-driven, highly representative, layered hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, with 85\% sensitivity at 3 false positive per patient, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.},
  archiveprefix = {arxiv},
  eprint        = {1602.03409},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass  = {cs},
  shorttitle    = {Deep {Convolutional} {Neural} {Networks} for {Computer}-{Aided} {Detection}},
}

@Manual{shiny_2016,
  title  = {shiny: Web Application Framework for R},
  author = {Winston Chang and Joe Cheng and JJ Allaire and Yihui Xie and Jonathan McPherson},
  note   = {R package version 1.4.0},
  year   = {2019},
  url    = {https://CRAN.R-project.org/package=shiny},
}

@Article{silva_forensic_2015,
  author     = {Sarah S. Silva and C{\'a}tia Lopes and A.L. Teixeira and M.J Carneiro de Sousa and R. Medeiros},
  journal    = {Forensic Science International: Genetics},
  title      = {{Forensic {miRNA}: {Potential} biomarker for body fluids?}},
  year       = {2015},
  issn       = {1872-4973},
  month      = jan,
  pages      = {1--10},
  volume     = {14},
  doi        = {10.1016/j.fsigen.2014.09.002},
  language   = {en},
  shorttitle = {Forensic {miRNA}},
  url        = {http://linkinghub.elsevier.com/retrieve/pii/S1872497314001847},
  urldate    = {2016-12-22},
}

@Article{sing_rocr:_2005,
  author     = {Tobias Sing and Oliver Sander and Niko Beerenwinkel and Thomas Lengauer},
  journal    = {Bioinformatics},
  title      = {{{ROCR}: visualizing classifier performance in {R}}},
  year       = {2005},
  issn       = {1367-4803},
  month      = oct,
  number     = {20},
  pages      = {3940--3941},
  volume     = {21},
  abstract   = {Summary: ROCR is a package for evaluating and visualizing the performance of scoring classifiers in the statistical language R. It features over 25 performance measures that can be freely combined to create two-dimensional performance curves. Standard methods for investigating trade-offs between specific performance measures are available within a uniform framework, including receiver operating characteristic (ROC) graphs, precision/recall plots, lift charts and cost curves. ROCR integrates tightly with R's powerful graphics capabilities, thus allowing for highly adjustable plots. Being equipped with only three commands and reasonable default values for optional parameters, ROCR combines flexibility with ease of usage.Availability:http://rocr.bioinf.mpi-sb.mpg.de. ROCR can be used under the terms of the GNU General Public License. Running within R, it is platform-independent.Contact:tobias.sing@mpi-sb.mpg.de},
  doi        = {10.1093/bioinformatics/bti623},
  shorttitle = {{ROCR}},
  url        = {https://academic.oup.com/bioinformatics/article/21/20/3940/202693/ROCR-visualizing-classifier-performance-in-R},
  urldate    = {2017-07-14},
}

@Article{singer_characterization_1997,
  author   = {V. L. Singer and L. J. Jones and S. T. Yue and R. P. Haugland},
  journal  = {Analytical Biochemistry},
  title    = {{Characterization of {PicoGreen} reagent and development of a fluorescence-based solution assay for double-stranded {DNA} quantitation}},
  year     = {1997},
  issn     = {0003-2697},
  month    = jul,
  number   = {2},
  pages    = {228--238},
  volume   = {249},
  abstract = {A sensitive assay for detecting double-stranded (ds) DNA in solution is described. This assay employs a new dye, PicoGreen dsDNA quantitation reagent, which becomes intensely fluorescent upon binding nucleic acids. The brightness of this reagent is due to its high quantum yield (approximately 0.5, bound to ds calf thymus DNA) and large molar extinction coefficient (approximately 70,000 cm-1 M-1). The fluorescence enhancement of this dye upon binding dsDNA is {\textgreater} 1000-fold, with excitation and emission maxima near those of fluorescein. Unlike Hoechst 33258, PicoGreen reagent fluorescence intensity was the same upon binding to poly(dA).poly(dT) and poly(dG).poly(dC) homopolymers. The PicoGreen assay allowed the detection of 25 pg/ml dsDNA, surpassing the sensitivity achieved with Hoechst 33258 by 400-fold. The linear concentration range for DNA quantitation extended over four orders of magnitude-25 pg/ml to 1 microgram/ml-with a single dye concentration. Assay linearity was maintained even in the presence of salts, proteins, poly(ethylene glycol), urea, chloroform, ethanol, and agarose; some ionic detergents and heparin interfered. Linear DNAs yielded slightly brighter signals than supercoiled plasmids. Finally, the assay showed greater dsDNA:RNA selectivity than Hoechst 33258 in low ionic strength buffer and better dsDNA:single-stranded DNA selectivity in 1 M NaCl.},
  doi      = {10.1006/abio.1997.2177},
  keywords = {Fluorescent Dyes; Animals; DNA; Reproducibility of Results; Cattle; Organic Chemicals; Sensitivity and Specificity; Fluorometry; Indicators and Reagents; Solutions; Binding Sites; DNA; Single-Stranded; Drug Stability; Light},
  language = {eng},
  pmid     = {9212875},
}

@Article{sosnoski_melting_2002,
  author     = {Donna M. Sosnoski and Esteban Parra and Jian Ye and Kevin Hiester and Mark D. Shriver and P. A. Underhill},
  journal    = {Journal of Forensic Science},
  title      = {{Melting curve {SNP} ({McSNP}) genotyping: a useful approach for diallelic genotyping in forensic science}},
  year       = {2002},
  number     = {3},
  pages      = {593--600},
  volume     = {47},
  file       = {Ye et al. 2002.pdf:/home/tux/Work/Literatur/Zotero_DB/zotero/storage/ZWDJH4I8/sosnoski_melting_2002 - Melting Curve SNP (McSNP) Genotyping_ a Useful Approach for Diallelic Genotyping in Forensic Science.pdf:application/pdf},
  shorttitle = {Melting curve {SNP} ({McSNP}) genotyping},
  url        = {http://www.astm.org/DIGITAL_LIBRARY/JOURNALS/FORENSIC/PAGES/JFS2001183.htm},
  urldate    = {2016-12-21},
}

@Article{sparkes_validation_1996,
  author   = {R. Sparkes and C. Kimpton and S. Gilbard and P. Carne and J. Anderson and N. Oldroyd and D. Thomas and A. Urquhart and P. Gill},
  journal  = {International Journal of Legal Medicine},
  title    = {{The validation of a 7-locus multiplex {STIR} test for use in forensic casework}},
  year     = {1996},
  issn     = {0937-9827, 1437-1596},
  month    = dec,
  number   = {4},
  pages    = {195--204},
  volume   = {109},
  abstract = {PCR-based DNA typing of biological evidence is now widely used in forensic analyses due to the obvious advantages of enhanced sensitivity, the ability to distinguish discrete alleles and efficacy with degraded samples. A multiplex short tandem repeat (STR) system has been previously developed which successfully co-amplifies six STR loci HUMTH01, D21S11, D18S51, D8S1179, HUMVWF31/A and HUMFIBRA (FGA) in conjunction with the X-Y homologous gene Amelogenin. This is known as the second generation multiplex system (SGM). Detection of the PCR products is undertaken on ABD 373A or 377 automated sequencers using denaturing polyacrylamide gels coupled with fluorescent-based technology. We have evaluated this system for routine forensic use and demonstrated that the technique is robust and reproducible under conditions consistent with those encountered in a forensic environment. A total of 132 stains from simulated and actual casework were analysed, together with relevant control areas and reference samples. The success rate was high with 76\% of stains giving full profiles; we were also able to successfully detect and interpret mixtures. No mistyping was observed. A detailed examination of each of these profiles has assisted in the development of guidelines for casework interpretation. Although artefacts, stutter peaks and undenatured DNA were occasionally observed, these did not interfere with the accuracy of interpretation. In addition 38 samples, previously examined using the quadruplex system, were analysed with the SGM to enable a direct comparison to be made between the systems. The performance of the system with poor quality samples demonstrated its use as a rapid and powerful technique for individual identification.},
  doi      = {10.1007/BF01225518},
  language = {en},
  urldate  = {2016-12-04},
}

@Article{swango_developmental_2007,
  author   = {Katie L. Swango and William R. Hudlow and Mark D. Timken and Martin R. Buoncristiani},
  journal  = {Forensic Science International},
  title    = {{Developmental validation of a multiplex {qPCR} assay for assessing the quantity and quality of nuclear {DNA} in forensic samples}},
  year     = {2007},
  issn     = {0379-0738},
  month    = jul,
  number   = {1},
  pages    = {35--45},
  volume   = {170},
  abstract = {Forensic scientists are constantly searching for better, faster, and less expensive ways to increase the first-pass success rate of forensic sample analysis. Technological advances continue to increase the sensitivity of analysis methods to enable genotyping of samples containing minimal amounts of DNA, yet few tools are available that can simultaneously alert the analyst to both the presence of inhibition and level of degradation in samples prior to genotyping to allow analysts the opportunity to make appropriate modifications to their protocols and, consequently, to use less sample. Our laboratory developed a multiplex quantitative PCR assay that amplifies two human nuclear DNA target sequences of different length to assess DNA degradation and a third amplification target, a synthetic oligonucleotide internal PCR control (IPC), to allow for the assessment of PCR inhibition. We chose the two nuclear targets to provide quantity and fragment-length information relevant to the STR amplification targets commonly used for forensic genotyping. The long target (nuTH01, 170--190 bp) spans the TH01 STR locus and uses a FAM-labeled TaqMan{\textregistered} probe for detection. The short nuclear target (nuCSF, 67 bp) is directed at the upstream flanking region of the CSF1PO STR locus and is detected using a VIC-labeled TaqManMGB{\textregistered} probe. The IPC target sequence is detected using a NED-labeled TaqManMGB{\textregistered} probe. The assay was validated on the Applied Biosystems 7500 Real-Time PCR system, which is optimized for NED detection. We report the results of a developmental validation in which the assay was rigorously tested, in accordance with the current SWGDAM guidelines, for precision, sensitivity, accuracy, reproducibility, species specificity, and stability.},
  doi      = {10.1016/j.forsciint.2006.09.002},
  keywords = {CSF; Degraded DNA; DNA quantitation; Forensic Sciences; Quantitative polymerase chain reaction; TH01},
  url      = {http://www.sciencedirect.com/science/article/pii/S0379073806005767},
  urldate  = {2016-12-03},
}

@Article{templ_exploring_2012,
  author   = {Matthias Templ and Andreas Alfons and Peter Filzmoser},
  journal  = {Advances in Data Analysis and Classification},
  title    = {{Exploring incomplete data using visualization techniques}},
  year     = {2012},
  issn     = {1862-5347, 1862-5355},
  month    = apr,
  number   = {1},
  pages    = {29--47},
  volume   = {6},
  doi      = {10.1007/s11634-011-0102-y},
  language = {en},
  urldate  = {2017-08-28},
}

@Article{tolson_machine_2001,
  author  = {Edward Tolson},
  journal = {Advanced Undergraduate Project, Spring},
  title   = {{Machine {Learning} in the area of image analysis and pattern recognition}},
  year    = {2001},
  url     = {https://stuff.mit.edu/afs/athena/course/urop/profit/PDFS/EdwardTolson.pdf},
  urldate = {2017-03-02},
}

@Article{untergasser_2007,
  author   = {Andreas Untergasser and Harm Nijveen and Xiangyu Rao and Ton Bisseling and Ren{\'e} Geurts and Jack A. M. Leunissen},
  journal  = {Nucleic Acids Research},
  title    = {{{Primer3Plus}, an enhanced web interface to {Primer3}}},
  year     = {2007},
  issn     = {0305-1048, 1362-4962},
  month    = jul,
  number   = {suppl 2},
  pages    = {W71--W74},
  volume   = {35},
  abstract = {Here we present {Primer3Plus}, a new web interface to the popular Primer3 primer design program as an enhanced alternative for the {CGI}- scripts that come with Primer3. Primer3 consists of a command line program and a web interface. The web interface is one large form showing all of the possible options. This makes the interface powerful, but at the same time confusing for occasional users. Primer3Plus provides an intuitive user interface using present-day web technologies and has been developed in close collaboration with molecular biologists and technicians regularly designing primers. It focuses on the task at hand, and hides detailed settings from the user until these are needed. We also added functionality to automate specific tasks like designing primers for cloning or step-wise sequencing. Settings and designed primer sequences can be stored locally for later use. Primer3Plus supports a range of common sequence formats, such as {FASTA}. Finally, primers selected by Primer3Plus can be sent to an order form, allowing tight integration into laboratory ordering systems. Moreover, the open architecture of Primer3Plus allows easy expansion or integration of external software packages. The Primer3Plus Perl source code is available under {GPL} license from {SourceForge}. Primer3Plus is available at http://www.bioinformatics.nl/primer3plus.},
  doi      = {10.1093/nar/gkm306},
  language = {en},
  pmid     = {17485472},
  url      = {http://nar.oxfordjournals.org/content/35/suppl_2/W71},
  urldate  = {2014-09-11},
}

@Article{vennemann_mrna_2010,
  author     = {Marielle Vennemann and Antje Koppelkamm},
  journal    = {Forensic Science International},
  title      = {{{mRNA} profiling in forensic genetics {I}: {Possibilities} and limitations}},
  year       = {2010},
  issn       = {0379-0738},
  month      = dec,
  number     = {1-3},
  pages      = {71--75},
  volume     = {203},
  doi        = {10.1016/j.forsciint.2010.07.006},
  language   = {en},
  shorttitle = {{mRNA} profiling in forensic genetics {I}},
  url        = {http://linkinghub.elsevier.com/retrieve/pii/S037907381000335X},
  urldate    = {2016-12-16},
}

@Article{vera_r_parallel_2008,
  author   = {Gonzalo Vera and Ritsert C. Jansen and Remo L. Suppi},
  journal  = {BMC Bioinformatics},
  title    = {{R/parallel -- speeding up bioinformatics analysis with {R}}},
  year     = {2008},
  issn     = {1471-2105},
  month    = sep,
  pages    = {390},
  volume   = {9},
  abstract = {R is the preferred tool for statistical analysis of many bioinformaticians due in part to the increasing number of freely available analytical methods. Such methods can be quickly reused and adapted to each particular experiment. However, in experiments where large amounts of data are generated, for example using high-throughput screening devices, the processing time required to analyze data is often quite long. A solution to reduce the processing time is the use of parallel computing technologies. Because R does not support parallel computations, several tools have been developed to enable such technologies. However, these tools require multiple modications to the way R programs are usually written or run. Although these tools can finally speed up the calculations, the time, skills and additional resources required to use them are an obstacle for most bioinformaticians.},
  doi      = {10.1186/1471-2105-9-390},
  urldate  = {2017-07-09},
}

@Article{verrecas_forensic_2004,
  author     = {M Verrecas and K Knaepen and A Gilissen and J.-J Cassiman and R Decorte},
  journal    = {International Congress Series},
  title      = {{Forensic toxicology: development of an {SNP}-assay for genotyping {CYP}2D6 and {CYP}2C19 variants}},
  year       = {2004},
  issn       = {0531-5131},
  month      = apr,
  pages      = {583--585},
  volume     = {1261},
  doi        = {10.1016/S0531-5131(03)01775-8},
  language   = {en},
  shorttitle = {Forensic toxicology},
  url        = {http://linkinghub.elsevier.com/retrieve/pii/S0531513103017758},
  urldate    = {2016-12-22},
}

@Book{wickham_ggplot2_2016,
  author     = {Hadley Wickham},
  publisher  = {Springer},
  title      = {{{ggplot2}: {Elegant} {Graphics} for {Data} {Analysis}}},
  year       = {2016},
  address    = {Cham},
  edition    = {2nd ed. 2016 edition},
  isbn       = {978-3-319-24275-0},
  month      = jun,
  abstract   = {This new edition to the classic book by ggplot2 creator Hadley Wickham highlights compatibility with knitr and RStudio. ggplot2 is a data visualization package for R that helps users create data graphics, including those that are multi-layered, with ease. With ggplot2, it's easy to:produce handsome, publication-quality plots with automatic legends created from the plot specificationsuperimpose multiple layers (points, lines, maps, tiles, box plots) from different data sources with automatically adjusted common scalesadd customizable smoothers that use powerful modeling capabilities of R, such as loess, linear models, generalized additive models, and robust regressionsave any ggplot2 plot (or part thereof) for later modification or reusecreate custom themes that capture in-house or journal style requirements and that can easily be applied to multiple plotsapproach a graph from a visual perspective, thinking about how each component of the data is represented on the final plotThis book will be useful to everyone who has struggled with displaying data in an informative and attractive way. Some basic knowledge of R is necessary (e.g., importing data into R). ggplot2 is a mini-language specifically tailored for producing graphics, and you'll learn everything you need in the book. After reading this book you'll be able to produce graphics customized precisely for your problems, and you'll find it easy to get graphics out of your head and on to the screen or page.},
  language   = {English},
  shorttitle = {ggplot2},
}

@Article{williams_rattle:_2009,
  author  = {Graham J. Williams},
  journal = {The R Journal},
  title   = {{Rattle: {A} {Data} {Mining} {GUI} for {R}}},
  year    = {2009},
  month   = dec,
  number  = {2},
  pages   = {45--55},
  volume  = {1},
  url     = {http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Williams.pdf},
}

@Article{wittwer_high-resolution_2009,
  author       = {Carl T. Wittwer},
  journal      = {Human Mutation},
  title        = {{High-resolution {DNA} melting analysis: advancements and limitations}},
  year         = {2009},
  issn         = {1098-1004},
  number       = {6},
  pages        = {857--859},
  volume       = {30},
  abstract     = {Recent advances in fluorescent dyes, methods, instruments and software for {DNA} melting analysis have created versatile new tools for variant scanning and genotyping. High resolution melting analysis ({HRM} or {HRMA}) is faster, simpler, and less expensive than alternative approaches requiring separations or labeled probes. With the addition of a saturating dye before {PCR} followed by rapid melting analysis of the {PCR} products, the sensitivity of heterozygote scanning approaches 100\%. Specificity can be increased by identifying common polymorphisms with small amplicon melting, unlabeled probes or snapback primers to decrease the sequencing burden. However, some homozygotes require mixing for identification. Furthermore, different heterozygotes may produce melting curves so similar to each other that, although they clearly vary from homozygous variants, they are not differentiated from each other. Nevertheless, the experimental return for minimal effort is great. This focus issue of Human Mutation includes a concise, timely review on high resolution melting, a comparison to denaturing gradient gel electrophoresis, integration with {qPCR} for copy number assessment, combined amplicon scanning and unlabeled probe genotyping from a single melting curve, and applications to the mitochondrial genome and to {BRCA}1. Hum Mutat 30, 857--859, 2009. {\copyright} 2009 Wiley-Liss, Inc.},
  doi          = {10.1002/humu.20951},
  keywords     = {Heterozygote scanning; {HRM}; {HRMA}; snapback primer; variant detection},
  langid       = {english},
  rights       = {{\copyright} 2009 Wiley-Liss, Inc.},
  shortjournal = {Hum. Mutat.},
  shorttitle   = {High-resolution {DNA} melting analysis},
  urldate      = {2014-09-11},
}

@Article{wurmb-schwark_quantification_2002,
  author   = {N. von Wurmb-Schwark and R. Higuchi and A. P. Fenech and C. Elfstroem and C. Meissner and M. Oehmichen and G. A. Cortopassi},
  journal  = {Forensic Science International},
  title    = {{Quantification of human mitochondrial {DNA} in a real time {PCR}}},
  year     = {2002},
  issn     = {0379-0738, 1872-6283},
  month    = mar,
  number   = {1},
  pages    = {34--39},
  volume   = {126},
  abstract = {Recently, a moderately priced machine for real-time quantitative PCR has become available, the Perkin Elmer 5700. The rapid and quantitative assay of mitochondrial DNA (mtDNA) copy number is potentially useful in a variety of molecular, evolutionary and forensic fields. Using this new tool, we have evaluated the precision and reliability of the real time PCR to quantify undeleted mitochondrial genome copy number, and to determine the frequency of an age-associated deletion of 4977 base pairs in length, in 42 human iliopsoas muscle DNA samples from persons of known age.},
  doi      = {10.1016/S0379-0738(02)00026-9},
  language = {English},
  pmid     = {11955829, 11955829},
  url      = {/article/S0379-0738(02)00026-9/abstract},
  urldate  = {2016-12-16},
}

@Book{xml_book,
  author    = {Deborah Nolan and Duncan Temple Lang},
  publisher = {Springer},
  title     = {{{XML} and {Web} {Technologies} for {Data} {Sciences} with {R}}},
  year      = {2014},
  isbn      = {978-1-4614-7900-0},
  abstract  = {Web technologies are increasingly relevant to scientists working with data, for both accessing data and creating rich dynamic and interactive displays. The XML and JSON data formats are widely used in Web services, regular Web ...},
  keywords  = {Compilers; Interpreters; Programming Languages; Statistics and Computing / Statistics Programs; XML and Web Technologies for Data Sciences with R},
  url       = {http://www.springer.com/statistics/computational+statistics/book/978-1-4614-7899-7},
}

@Article{yang_application_2014,
  author   = {Yaran Yang and Bingbing Xie and Jiangwei Yan},
  journal  = {Genomics, Proteomics \& Bioinformatics},
  title    = {{Application of {Next}-generation {Sequencing} {Technology} in {Forensic} {Science}}},
  year     = {2014},
  issn     = {1672-0229},
  month    = oct,
  number   = {5},
  pages    = {190--197},
  volume   = {12},
  abstract = {Next-generation sequencing (NGS) technology, with its high-throughput capacity and low cost, has developed rapidly in recent years and become an important analytical tool for many genomics researchers. New opportunities in the research domain of the forensic studies emerge by harnessing the power of NGS technology, which can be applied to simultaneously analyzing multiple loci of forensic interest in different genetic contexts, such as autosomes, mitochondrial and sex chromosomes. Furthermore, NGS technology can also have potential applications in many other aspects of research. These include DNA database construction, ancestry and phenotypic inference, monozygotic twin studies, body fluid and species identification, and forensic animal, plant and microbiological analyses. Here we review the application of NGS technology in the field of forensic science with the aim of providing a reference for future forensics studies and practice.},
  doi      = {10.1016/j.gpb.2014.09.001},
  keywords = {Forensics; Next-generation sequencing; Degradation of DNA; Genomics},
  series   = {{Special {Issue}: {Translational} {Omics}}},
  url      = {http://www.sciencedirect.com/science/article/pii/S1672022914001053},
  urldate  = {2017-12-22},
}

@Article{zeller_pmml:_2009,
  author  = {Michael Zeller and Wen-Ching Lin Alex Guazzelli and Graham Williams},
  journal = {The R Journal},
  title   = {{{PMML}: {An} {Open} {Standard} for {Sharing} {Models}}},
  year    = {2009},
  month   = jun,
  number  = {1},
  pages   = {60--65},
  volume  = {1},
  url     = {http://journal.r-project.org/archive/2009-1/RJournal_2009-1_Guazzelli+et+al.pdf},
}

@Book{zielesny_curve_2011,
  author    = {Achim Zielesny},
  editor    = {Janusz Kacprzyk and Lakhmi C. Jain},
  publisher = {Springer Berlin Heidelberg},
  title     = {{From {Curve} {Fitting} to {Machine} {Learning}}},
  year      = {2011},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-21279-6 978-3-642-21280-2},
  series    = {{Intelligent {Systems} {Reference} {Library}}},
  volume    = {18},
  doi       = {10.1007/978-3-642-21280-2},
  editor    = {Janusz Kacprzyk and Lakhmi C. Jain},
  urldate   = {2017-06-25},
}

@Manual{Seibelt_xray,
  title  = {{{xray}: X Ray Vision on your Datasets}},
  author = {Pablo Seibelt},
  note   = {R package version 0.2},
  year   = {2017},
  url    = {https://CRAN.R-project.org/package=xray},
}

@Article{karsai_evaluation_2002,
  author   = {Albert Karsai and Sabine M{\"u}ller and Stefan Platz and Marie-Theres Hauser},
  journal  = {BioTechniques},
  title    = {{Evaluation of a {Homemade} {SYBR}{\textregistered} {Green} {I} {Reaction} {Mixture} for {Real}-{Time} {PCR} {Quantification} of {Gene} {Expression}}},
  year     = {2002},
  issn     = {0736-6205},
  month    = apr,
  number   = {4},
  pages    = {790--796},
  volume   = {32},
  abstract = {Real-time PCR is an accurate method that can be used for the quantification of specific DNA molecules. Here we provide a protocol for SYBR{\textregistered} Green I in real-time PCR applications using plastic reaction tubes. We report that SYBR Green I is alkali labile and once degraded inhibits the PCR. In our optimized protocol, diluted aliquots of SYBR Green I remain stable for at least two weeks. We also evaluated different cDNA synthesis protocols for the quantification of multiple genes from the same cDNA preparation. The best result was obtained with cDNAs synthesized by OmniScript\texttrademark reverse transcriptase from 2.5 \mug total RNA using oligo d(T)18 primers. The cDNA reactions could be diluted 1:25, allowing the quantification of up to 125 different medium expressed genes of Arabidopsis. Extension times ranged between 20 and 40 bp/s for accurate quantification of PCR products up to approximately 400 bp in the Rotor-Gene 2000 system. Using our optimized real-time PCR protocol, the reproducibility and amplification efficiency was high and comparable to a commercially available SYBR Green I kit. Furthermore, the sensitivity allowed us to quantify 10--20 copies of mRNA and dsDNA. Thus, the protocol eliminates the need for expensive pre-made kits.},
  pmcid    = {PMC4353838},
  pmid     = {11962601},
  url      = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4353838/},
  urldate  = {2018-01-10},
}

@Article{wickham_testthat_2011,
  author  = {Hadley Wickham},
  journal = {The R Journal},
  title   = {{testthat: {Get} {Started} with {Testing}}},
  year    = {2011},
  month   = jun,
  number  = {1},
  pages   = {5--10},
  volume  = {3},
  url     = {http://journal.r-project.org/archive/2011/RJ-2011-002/index.html},
}

@Book{myers_art_2004,
  author    = {Glenford J. Myers and Tom Badgett and Todd M. Thomas and Corey Sandler},
  publisher = {John Wiley \& Sons},
  title     = {{The art of software testing}},
  year      = {2004},
  address   = {Hoboken, N.J},
  edition   = {2nd ed},
  isbn      = {978-0-471-46912-4},
  keywords  = {Computer software; Debugging in computer science; Testing},
}

@Article{kemperman_mircomp-shiny:_2017,
  author     = {Lauren Kemperman and Matthew N. McCall},
  journal    = {F1000Research},
  title      = {{{miRcomp}-{Shiny}: {Interactive} assessment of {qPCR}-based {microRNA} quantification and quality control algorithms}},
  year       = {2017},
  issn       = {2046-1402},
  month      = nov,
  pages      = {2046},
  volume     = {6},
  language   = {en},
  shorttitle = {{miRcomp}-{Shiny}},
  url        = {https://f1000research.com/articles/6-2046/v1},
  urldate    = {2017-12-10},
}

@Book{de_vries_r_2012,
  author    = {Andrie {De Vries} and Joris Meys},
  publisher = {John Wiley \& Sons},
  title     = {{R for {Dummies}}},
  year      = {2012},
  edition   = {2},
  isbn      = {978-1-119-96284-7},
}

@InProceedings{luo_learning_2010,
  author    = {Ping Luo and Liang Lin and Hongyang Chao},
  booktitle = {{European {Conference} on {Computer} {Vision}}},
  title     = {{Learning shape detector by quantizing curve segments with multiple distance metrics}},
  year      = {2010},
  pages     = {342--355},
  publisher = {Springer},
}

@Book{kitchin2014,
  author    = {Rob Kitchin},
  publisher = {SAGE Publications},
  title     = {{The data revolution : big data, open data, data infrastructures \& their consequences}},
  year      = {2014},
  address   = {Los Angeles, California London},
  isbn      = {1446287483},
}

@Article{rote_computing_1991,
  author   = {G{\"u}nter Rote},
  journal  = {Information Processing Letters},
  title    = {{Computing the minimum {Hausdorff} distance between two point sets on a line under translation}},
  year     = {1991},
  issn     = {0020-0190},
  month    = may,
  number   = {3},
  pages    = {123--127},
  volume   = {38},
  abstract = {Given two sets of points on a line, we want to translate one of them so that their Hausdorff distance (the maximum of the distances from a point in any of the sets to the nearest point in the other set) is as small as possible. We present an optimal O(n log n) algorithm for this problem.},
  doi      = {10.1016/0020-0190(91)90233-8},
  keywords = {Computational geometry; Hausdorff distance; pattern matching; pattern recognition},
  url      = {http://www.sciencedirect.com/science/article/pii/0020019091902338},
  urldate  = {2018-02-12},
}

@Article{nolan_2006,
  author  = {Tania Nolan and Rebecca E Hands and Stephen A Bustin},
  journal = {Nature Protocols},
  title   = {{Quantification of {mRNA} using real-time {RT}-{PCR}}},
  year    = {2006},
  month   = nov,
  pages   = {1559},
  volume  = {1},
  doi     = {10.1038/nprot.2006.236},
}

@Article{isaac_essentials_2009,
  author     = {Peter G. Isaac},
  journal    = {Annals of Botany},
  title      = {{Essentials of nucleic acid analysis: a robust approach}},
  year       = {2009},
  issn       = {1095-8290, 0305-7364},
  month      = aug,
  number     = {2},
  pages      = {vi--vi},
  volume     = {104},
  doi        = {10.1093/aob/mcp135},
  language   = {en},
  shorttitle = {Essentials of nucleic acid analysis},
  urldate    = {2017-09-05},
}

@Article{reshef_detecting_2011,
  author  = {David N. Reshef and Yakir A. Reshef and Hilary K. Finucane and Sharon R. Grossman and Gilean McVean and Peter J. Turnbaugh and Eric S. Lander and Michael Mitzenmacher and Pardis C. Sabeti},
  journal = {science},
  title   = {{Detecting novel associations in large data sets}},
  year    = {2011},
  number  = {6062},
  pages   = {1518--1524},
  volume  = {334},
}

@Article{walsh_correct_2015,
  author     = {Ian Walsh and Gianluca Pollastri and Silvio C. E. Tosatto},
  journal    = {Briefings in Bioinformatics},
  title      = {{Correct machine learning on protein sequences: a peer-reviewing perspective}},
  year       = {2015},
  issn       = {1467-5463, 1477-4054},
  month      = sep,
  pages      = {bbv082},
  abstract   = {Machine learning methods are becoming increasingly popular to predict protein features from sequences. Machine learning in bioinformatics can be powerful but carries also the risk of introducing unexpected biases, which may lead to an overestimation of the performance. This article espouses a set of guidelines to allow both peer reviewers and authors to avoid common machine learning pitfalls. Understanding biology is necessary to produce useful data sets, which have to be large and diverse. Separating the training and test process is imperative to avoid over-selling method performance, which is also dependent on several hidden parameters. A novel predictor has always to be compared with several existing methods, including simple baseline strategies. Using the presented guidelines will help nonspecialists to appreciate the critical issues in machine learning.},
  doi        = {10.1093/bib/bbv082},
  keywords   = {machine learning; protein sequence; posttranslational modification; predictor; training; evaluation},
  language   = {en},
  pmid       = {26411473},
  shorttitle = {Correct machine learning on protein sequences},
  url        = {http://bib.oxfordjournals.org/content/early/2015/09/25/bib.bbv082},
  urldate    = {2016-05-13},
}

@InCollection{mcfadden_conditional_1974,
  author    = {Daniel L. McFadden},
  booktitle = {{Frontiers in {Economics}}},
  publisher = {New York: Academic Press},
  title     = {{Conditional {Logit} {Analysis} of {Qualitative} {Choice} {Behavior}}},
  year      = {1974},
  pages     = {105--142},
  series    = {{P. {Zarembka} (ed.)}},
  volume    = {Frontiers in Economics},
  url       = {https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf},
  urldate   = {2018-03-03},
}

@Article{tichopad_standardized_2003,
  author   = {Ales Tichopad and Michael Dilger and Gerhard Schwarz and Michael W Pfaffl},
  journal  = {Nucleic acids research},
  title    = {{Standardized determination of real-time {PCR} efficiency from a single reaction set-up}},
  year     = {2003},
  issn     = {1362-4962},
  month    = oct,
  number   = {20},
  pages    = {e122},
  volume   = {31},
  abstract = {We propose a computing method for the estimation of real-time PCR amplification efficiency. It is based on a statistic delimitation of the beginning of exponentially behaving observations in real-time PCR kinetics. PCR ground fluorescence phase, non-exponential and plateau phase were excluded from the calculation process by separate mathematical algorithms. We validated the method on experimental data on multiple targets obtained on the LightCycler platform. The developed method yields results of higher accuracy than the currently used method of serial dilutions for amplification efficiency estimation. The single reaction set-up estimation is sensitive to differences in starting concentrations of the target sequence in samples. Furthermore, it resists the subjective influence of researchers, and the estimation can therefore be fully instrumentalized.},
  keywords = {Animals; DNA; Fluorescence; Plasmids; Reference Standards; Polymerase chain reaction; Reproducibility of Results; Algorithms; Cattle; Genes; sry; Organic Chemicals; Sensitivity and Specificity},
  language = {eng},
  pmcid    = {PMC219490},
  pmid     = {14530455},
}

@Article{higuchi1993,
  author     = {Russell Higuchi and Carita Fockler and Gavin Dollinger and Robert Watson},
  journal    = {Nature Biotechnology},
  title      = {Kinetic {PCR} Analysis: {Real}-time Monitoring of {DNA} Amplification Reactions},
  year       = {1993},
  issn       = {1546-1696},
  month      = sep,
  number     = {9},
  pages      = {1026--1030},
  abstract   = {We describe a simple, quantitative assay for any amplifiable DNA sequence that uses a video camera to monitor multiple polymerase chain reactions (PCRs) simultaneously over the course of thermocycling. The video camera detects the accumulation of double-stranded DNA (dsDNA) in each PCR using the increase in the fluorescence of ethidium bromide (EtBr) that results from its binding duplex DNA. The kinetics of fluorescence accumulation during thermocycling are directly related to the starting number of DNA copies. The fewer cycles necessary to produce a detectable fluorescence, the greater the number of target sequences. Results obtained with this approach indicate that a kinetic approach to PCR analysis can quantitate DNA sensitively, selectively and over a large dynamic range. This approach also provides a means of determining the effect of different reaction conditions on the efficacy of the amplification and so can provide insight into fundamental PCR processes.},
  copyright  = {1993 Nature Publishing Group},
  doi        = {10.1038/nbt0993-1026},
  language   = {en},
  shorttitle = {Kinetic {PCR} {Analysis}},
}

@Article{rutledge2003,
  author   = {R. G. Rutledge and C. C{\^o}t{\'e}},
  journal  = {Nucleic Acids Research},
  title    = {Mathematics of quantitative kinetic {PCR} and the application of standard curves},
  year     = {2003},
  issn     = {0305-1048},
  month    = aug,
  number   = {16},
  pages    = {e93},
  abstract = {Fluorescent monitoring of DNA amplification is the basis of real-time PCR, from which target DNA concentration can be determined from the fractional cycle at which a threshold amount of amplicon DNA is produced. Absolute quantification can be achieved using a standard curve constructed by amplifying known amounts of target DNA. In this study, the mathematics of quantitative PCR are examined in detail, from which several fundamental aspects of the threshold method and the application of standard curves are illustrated. The construction of five replicate standard curves for two pairs of nested primers was used to examine the reproducibility and degree of quantitative variation using SYBER(R) Green I fluorescence. Based upon this analysis the application of a single, well- constructed standard curve could provide an estimated precision of \pm6--21\%, depending on the number of cycles required to reach threshold. A simplified method for absolute quantification is also proposed, in which quantitative scale is determined by DNA mass at threshold.},
  pmcid    = {PMC169985},
  pmid     = {12907745},
}

@Book{westermeier2004,
  author    = {Reiner Westermeier},
  publisher = {Wiley-Blackwell},
  title     = {Electrophoresis in {Practice}: {A} {Guide} to {Methods} and {Applications} of {DNA} and {Protein} {Separations}, {Fourth} {Edition}},
  year      = {2004},
  isbn      = {978-3-527-31181-1 978-3-527-60346-6},
  doi       = {10.1002/3527603468},
}

@Article{van_oorschot_forensic_2010,
  author     = {Roland AH van Oorschot and Kaye N Ballantyne and R John Mitchell},
  journal    = {Investigative Genetics},
  title      = {Forensic trace {DNA}: a review},
  year       = {2010},
  issn       = {2041-2223},
  number     = {1},
  pages      = {14},
  abstract   = {DNA analysis is frequently used to acquire information from biological material to aid enquiries associated with criminal offences, disaster victim identification and missing persons investigations. As the relevance and value of DNA profiling to forensic investigations has increased, so too has the desire to generate this information from smaller amounts of DNA. Trace DNA samples may be defined as any sample which falls below recommended thresholds at any stage of the analysis, from sample detection through to profile interpretation, and can not be defined by a precise picogram amount. Here we review aspects associated with the collection, DNA extraction, amplification, profiling and interpretation of trace DNA samples. Contamination and transfer issues are also briefly discussed within the context of trace DNA analysis. Whilst several methodological changes have facilitated profiling from trace samples in recent years it is also clear that many opportunities exist for further improvements.},
  doi        = {10.1186/2041-2223-1-14},
  language   = {en},
  shorttitle = {Forensic trace {DNA}},
}

@Article{kruppa_probability_2014,
  author     = {Jochen Kruppa and Yufeng Liu and G{\'e}rard Biau and Michael Kohler and Inke R. K{\"o}nig and James D. Malley and Andreas Ziegler},
  journal    = {Biometrical Journal},
  title      = {Probability estimation with machine learning methods for dichotomous and multicategory outcome: {Theory}},
  year       = {2014},
  issn       = {1521-4036},
  month      = jul,
  number     = {4},
  pages      = {534--563},
  abstract   = {Probability estimation for binary and multicategory outcome using logistic and multinomial logistic regression has a long-standing tradition in biostatistics. However, biases may occur if the model is misspecified. In contrast, outcome probabilities for individuals can be estimated consistently with machine learning approaches, including k-nearest neighbors (k-NN), bagged nearest neighbors (b-NN), random forests (RF), and support vector machines (SVM). Because machine learning methods are rarely used by applied biostatisticians, the primary goal of this paper is to explain the concept of probability estimation with these methods and to summarize recent theoretical findings. Probability estimation in k-NN, b-NN, and RF can be embedded into the class of nonparametric regression learning machines; therefore, we start with the construction of nonparametric regression estimates and review results on consistency and rates of convergence. In SVMs, outcome probabilities for individuals are estimated consistently by repeatedly solving classification problems. For SVMs we review classification problem and then dichotomous probability estimation. Next we extend the algorithms for estimating probabilities using k-NN, b-NN, and RF to multicategory outcomes and discuss approaches for the multicategory probability estimation problem using SVM. In simulation studies for dichotomous and multicategory dependent variables we demonstrate the general validity of the machine learning methods and compare it with logistic regression. However, each method fails in at least one simulation scenario. We conclude with a discussion of the failures and give recommendations for selecting and tuning the methods. Applications to real data and example code are provided in a companion article (doi:10.1002/bimj.201300077).},
  doi        = {10.1002/bimj.201300068},
  keywords   = {Bagged nearest neighbor; Nonparametric regression; Probability estimation; Random forest; Support vector machine},
  language   = {en},
  shorttitle = {Probability estimation with machine learning methods for dichotomous and multicategory outcome},
}

@Article{PCRedux_citation,
  author  = {Stefan R\"{o}diger and Micha\l{} Burdukiewicz and Andrej-Nikolai Spiess and Konstantin A. Blagodatskikh},
  journal = {Comprehensive R Archive Network},
  title   = {PCRedux: Quantitative Polymerase Chain Reaction (qPCR) Data Mining and Machine Learning Helper Tool},
  year    = {2018},
  number  = {R package version 0.2.6-2},
  url     = {https://CRAN.R-project.org/package=PCRedux},
}

@Manual{covr,
  title  = {covr: Test Coverage for Packages},
  author = {Jim Hester},
  note   = {R package version 3.1.0},
  year   = {2018},
  url    = {https://CRAN.R-project.org/package=covr},
}

@Article{burdukiewicz_algorithms_2018,
  author   = {Burdukiewicz, Micha\l{} and Spiess, Andrej-Nikolai and Blagodatskikh, Konstantin A. and Lehmann, Werner and Schierack, Peter and R\"{o}diger, Stefan},
  journal  = {Biomolecular Detection and Quantification},
  title    = {Algorithms for automated detection of hook effect-bearing amplification curves},
  year     = {2018},
  issn     = {2214-7535},
  month    = oct,
  abstract = {Amplification curves from quantitative Real-Time PCR experiments typically exhibit a sigmoidal shape. They can roughly be divided into a ground or baseline phase, an exponential amplification phase, a linear phase and finally a plateau phase, where in the latter, the PCR product concentration no longer increases. Nevertheless, in some cases the plateau phase displays a negative trend, e.g. in hydrolysis probe assays. This cycle-to-cycle fluorescence decrease is commonly referred to in the literature as the hook effect. Other detection chemistries also exhibit this negative trend, however the underlying molecular mechanisms are different. In this study we present two approaches to automatically detect hook effect-like curvatures based on linear (hookreg) and nonlinear regression (hookregNL). As the hook effect is typical for qPCR data, both algorithms can be employed for the automated identification of regular structured qPCR curves. Therefore, our algorithms streamline quality control, but can also be used for assay optimization or machine learning.},
  doi      = {10.1016/j.bdq.2018.08.001},
  keywords = {RDML, Automation, EvaGreen, Hook effect, Linear, Nonlinear, QPCR, SybrGreen, TaqMan},
  url      = {http://www.sciencedirect.com/science/article/pii/S221475351730219X},
  urldate  = {2018-10-17},
}

@Article{nassirpour_identification_2014,
  author     = {Nassirpour, Rounak and Mathur, Sachin and Gosink, Mark M. and Li, Yizheng and Shoieb, Ahmed M. and Wood, Joanna and O'Neil, Shawn P. and Homer, Bruce L. and Whiteley, Laurence O.},
  journal    = {BMC Genomics},
  title      = {Identification of tubular injury {microRNA} biomarkers in urine: comparison of next-generation sequencing and {qPCR}-based profiling platforms},
  year       = {2014},
  issn       = {1471-2164},
  month      = jun,
  note       = {00000},
  pages      = {485},
  volume     = {15},
  abstract   = {MicroRNAs (miRNAs) are small, non-coding RNAs that regulate protein levels post-transcriptionally. miRNAs play important regulatory roles in many cellular processes and have been implicated in several diseases. Recent studies have reported significant levels of miRNAs in a variety of body fluids, raising the possibility that miRNAs could serve as useful biomarkers. Next-generation sequencing (NGS) is increasingly employed in biomedical investigations. Although concordance between this platform and qRT-PCR based assays has been reported in high quality specimens, information is lacking on comparisons in biofluids especially urine. Here we describe the changes in miRNA expression patterns in a rodent model of renal tubular injury (gentamicin). Our aim is to compare RNA sequencing and qPCR based miRNA profiling in urine specimen from control and rats with confirmed tubular injury.},
  doi        = {10.1186/1471-2164-15-485},
  keywords   = {Next-generation sequencing, Gentamicin, Kidney injury, miRNA, NGS, qRT-PCR, Small RNA, TruSeq, Urine},
  shorttitle = {Identification of tubular injury {microRNA} biomarkers in urine},
  urldate    = {2018-04-10},
}

@Article{cristino_deep_2011,
  author   = {Cristino, Alexandre S. and Tanaka, Erica D. and Rubio, Mercedes and Piulachs, Maria-Dolors and Belles, Xavier},
  journal  = {PLOS ONE},
  title    = {Deep {Sequencing} of {Organ}- and {Stage}-{Specific} {microRNAs} in the {Evolutionarily} {Basal} {Insect} {Blattella} germanica ({L}.) ({Dictyoptera}, {Blattellidae})},
  year     = {2011},
  issn     = {1932-6203},
  month    = apr,
  note     = {00000},
  number   = {4},
  pages    = {e19350},
  volume   = {6},
  abstract = {Background microRNAs (miRNAs) have been reported as key regulators at post-transcriptional level in eukaryotic cells. In insects, most of the studies have focused in holometabolans while only recently two hemimetabolans (Locusta migratoria and Acyrthosiphon pisum) have had their miRNAs identified. Therefore, the study of the miRNAs of the evolutionarily basal hemimetabolan Blattella germanica may provide valuable insights on the structural and functional evolution of miRNAs. Methodology/Principal Findings Small RNA libraries of the cockroach B. germanica were built from the whole body of the last instar nymph, and the adult ovaries. The high throughput Solexa sequencing resulted in approximately 11 and 8 million reads for the whole-body and ovaries, respectively. Bioinformatic analyses identified 38 known miRNAs as well as 11 known miRNA*s. We also found 70 miRNA candidates conserved in other insects and 170 candidates specific to B. germanica. The positive correlation between Solexa data and real-time quantitative PCR showed that number of reads can be used as a quantitative approach. Five novel miRNA precursors were identified and validated by PCR and sequencing. Known miRNAs and novel candidates were also validated by decreasing levels of their expression in dicer-1 RNAi knockdown individuals. The comparison of the two libraries indicates that whole-body nymph contain more known miRNAs than ovaries, whereas the adult ovaries are enriched with novel miRNA candidates. Conclusions/Significance Our study has identified many known miRNAs and novel miRNA candidates in the basal hemimetabolan insect B. germanica, and most of the specific sequences were found in ovaries. Deep sequencing data reflect miRNA abundance and dicer-1 RNAi assay is shown to be a reliable method for validation of novel miRNAs.},
  doi      = {10.1371/journal.pone.0019350},
  keywords = {MicroRNAs, cDNA libraries, Ovaries, RNA sequencing, Sequence alignment, Sequence assembly tools, Sequence databases, Small interfering RNAs},
  language = {en},
  url      = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0019350},
  urldate  = {2018-04-07},
}

@Article{gunther_neuralnet:_2010,
  author  = {G\"{u}nther, Frauke and Fritsch, Stefan},
  journal = {The R Journal},
  title   = {neuralnet: {Training} of neural networks},
  year    = {2010},
  month   = jun,
  number  = {1},
  pages   = {30--38},
  volume  = {2},
  url     = {http://journal.r-project.org/archive/2010-1/RJournal_2010-1_Guenther+Fritsch.pdf},
}

@Article{fernandez-delgado_we_2014,
  author   = {Fernandez-Delgado, Manuel and Cernadas, Eva and Barro, Senen and Amorim, Dinani},
  journal  = {Journal of Machine Learning Research},
  title    = {{Do we Need Hundreds of Classifiers to Solve Real World Classification Problems?}},
  year     = {2014},
  pages    = {3133--3181},
  volume   = {15},
  abstract = {We evaluate 179 classifiers arising from 17 families (discriminant analysis, Bayesian, neural networks, support vector machines, decision trees, rule-based classifiers, boosting, bagging, stacking, random forests and other ensembles, generalized linear models, nearestneighbors, partial least squares and principal component regression, logistic and multinomial regression, multiple adaptive regression splines and other methods), implemented in Weka, R (with and without the caret package), C and Matlab, including all the relevant classifiers available today. We use 121 data sets, which represent the whole UCI data base (excluding the large-scale problems) and other own real problems, in order to achieve significant conclusions about the classifier behavior, not dependent on the data set collection. The classifiers most likely to be the bests are the random forest (RF) versions, the best of which (implemented in R and accessed via caret) achieves 94.1\% of the maximum accuracy overcoming 90\% in the 84.3\% of the data sets. However, the difference is not statistically significant with the second best, the SVM with Gaussian kernel implemented in C using LibSVM, which achieves 92.3\% of the maximum accuracy. A few models are clearly better than the remaining ones: random forest, SVM with Gaussian and polynomial kernels, extreme learning machine with Gaussian kernel, C5.0 and avNNet (a committee of multi-layer perceptrons implemented in R with the caret package). The random forest is clearly the best family of classifiers (3 out of 5 bests classifiers are RF), followed by SVM (4 classifiers in the top-10), neural networks and boosting ensembles (5 and 3 members in the top-20, respectively).},
  language = {en},
  url      = {http://jmlr.org/papers/v15/delgado14a.html},
}

@Article{maher_clinical_2014,
  author   = {Maher, Robert L. and Hanlon, Joseph T. and Hajjar, Emily R.},
  journal  = {Expert opinion on drug safety},
  title    = {Clinical {Consequences} of {Polypharmacy} in {Elderly}},
  year     = {2014},
  issn     = {1474-0338},
  month    = jan,
  number   = {1},
  volume   = {13},
  abstract = {Introduction
Polypharmacy, defined as the use of multiple drugs or more than are medically necessary, is a growing concern for older adults.

Areas Covered
We present information about; 1.) Prevalence of polypharmacy and unnecessary medication use. ; 2.) Negative Consequences of Polypharmacy; 3.) Interventions to improve polypharmacy.

Expert Opinion
International research shows that polypharmacy is common in older adults with the highest number of drugs taken by those residing in nursing homes. Nearly 50\% of older adults take one or more medications that are not medically necessary. Research has clearly established a strong relationship between polypharmacy and negative clinical consequences. Moreover, well designed inter-professional (often incuding clinical pharmacist) intervention studies that focus on enrolling high risk older patients with polypharmacy have shown that they can be effective in improving the overall quality of prescribing with mixed results on distal health outcomes.},
  doi      = {10.1517/14740338.2013.827660},
  pmcid    = {PMC3864987},
  pmid     = {24073682},
  url      = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3864987/},
  urldate  = {2019-04-17},
}

@Article{caudle_prn_2019,
  author     = {Caudle, Kelly E. and Gammal, Roseann S. and Karnes, Jason H. and Afanasjeva, Janna and Anderson, Keri C. and Barreto, Erin F. and Beavers, Craig and Bhat, Shubha and Birrer, Kara L. and Chahine, Elias B. and Ensor, Christopher R. and Flowers, Stephanie A. and Formea, Christine M. and George, Jomy M. and Gosser, Rena A. and Hebert, Mary F. and Karaoui, Lamis R. and Kolpek, Jimmi Hatton and Lee, James C. and Leung, Jonathan G. and Maldonado, Angela Q. and Minze, Molly G. and Pulk, Rebecca A. and Shelton, Chasity M. and Sheridan, Maria and Smith, Michael A. and Soefje, Scott and Tellez-Corrales, Eglis and Walko, Christine M. and Cavallari, Larisa H.},
  journal    = {JACCP: JOURNAL OF THE AMERICAN COLLEGE OF CLINICAL PHARMACY},
  title      = {{PRN} {OPINION} {PAPER}: {Application} of precision medicine across pharmacy specialty areas},
  year       = {2019},
  issn       = {2574-9870},
  number     = {3},
  pages      = {288--302},
  volume     = {2},
  abstract   = {Clinical pharmacists have been incorporating precision medicine into practice for decades. Drug selection and dosing based on patient-specific clinical factors such as age, weight, renal function, drug interactions, plasma drug concentrations, and diet are expected as part of routine clinical practice. Newer concepts of precision medicine such as pharmacogenomics have recently been implemented into clinical care, while other concepts such as epigenetics and pharmacomicrobiomics still predominantly exist in the research area but clinical translation is expected in the future. The purpose of this paper is to describe current and emerging aspects of precision medicine as it relates to clinical pharmacy across a variety of specialty areas of practice, with perspectives from the American College of Clinical Pharmacy Practice and Research Network membership.},
  doi        = {10.1002/jac5.1107},
  keywords   = {pharmacogenomics, pharmacotherapy, precision medicine},
  language   = {en},
  shorttitle = {{PRN} {OPINION} {PAPER}},
  urldate    = {2019-10-15},
}

@Article{rao_6-week_2018,
  author     = {Rao, Prema S. and Endicott, Ryan and Mullins, Randy and Rao, U. Subrahmanyeswara},
  journal    = {The Pharmacogenomics Journal},
  title      = {A 6-week laboratory research rotation in pharmacogenomics: a model for preparing pharmacy students to practice precision medicine},
  year       = {2018},
  issn       = {1470-269X, 1473-1150},
  month      = jul,
  number     = {4},
  pages      = {601--608},
  volume     = {18},
  abstract   = {Comparison of human genome sequences from different individuals has unraveled that genes involved in the drug efficacy and metabolism are polymorphic, harboring mutations, splicing variations and other alterations. These data provide a reasonable explanation for the inter-individual variations observed in drug therapy. Thus, a detailed molecular analysis and an in-depth knowledge of these genes is a prerequisite to practice pharmacogenomics-based medicine. We have introduced a 6-week laboratory research rotation to train students in the expression analysis of different pharmacogenes combined with bioinformatics tools. Students were first introduced to the bioinformatics tools to identify appropriate DNA primers to amplify specific pharmacogenes from the laboratory cancer cell lines. The amplified DNA fragments were sequenced. Finally, students were trained in bioinformatics tools to establish the identity of these DNA sequences. The possible implications of this laboratory training in developing problem-solving skills needed in the implementation of pharmacogenomics knowledge in the clinic, are discussed.},
  doi        = {10.1038/s41397-018-0019-3},
  language   = {en},
  shorttitle = {A 6-week laboratory research rotation in pharmacogenomics},
  url        = {http://www.nature.com/articles/s41397-018-0019-3},
  urldate    = {2019-10-15},
}

@Article{mestdagh_long_2016,
  author    = {Mestdagh, Pieter and Lefever, Steve and Volders, Pieter-Jan and Derveaux, Stefaan and Hellemans, Jan and Vandesompele, Jo},
  journal   = {Scientific Data},
  title     = {Long non-coding {RNA} expression profiling in the {NCI}60 cancer cell line panel using high-throughput {RT}-{qPCR}},
  year      = {2016},
  issn      = {2052-4463},
  month     = jul,
  number    = {1},
  pages     = {1--6},
  volume    = {3},
  abstract  = {Long non-coding RNAs (lncRNAs) form a new class of RNA molecules implicated in various aspects of protein coding gene expression regulation. To study lncRNAs in cancer, we generated expression profiles for 1707 human lncRNAs in the NCI60 cancer cell line panel using a high-throughput nanowell RT-qPCR platform. We describe how qPCR assays were designed and validated and provide processed and normalized expression data for further analysis. Data quality is demonstrated by matching the lncRNA expression profiles with phenotypic and genomic characteristics of the cancer cell lines. This data set can be integrated with publicly available omics and pharmacological data sets to uncover novel associations between lncRNA expression and mRNA expression, miRNA expression, DNA copy number, protein coding gene mutation status or drug response 
                
                  
                    
                    
                    
                  
                
               Machine-accessible metadata file describing the reported data (ISA-Tab format)},
  copyright = {2016 The Author(s)},
  doi       = {10.1038/sdata.2016.52},
  language  = {en},
  url       = {https://www.nature.com/articles/sdata201652},
  urldate   = {2019-10-19},
}

@Article{giuliano_use_2017,
  author     = {Giuliano, Kenneth A. and Wachi, Shinichiro and Drew, Lawrence and Dukovski, Danijela and Green, Olivia and Bastos, Cecilia and Cullen, Matthew D. and Hauck, Sheila and Tait, Bradley D. and Munoz, Benito and Lee, Po-Shun and Miller, John Preston},
  journal    = {SLAS DISCOVERY: Advancing Life Sciences R\&D},
  title      = {Use of a {High}-{Throughput} {Phenotypic} {Screening} {Strategy} to {Identify} {Amplifiers}, a {Novel} {Pharmacological} {Class} of {Small} {Molecules} {That} {Exhibit} {Functional} {Synergy} with {Potentiators} and {Correctors}:},
  year       = {2017},
  month      = sep,
  abstract   = {Cystic fibrosis (CF) is a lethal genetic disorder caused by mutation of the cystic fibrosis transmembrane conductance regulator (CFTR) gene. Despite recent grou...},
  doi        = {10.1177/2472555217729790},
  language   = {en},
  shorttitle = {Use of a {High}-{Throughput} {Phenotypic} {Screening} {Strategy} to {Identify} {Amplifiers}, a {Novel} {Pharmacological} {Class} of {Small} {Molecules} {That} {Exhibit} {Functional} {Synergy} with {Potentiators} and {Correctors}},
  urldate    = {2019-10-19},
}

@Article{meyer_high_2017,
  author    = {Meyer, Hermann-Josef and Turincio, Rebecca and Ng, Shirley and Li, Juan and Wilson, Blair and Chan, Pamela and Zak, Mark and Reilly, Dorothea and Beresini, Maureen H. and Wong, Athena W.},
  journal   = {Biotechnology Progress},
  title     = {High throughput screening identifies novel, cell cycle-arresting small molecule enhancers of transient protein expression},
  year      = {2017},
  issn      = {1520-6033},
  number    = {6},
  pages     = {1579--1588},
  volume    = {33},
  abstract  = {Transient gene expression in mammalian cells is an efficient process for producing recombinant proteins for various research applications to support large molecule therapeutics development. For the first time, we report a high throughput small molecule (SM) screen to identify novel compounds that increase antibody titers after polyethylenimine (PEI) transient transfection of a HEK293 cell line. After screening 31,413 SMs in a 50 \muL scaled-down process, we validated 164 SMs to improve yields by up to twofold. The titer increase mediated by the SMs varied for different antibodies. SM dose optimizations resulted in almost threefold higher titers. The top 2, structurally distinct SM hits, increased antibody titers more than twofold in a 1 mL production process. Averaged across three antibodies of different expression levels, the compounds enhanced transient productivity by ~80\%. Intriguingly, both compounds arrested cells in the G2/M cell cycle phase leading to a decrease in growth and nutrient consumption, while elevating titer, nuclear plasmid DNA (pDNA) copy numbers, and mRNA levels. \textcopyright 2017 American Institute of Chemical Engineers Biotechnol. Prog., 3:1579--1588, 2017},
  copyright = {\textcopyright 2017 American Institute of Chemical Engineers},
  doi       = {10.1002/btpr.2517},
  keywords  = {antibody expression, cell cycle, HEK293, protein production, small molecule screen, transient transfection},
  language  = {en},
  urldate   = {2019-10-19},
}

@Article{lee_high-throughput_2017,
  author   = {Lee, Seung-Hee and Cunha, Daniel and Piermarocchi, Carlo and Paternostro, Giovanni and Pinkerton, Anthony and Ladriere, Laurence and Marchetti, Piero and Eizirik, Decio L. and Cnop, Miriam and Levine, Fred},
  journal  = {Biochemical Pharmacology},
  title    = {High-throughput screening and bioinformatic analysis to ascertain compounds that prevent saturated fatty acid-induced \beta-cell apoptosis},
  year     = {2017},
  issn     = {0006-2952},
  month    = aug,
  pages    = {140--149},
  volume   = {138},
  doi      = {10.1016/j.bcp.2017.05.007},
  language = {en},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0006295217302575},
  urldate  = {2019-10-19},
}

@Manual{assertr,
  title  = {{assertr: Assertive Programming for R Analysis Pipelines}},
  author = {Tony Fischetti},
  note   = {R package version 2.6},
  year   = {2019},
  url    = {https://CRAN.R-project.org/package=assertr},
}

@Comment{jabref-meta: databaseType:bibtex;}
