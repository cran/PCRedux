@comment{x-kbibtex-encoding=utf-8}

@article{rodiger_highly_2013,
	abstract = {The analysis of different biomolecules is of prime importance for life science research and medical diagnostics. Due to the discovery of new molecules and new emerging bioanalytical problems, there is an ongoing demand for a technology platform that provides a broad range of assays with a user-friendly flexibility and rapid adaptability to new applications. Here we describe a highly versatile microscopy platform, VideoScan, for the rapid and simultaneous analysis of various assay formats based on fluorescence microscopic detection. The technological design is equally suitable for assays in solution, microbead-based assays and cell pattern recognition. The multiplex real-time capability for tracking of changes under dynamic heating conditions makes it a useful tool for PCR applications and nucleic acid hybridization, enabling kinetic data acquisition impossible to obtain by other technologies using endpoint detection. The paper discusses the technological principle of the platform regarding data acquisition and processing. Microbead-based and solution applications for the detection of diverse biomolecules, including antigens, antibodies, peptides, oligonucleotides and amplicons in small reaction volumes, are presented together with a high-content detection of autoimmune antibodies using a HEp-2 cell assay. Its adaptiveness and versatility gives VideoScan a competitive edge over other bioanalytical technologies.},
	author = {Rödiger, Stefan and Schierack, Peter and Böhm, Alexander and Nitschke, Jörg and Berger, Ingo and Frömmel, Ulrike and Schmidt, Carsten and Ruhland, Mirko and Schimke, Ingolf and Roggenbuck, Dirk and Lehmann, Werner and Schröder, Christian},
	doi = {10.1007/10_2011_132},
	issn = {0724-6145},
	journal = {Advances in Biochemical Engineering/Biotechnology},
	keywords = {Microspheres, Polymerase chain reaction, Antibodies, Biological Assay, Computer Systems, Microscopy, Fluorescence, Nucleic Acid Hybridization, Pathology, Molecular},
	language = {eng},
	pages = {35–74},
	pmid = {22437246},
	title = {A highly versatile microscope imaging technology platform for the multiplex real-time detection of biomolecules and autoimmune antibodies},
	volume = {133},
	year = {2013}
}

@article{willitzki_new_2012,
	abstract = {Antibody assessment is an essential part in the serological diagnosis of autoimmune diseases. However, different diagnostic strategies have been proposed for the work up of sera in particular from patients with systemic autoimmune rheumatic disease (SARD). In general, screening for SARD-associated antibodies by indirect immunofluorescence (IIF) is followed by confirmatory testing covering different assay techniques. Due to lacking automation, standardization, modern data management, and human bias in IIF screening, this two-stage approach has recently been challenged by multiplex techniques particularly in laboratories with high workload. However, detection of antinuclear antibodies by IIF is still recommended to be the gold standard method for antibody screening in sera from patients with suspected SARD. To address the limitations of IIF and to meet the demand for cost-efficient autoantibody screening, automated IIF methods employing novel pattern recognition algorithms for image analysis have been introduced recently. In this respect, the AKLIDES technology has been the first commercially available platform for automated interpretation of cell-based IIF testing and provides multiplexing by addressable microbead immunoassays for confirmatory testing. This paper gives an overview of recently published studies demonstrating the advantages of this new technology for SARD serology.},
	author = {Willitzki, Annika and Hiemann, Rico and Peters, Vanessa and Sack, Ulrich and Schierack, Peter and Rödiger, Stefan and Anderer, Ursula and Conrad, Karsten and Bogdanos, Dimitrios P. and Reinhold, Dirk and Roggenbuck, Dirk},
	doi = {10.1155/2012/284740},
	issn = {1740-2530},
	journal = {Clinical \& Developmental Immunology},
	keywords = {Autoantibodies, Autoimmune Diseases, Fluorescent Antibody Technique, Indirect, Humans, Serologic Tests},
	language = {eng},
	pages = {284740},
	pmcid = {PMC3536031},
	pmid = {23316252},
	title = {New platform technology for comprehensive serological diagnostics of autoimmune diseases},
	volume = {2012},
	year = {2012}
}

@article{roediger_rkward_2012,
	abstract = {R is a free open-source implementation of the S statistical computing language and programming environment. The current status of R is a command line driven interface with no advanced cross-platform graphical user interface (GUI), but it includes tools for building such. Over the past years, proprietary and non-proprietary GUI solutions have emerged, based on internal or external tool kits, with different scopes and technological concepts. For example, Rgui.exe and Rgui.app have become the de facto GUI on the Microsoft Windows and Mac OS X platforms, respectively, for most users. In this paper we discuss RKWard which aims to be both a comprehensive GUI and an integrated development environment for R. RKWard is based on the KDE software libraries. Statistical procedures and plots are implemented using an extendable plugin architecture based on ECMAScript (JavaScript), R, and XML. RKWard provides an excellent tool to manage different types of data objects; even allowing for seamless editing of certain types. The objective of RKWard is to provide a portable and extensible R interface for both basic and advanced statistical and graphical analysis, while not compromising on flexibility and modularity of the R programming environment itself.},
	author = {Rödiger, Stefan and Friedrichsmeier, Thomas and Kapat, Prasenjit and Michalke, Meik},
	journal = {Journal of Statistical Software},
	number = {9},
	pages = {1–34},
	shorttitle = {{RKWard}},
	title = {{RKWard}: a comprehensive graphical user interface and integrated development environment for statistical analysis with {R}},
	url = {https://www.jstatsoft.org/article/view/v049i09/v49i09.pdf},
	volume = {49},
	year = {2012}
}

@article{rodiger_quantification_2018,
	abstract = {Background:  DNA double strand breaks (DSBs) are the most severe form of DNA damage in eukaryotic cells treated with ionizing radiation or chemotherapeutic drugs. They can be quantitatively assessed by fluorescence imaging of phosphorylated histone protein H2AX (γH2AX), where the number of γH2AX foci represents the number of DNA DSB. Real-time assessment of DSB could help tailoring cytotoxic therapies to individual patients regarding both response and adverse events. This would require reliable automated quantification technology not yet routinely available. Here we explore this concept in the context of malignant lymphoma.
 Methods:  To investigate the DSB response to cytotoxic treatment  in vitro , peripheral lymphocytes of healthy donors were incubated with bendamustine, an alkylating drug commonly used in lymphoma therapy. To mimic the clinical setting, the drug concentration per number of donor cells was either calculated as a standard dose or based on the body surface area of the individual donor. DNA DSB were quantified by an automatized immunofluorescence γH2AX assay using the AKLIDES NUK ®  system.
 Results:  Across all donors, the mean number of γH2AX foci per cell was 1.29, IQR (1.08) after bendamustine treatment as opposed to 0.04, IQR (0.125) in untreated freshly isolated peripheral blood mononuclear cells (PBMCs). The standardized incubation dosage resulted in a mean of 0.89, IQR (0.51) foci per cell, while individualized dose calculation yielded 1.57, IQR (0.5) foci per cell. The difference in γH2AX foci between the two dosage calculations was significant (P=0.036). In addition, we observed a trend towards a negative correlation between the donors’ body surface area and the number of foci per cell. Between donors, no significant correlation of the number of foci in response to a given dose was observed. Dose titrations on the cells of individual donors demonstrated a significant response (P Conclusions:  The automatic AKLIDES analysis platform can assess γH2AX foci for routine use. The individual γH2AX foci response to  in vitro  bendamustine is dose-dependent and can be monitored timely. Calculating individual  in vitro  dosage from the donor’s body surface area resulted in a broad variation of foci counts between individuals, suggesting that this dosage method does not result in equivalent biological effects among different individuals. Adjusting the dose individually based on biological responses such as DNA DSB could offer a way of personalized medicine with conventional substances, reducing toxicity while increasing therapeutic efficacy.},
	author = {Rödiger, Stefan and Liefold, Marius and Ruhe, Madeleine and Reinwald, Mark and Beck, Eberhard and Deckert, P. Markus},
	journal = {Journal of Laboratory and Precision Medicine},
	language = {en},
	month = may,
	number = {5},
	title = {Quantification of {DNA} double-strand breaks in peripheral blood mononuclear cells from healthy donors exposed to bendamustine by an automated γ{H}2AX assay–an exploratory study},
	url = {http://jlpm.amegroups.com/article/view/4370},
	urldate = {2018-05-30},
	volume = {3},
	year = {2018}
}

@article{reddig_dna_2018,
	abstract = {Precision or personalized medicine is an aspiring but controversially discussed new paradigm in modern medicine. The individual variability of patients and their diverse responses to treatment options casts doubt on “one-fits-all” therapeutic strategies. Thus, biomarker-based stratification of patients into smaller cohorts is recommended. Indeed, the enormous progress in “omics” technologies has greatly supported this medical model which focused on determining disease predisposition, delivering early and targeted prevention, and/or tailoring the right therapy for each patient at the right time. Especially in the field of precision cancer therapy, the growing understanding of tumor heterogeneity and individual treatment responses has enabled the identification of adequate biomarkers. This review focuses on biomarkers for genotoxicity assessment by different methods, their characteristics, technical advances and their potential clinical applications.},
	author = {Reddig, Annika and Rübe, Claudia E. and Rödiger, Stefan and Schierack, Peter and Reinhold, Dirk and Roggenbuck, Dirk},
	journal = {Journal of Laboratory and Precision Medicine},
	language = {en},
	month = apr,
	number = {4},
	title = {{DNA} damage assessment and potential applications in laboratory diagnostics and precision medicine},
	url = {http://jlpm.amegroups.com/article/view/4305},
	urldate = {2018-06-07},
	volume = {3},
	year = {2018}
}

@article{pscl,
	author = {Zeileis, Achim and Kleiber, Christian and Jackman, Simon},
	doi = {10.18637/jss.v027.i08},
	journal = {Journal of Statistical Software},
	language = {en-US},
	number = {8},
	title = {Regression {Models} for {Count} {Data} in {R}},
	url = {http://www.jstatsoft.org/v27/i08/},
	urldate = {2018-07-23},
	volume = {27},
	year = {2008}
}

@manual{DT,
	author = {Xie, Yihui},
	note = {R package version 0.4},
	title = {DT: A Wrapper of the JavaScript Library 'DataTables'},
	url = {https://CRAN.R-project.org/package=DT},
	year = {2018}
}

@book{ggplot2,
	author = {Wickham, Hadley},
	isbn = {978-3-319-24277-4},
	publisher = {Springer-Verlag New York},
	title = {ggplot2: Elegant Graphics for Data Analysis},
	url = {http://ggplot2.org},
	year = {2016}
}

@book{MASS,
	address = {New York},
	author = {Venables, W. N. and Ripley, B. D.},
	edition = {Fourth},
	note = {ISBN 0-387-95457-0},
	publisher = {Springer},
	title = {Modern Applied Statistics with S},
	url = {http://www.stats.ox.ac.uk/pub/MASS4},
	year = {2002}
}

@manual{shiny,
	author = {Chang, Winston and Cheng, Joe and Allaire, JJ and Xie, Yihui and McPherson, Jonathan},
	note = {R package version 1.1.0},
	title = {shiny: Web Application Framework for R},
	url = {https://CRAN.R-project.org/package=shiny},
	year = {2018}
}

@manual{Rrr,
	address = {Vienna, Austria},
	author = {{R Core Team}},
	organization = {R Foundation for Statistical Computing},
	title = {R: A Language and Environment for Statistical Computing},
	url = {https://www.R-project.org/},
	year = {2018}
}

@article{reshape2,
	author = {Wickham, Hadley},
	journal = {Journal of Statistical Software},
	number = {12},
	pages = {1–20},
	title = {Reshaping Data with the {reshape} Package},
	url = {http://www.jstatsoft.org/v21/i12/},
	volume = {21},
	year = {2007}
}

@manual{shinythemes,
	author = {Chang, Winston},
	note = {R package version 1.1.1},
	title = {shinythemes: Themes for Shiny},
	url = {https://CRAN.R-project.org/package=shinythemes},
	year = {2016}
}

@manual{rhandsontable,
	author = {Owen, Jonathan},
	note = {R package version 0.3.6},
	title = {rhandsontable: Interface to the 'Handsontable.js' Library},
	url = {https://CRAN.R-project.org/package=rhandsontable},
	year = {2018}
}

@manual{rmarkdown,
	author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston},
	note = {R package version 1.10},
	title = {rmarkdown: Dynamic Documents for R},
	url = {https://CRAN.R-project.org/package=rmarkdown},
	year = {2018}
}

@misc{gridextra,
	abstract = {Provides a number of user-level functions to work with "grid" graphics, notably to arrange multiple grid-based plots on a page, and draw tables.},
	author = {Auguie, Baptiste and Antonov, Anton},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	month = sep,
	shorttitle = {{gridExtra}},
	title = {{gridExtra}: {Miscellaneous} {Functions} for "{Grid}" {Graphics}},
	url = {https://CRAN.R-project.org/package=gridExtra},
	urldate = {2018-07-23},
	year = {2017}
}

@misc{dplyr,
	abstract = {A fast, consistent tool for working with data frame like objects, both in memory and out of memory.},
	author = {Wickham, Hadley and François, Romain and Henry, Lionel and Müller, Kirill and RStudio},
	copyright = {MIT + file LICENSE},
	keywords = {ModelDeployment},
	month = jun,
	shorttitle = {dplyr},
	title = {dplyr: {A} {Grammar} of {Data} {Manipulation}},
	url = {https://CRAN.R-project.org/package=dplyr},
	urldate = {2018-07-23},
	year = {2018}
}

@article{shrinkbayes,
	abstract = {Complex designs are common in (observational) clinical studies. Sequencing data for such studies are produced more and more often, implying challenges for the analysis, such as excess of zeros, presence of random effects and multi-parameter inference. Moreover, when sample sizes are small, inference is likely to be too liberal when, in a Bayesian setting, applying a non-appropriate prior or to lack power when not carefully borrowing information across features.},
	annote = {Pages 116 in PDF},
	author = {van de Wiel, Mark A. and Neerincx, Maarten and Buffart, Tineke E. and Sie, Daoud and Verheul, Henk MW},
	doi = {10.1186/1471-2105-15-116},
	issn = {1471-2105},
	journal = {BMC Bioinformatics},
	keywords = {Bayesian analysis, Differential expression, Sequencing, Shrinkage},
	month = apr,
	pages = {116},
	shorttitle = {{ShrinkBayes}},
	title = {{ShrinkBayes}: a versatile {R}-package for analysis of count-based sequencing data in complex study designs},
	urldate = {2018-07-19},
	volume = {15},
	year = {2014}
}

@manual{COUNT,
	author = {Hilbe, Joseph M},
	note = {R package version 1.3.4},
	title = {COUNT: Functions, Data and Code for Count Data},
	url = {https://CRAN.R-project.org/package=COUNT},
	year = {2016}
}

@misc{countseppm,
	abstract = {Modeling under- and over-dispersed count data using extended Poisson process models (EPPM).},
	author = {Smith, David M. and Faddy, Malcolm J.},
	copyright = {GPL-2},
	month = apr,
	shorttitle = {{CountsEPPM}},
	title = {{CountsEPPM}: {Mean} and {Variance} {Modeling} of {Count} {Data}},
	url = {https://CRAN.R-project.org/package=CountsEPPM},
	urldate = {2018-07-23},
	year = {2016}
}

@misc{countreg,
	author = {Zeileis, Achim and Kleiber, Christian},
	note = {R package version 0.2-0},
	title = {countreg: {Count} {Data} {Regression}},
	url = {http://r-forge.r-project.org/projects/countreg/},
	year = {2018}
}

%article{morina_generalized_2015,
%	abstract = {The Generalized Hermite distribution (and the Hermite distribution as a particular case) is often used for fitting count data in the presence of overdispersion or multimodality. Despite this, to our knowledge, no standard software packages have implemented specific functions to compute basic probabilities and make simple statistical inference based on these distributions. We present here a set of computational tools that allows the user to face these difficulties by modelling with the Generalized Hermite distribution using the R package hermite. The package can also be used to generate random deviates from a Generalized Hermite distribution and to use basic functions to compute probabilities (density, cumulative density and quantile functions are available), to estimate parameters using the maximum likelihood method and to perform the likelihood ratio test for Poisson assumption against a Generalized Hermite alternative. In order to improve the density and quantile functions performance when the parameters are large, Edgeworth and Cornish-Fisher expansions have been used. Hermite regression is also a useful tool for modeling inflated count data, so its inclusion to a commonly used software like R will make this tool available to a wide range of potential users. Some examples of usage in several fields of application are also given.},
%	author = {Moriña, David and Higueras, Manuel and Puig, Pedro and Oliveira, María},
%	language = {en},
%	pages = {12},
%	title = {Generalized {Hermite} {Distribution} {Modelling} with the {R} {Package} hermite},
%	volume = {7},
%	year = {2015}
%}

@article{liu_r_2014,
	abstract = {It is scientifically and ethically imperative that the results of statistical analysis of biomedical research data be computationally reproducible in the sense that the reported results can be easily recapitulated from the study data. Some statistical analyses are computationally a function of many data files, program files, and other details that are updated or corrected over time. In many applications, it is infeasible to manually maintain an accurate and complete record of all these details about a particular analysis.
PMID: 24886202},
	author = {Liu, Zhifa and Pounds, Stan},
	copyright = {2014 Liu and Pounds; licensee BioMed Central Ltd.},
	doi = {10.1186/1471-2105-15-138},
	issn = {1471-2105},
	journal = {BMC Bioinformatics},
	language = {en},
	month = may,
	number = {1},
	pages = {138},
	pmid = {24886202},
	title = {An {R} package that automatically collects and archives details for reproducible computing},
	url = {http://www.biomedcentral.com/1471-2105/15/138/abstract},
	urldate = {2014-07-01},
	volume = {15},
	year = {2014}
}

@article{rodiger_r_2015,
	author = {Rödiger, Stefan and Burdukiewicz, Michał and Blagodatskikh, Konstantin A. and Schierack, Peter},
	journal = {The R Journal},
	number = {2},
	pages = {127–150},
	title = {R as an {Environment} for the {Reproducible} {Analysis} of {DNA} {Amplification} {Experiments}},
	url = {http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf},
	volume = {7},
	year = {2015}
}

@article{leeper_archiving_2014,
	author = {Leeper, Thomas J.},
	journal = {The R Journal},
	month = jun,
	number = {1},
	pages = {151–158},
	title = {Archiving {Reproducible} {Research} with {R} and {Dataverse}},
	url = {http://journal.r-project.org/archive/2014-1/leeper.pdf},
	volume = {6},
	year = {2014}
}

@article{gentleman_statistical_2007,
	author = {Gentleman, Robert and {Temple Lang}, Duncan},
	doi = {10.1198/106186007X178663},
	issn = {1061-8600, 1537-2715},
	journal = {Journal of Computational and Graphical Statistics},
	language = {en},
	month = mar,
	number = {1},
	pages = {1–23},
	title = {Statistical {Analyses} and {Reproducible} {Research}},
	urldate = {2018-06-18},
	volume = {16},
	year = {2007}
}

@article{thioulouse_online_2010,
	abstract = {This paper presents an example of online reproducible multivariate data analysis. This example is based on a web page providing an online computing facility on a server. HTML forms contain editable R code snippets that can be executed in any web browser thanks to the Rweb software. The example is based on the multivariate analysis of DNA fingerprints of the internal bacterial flora of the poultry red mite Dermanyssus gallinae. Several multivariate data analysis methods from the ade4 package are used to compare the fingerprints of mite pools coming from various poultry farms. All the computations and graphical displays can be redone interactively and further explored online, using only a web browser. Statistical methods are detailed in the duality diagram framework, and a discussion about online reproducibility is initiated.},
	author = {Thioulouse, Jean},
	journal = {The R Journal},
	language = {en},
	number = {1},
	pages = {44–52},
	title = {Online {Reproducible} {Research}: {An} {Application} to {Multivariate} {Analysis} of {Bacterial} {DNA} {Fingerprint} {Data}},
	url = {https://journal.r-project.org/archive/2010/RJ-2010-002/index.html},
	volume = {2},
	year = {2010}
}

@article{lahti_retrieval_2017,
	abstract = {The increasing availability of open statistical data resources is providing novel opportunities for research and citizen science. Efficient algorithmic tools are needed to realize the full potential of the new information resources. We introduce the eurostat R package that provides a collection of custom tools for the Eurostat open data service, including functions to query, download, manipulate, and visualize these data sets in a smooth, automated and reproducible manner. The online documentation provides detailed examples on the analysis of these spatio-temporal data collections. This work provides substantial improvements over the previously available tools, and has been extensively tested by an active user community. The eurostat R package contributes to the growing open source ecosystem dedicated to reproducible research in computational social science and digital humanities.},
	author = {Lahti, Leo and Huovari, Janne and Kainu, Markus and Biecek, Przemysław},
	issn = {2073-4859},
	journal = {The R Journal},
	language = {en},
	number = {1},
	pages = {385–392},
	title = {Retrieval and {Analysis} of {Eurostat} {Open} {Data} with the eurostat {Package}},
	url = {https://journal.r-project.org/archive/2017/RJ-2017-019/index.html},
	urldate = {2018-07-30},
	volume = {9},
	year = {2017}
}

@article{anderson_hosting_2017,
	abstract = {Data-only packages offer a way to provide extended functionality for other R users. However, such packages can be large enough to exceed the package size limit (5 megabytes) for the Comprehensive R Archive Network (CRAN). As an alternative, large data packages can be posted to additional repostiories beyond CRAN itself in a way that allows smaller code packages on CRAN to access and use the data. The drat package facilitates creation and use of such alternative repositories and makes it particularly simple to host them via GitHub. CRAN packages can draw on packages posted to drat repositories through the use of the ‘Additonal\_repositories’ field in the DESCRIPTION file. This paper describes how R users can create a suite of coordinated packages, in which larger data packages are hosted in an alternative repository created with drat, while a smaller code package that interacts with this data is created that can be submitted to CRAN.},
	author = {Anderson, G Brooke and Eddelbuettel, Dirk},
	issn = {2073-4859},
	journal = {The R Journal},
	language = {en},
	number = {1},
	pages = {486–497},
	shorttitle = {Hosting {Data} {Packages} via drat},
	title = {Hosting {Data} {Packages} via drat: {A} {Case} {Study} with {Hurricane} {Exposure} {Data}},
	url = {https://journal.r-project.org/archive/2017/RJ-2017-026/index.html},
	volume = {9},
	year = {2017}
}

@article{Biecek_2017,
	author = {Biecek, Przemyslaw and Kosinski, Marcin},
	doi = {10.18637/jss.v082.i11},
	journal = {Journal of Statistical Software},
	number = {11},
	pages = {1–28},
	title = {{archivist}: An {R} Package for Managing, Recording and Restoring Data Analysis Results},
	volume = {82},
	year = {2017}
}

@article{willitzki_fully_2013,
	abstract = {Analysis of phosphorylated histone protein H2AX (γH2AX) foci is currently the most sensitive method to detect DNA double-strand breaks (DSB). This protein modification has the potential to become an individual biomarker of cellular stress, especially in the diagnosis and monitoring of neoplastic diseases. To make γH2AX foci analysis available as a routine screening method, different software approaches for automated immunofluorescence pattern evaluation have recently been developed. In this study, we used novel pattern recognition algorithms on the AKLIDES® platform to automatically analyze immunofluorescence images of γH2AX foci and compared the results with visual assessments. Dose- and time-dependent γH2AX foci formation was investigated in human peripheral blood mononuclear cells (PBMCs) treated with the chemotherapeutic drug etoposide (ETP). Moreover, the AKLIDES system was used to analyze the impact of different immunomodulatory reagents on γH2AX foci formation in PBMCs. Apart from γH2AX foci counting the use of novel pattern recognition algorithms allowed the measurement of their fluorescence intensity and size, as well as the analysis of overlapping γH2AX foci. The comparison of automated and manual foci quantification showed overall a good correlation. After ETP exposure, a clear dose-dependent increase of γH2AX foci formation was evident using the AKLIDES as well as Western blot analysis. Kinetic experiments on PBMCs incubated with 5 μM ETP demonstrated a peak in γH2AX foci formation after 4 to 8 h, while a removal of ETP resulted in a strong reduction of γH2AX foci after 1 to 4 h. In summary, this study demonstrated that the AKLIDES system can be used as an efficient automatic screening tool for γH2AX foci analysis by providing new evaluation features and facilitating the identification of drugs which induce or modulate DNA damage. © 2013 International Society for Advancement of Cytometry},
	author = {Willitzki, Annika and Lorenz, Sebastian and Hiemann, Rico and Guttek, Karina and Goihl, Alexander and Hartig, Roland and Conrad, Karsten and Feist, Eugen and Sack, Ulrich and Schierack, Peter and Heiserich, Lisa and Eberle, Caroline and Peters, Vanessa and Roggenbuck, Dirk and Reinhold, Dirk},
	doi = {10.1002/cyto.a.22350},
	issn = {1552-4930},
	journal = {Cytometry Part A},
	keywords = {DNA double-strand breaks, Etoposide, γH2AX foci, automated microscopy, image analysis, human PBMCs},
	language = {en},
	month = nov,
	number = {11},
	pages = {1017–1026},
	title = {Fully automated analysis of chemically induced γ{H}2AX foci in human peripheral blood mononuclear cells by indirect immunofluorescence},
	urldate = {2016-10-11},
	volume = {83},
	year = {2013}
}

@article{schneider_open_2019,
	abstract = {DNA double-strand breaks (DSBs) are critical cellular lesions that represent a high risk for genetic instability. DSBs initiate repair mechanisms by recruiting sensor proteins and mediators. DSB biomarkers, like phosphorylated histone 2AX (γH2AX) and p53-binding protein 1 (53BP1), are detectable by immunofluorescence as either foci or distinct patterns in the vicinity of DSBs. The correlation between the number of foci and the number of DSBs makes them a useful tool for quantification of DNA damage in precision medicine, forensics and cancer research. The quantification and characterization of foci ideally uses large cell numbers to achieve statistical validity. This requires software tools that are suitable for the analysis of large complex data sets, even for users with limited experience in digital image processing. This includes, for example, pre-processing, transformation and presentation of the data in a less complex structure for further data analysis. There are numerous software solutions for the analysis of foci. This review gives an overview of open source image processing software packages, including graphical user interfaces (GUIs) such as CellProfiler, Icy and ImageJ/Fiji. Software packages like CellProfiler and Icy enable to gain high-content information about DSB biomarkers. Programming languages, like Python, are discussed briefly.},
	author = {Schneider, Jens and Weiss, Romano and Ruhe, Madeleine and Jung, Tobias and Roggenbuck, Dirk and Stohwasser, Ralf and Schierack, Peter and Rödiger, Stefan},
	doi = {10.21037/jlpm.2019.04.05},
	journal = {Journal of Laboratory and Precision Medicine},
	number = {0},
	pages = {1–27},
	title = {Open source bioimage informatics tools for the analysis of {DNA} damage and associated biomarkers},
	url = {http://jlpm.amegroups.com/article/view/5008},
	volume = {4},
	year = {2019}
}

@article{ruhe_effect_2018,
	abstract = {Chemotherapy and radiation therapy are used in malignant oncological diseases to increase the level of DNA double strand breaks (DSBs) in tumor cells. Unrepaired DSBs may either kill a cell or induce terminal arrest. Those DNA damages can be detected},
	author = {Ruhe, Madeleine and Dammermann, Werner and Lüth, Stefan and Sowa, Mandy and Schierack, Peter and Deckert, P. Markus and Rödiger, Stefan},
	doi = {10.3233/JCB-189006},
	issn = {2352-3689},
	journal = {Journal of Cellular Biotechnology},
	language = {en},
	month = jan,
	note = {00000},
	number = {1-2},
	pages = {67–73},
	title = {Effect of cryopreservation on the formation of {DNA} double strand breaks in human peripheral blood mononuclear cells},
	url = {https://content.iospress.com/articles/journal-of-cellular-biotechnology/jcb189006},
	urldate = {2019-01-18},
	volume = {4},
	year = {2018}
}

@article{narayanamoorthy_accommodating_2013,
	abstract = {This paper proposes a new spatial multivariate count model to jointly analyze the traffic crash-related counts of pedestrians and bicyclists by injury severity. The modeling framework is applied to predict injury counts at a Census tract level, based on crash data from Manhattan, New York. The results highlight the need to use a multivariate modeling system for the analysis of injury counts by road-user type and injury severity level, while also accommodating spatial dependence effects in injury counts.},
	author = {Narayanamoorthy, Sriram and Paleti, Rajesh and Bhat, Chandra R.},
	doi = {10.1016/J.TRB.2013.07.004},
	issn = {0191-2615},
	journal = {Transportation Research Part B: Methodological},
	keywords = {Composite marginal likelihood, Crash analysis, Multivariate count data, Spatial econometrics},
	month = sep,
	note = {00072},
	pages = {245–264},
	title = {On accommodating spatial dependence in bicycle and pedestrian injury counts by severity level},
	url = {http://www.sciencedirect.com/science/article/pii/S0191261513001197},
	urldate = {2019-02-02},
	volume = {55},
	year = {2013}
}

@article{brijs_studying_2008,
	abstract = {In previous research, significant effects of weather conditions on car crashes have been found. However, most studies use monthly or yearly data and only few studies are available analyzing the impact of weather conditions on daily car crash counts. Furthermore, the studies that are available on a daily level do not explicitly model the data in a time-series context, hereby ignoring the temporal serial correlation that may be present in the data. In this paper, we introduce an integer autoregressive model for modelling count data with time interdependencies. The model is applied to daily car crash data, metereological data and traffic exposure data from the Netherlands aiming at examining the risk impact of weather conditions on the observed counts. The results show that several assumptions related to the effect of weather conditions on crash counts are found to be significant in the data and that if serial temporal correlation is not accounted for in the model, this may produce biased results.},
	author = {Brijs, Tom and Karlis, Dimitris and Wets, Geert},
	doi = {10.1016/J.AAP.2008.01.001},
	issn = {0001-4575},
	journal = {Accident; Analysis and Prevention},
	keywords = {Humans, Time Factors, Models, Statistical, Poisson Distribution, Accident Prevention, Accidents, Traffic, Climate, Models, Theoretical, Regression (Psychology), Risk Assessment, Risk Factors, Time and Motion Studies},
	language = {eng},
	month = may,
	note = {00123},
	number = {3},
	pages = {1180–1190},
	pmid = {18460387},
	title = {Studying the effect of weather conditions on daily crash counts using a discrete time-series model},
	volume = {40},
	year = {2008}
}

@article{keene_analysis_2007,
	abstract = {Recurrent events in clinical trials have typically been analysed using either a multiple time-to-event method or a direct approach based on the distribution of the number of events. An area of application for these methods is exacerbation data from respiratory clinical trials. The different approaches to the analysis and the issues involved are illustrated for a large trial (n = 1465) in chronic obstructive pulmonary disease (COPD). For exacerbation rates, clinical interest centres on a direct comparison of rates for each treatment which favours the distribution-based analysis, rather than a time-to-event approach. Poisson regression has often been employed and has recently been recommended as the appropriate method of analysis for COPD exacerbations but the key assumptions often appear unreasonable for this analysis. By contrast use of a negative binomial model which corresponds to assuming a separate Poisson parameter for each subject offers a more appealing approach. Non-parametric methods avoid some of the assumptions required by these models, but do not provide appropriate estimates of treatment effects because of the discrete and bounded nature of the data.},
	author = {Keene, Oliver N. and Jones, Mark R. K. and Lane, Peter W. and Anderson, Julie},
	doi = {10.1002/PST.250},
	issn = {1539-1604},
	journal = {Pharmaceutical Statistics},
	keywords = {Humans, Models, Statistical, Poisson Distribution, Albuterol, Androstadienes, Asthma, Double-Blind Method, Drug Therapy, Combination, Fluticasone, Placebos, Pulmonary Disease, Chronic Obstructive, Salmeterol Xinafoate},
	language = {eng},
	month = jun,
	note = {00077},
	number = {2},
	pages = {89–97},
	pmid = {17230434},
	shorttitle = {Analysis of exacerbation rates in asthma and chronic obstructive pulmonary disease},
	title = {Analysis of exacerbation rates in asthma and chronic obstructive pulmonary disease: example from the {TRISTAN} study},
	volume = {6},
	year = {2007}
}

%jabref-meta: databaseType:bibtex;

@article{boggy_2010,
	author = {Boggy, Gregory J and Woolf, Peter J},
	doi = {10.1371/journal.pone.0012355},
	journal = {PloS One},
	journal-iso = {PLoS ONE},
	number = {8},
	pages = {e12355},
	pmid = {20814578},
	title = {A mechanistic model of {PCR} for accurate quantification of quantitative {PCR} data},
	volume = {5},
	year = {2010}
}

@article{barratt_improving_2002,
	author = {Barratt, Kevin and Mackay, John F.},
	doi = {10.1128/JCM.40.4.1571-1572.2002},
	issn = {0095-1137, 1098-660X},
	journal = {Journal of Clinical Microbiology},
	language = {en},
	month = apr,
	number = {4},
	pages = {1571–1572},
	pmid = {11923402},
	title = {Improving {Real}-{Time} {PCR} {Genotyping} {Assays} by {Asymmetric} {Amplification}},
	url = {http://jcm.asm.org/content/40/4/1571},
	urldate = {2017-08-06},
	volume = {40},
	year = {2002}
}

@article{blagodatskikh_improved_2017,
	abstract = {Whole-genome amplification (WGA) techniques are used for non-specific amplification of low-copy number DNA, and especially for single-cell genome and transcriptome amplification. There are a number of WGA methods that have been developed over the years. One example is degenerate oligonucleotide-primed PCR (DOP-PCR), which is a very simple, fast and inexpensive WGA technique. Although DOP-PCR has been regarded as one of the pioneering methods for WGA, it only provides low genome coverage and a high allele dropout rate when compared to more modern techniques. Here we describe an improved DOP-PCR (iDOP-PCR). We have modified the classic DOP-PCR by using a new thermostable DNA polymerase (SD polymerase) with a strong strand-displacement activity and by adjustments in primers design. We compared iDOP-PCR, classic DOP-PCR and the well-established PicoPlex technique for whole genome amplification of both high- and low-copy number human genomic DNA. The amplified DNA libraries were evaluated by analysis of short tandem repeat genotypes and NGS data. In summary, iDOP-PCR provided a better quality of the amplified DNA libraries compared to the other WGA methods tested, especially when low amounts of genomic DNA were used as an input material.},
	author = {Blagodatskikh, Konstantin A. and Kramarov, Vladimir M. and Barsova, Ekaterina V. and Garkovenko, Alexey V. and Shcherbo, Dmitriy S. and Shelenkov, Andrew A. and Ustinova, Vera V. and Tokarenko, Maria R. and Baker, Simon C. and Kramarova, Tatiana V. and Ignatov, Konstantin B.},
	doi = {10.1371/journal.pone.0184507},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Polymerase chain reaction, Polymerases, Comparative genomics, DNA libraries, DNA polymerase, Genomic libraries, Human genomics, Next-generation sequencing},
	month = sep,
	number = {9},
	pages = {e0184507},
	shorttitle = {Improved {DOP}-{PCR} ({iDOP}-{PCR})},
	title = {Improved {DOP}-{PCR} ({iDOP}-{PCR}): {A} robust and simple {WGA} method for efficient amplification of low copy number genomic {DNA}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184507},
	urldate = {2017-12-10},
	volume = {12},
	year = {2017}
}

@article{martinez_serra_fluorescence_2014,
	author = {Martinez-Serra, Jordi and Robles, Juan and Nicolas, Antoni and Gutierrez, Antonio and Ros, Teresa and Amat, Juan Carlos and Alemany, Regina and Noguera, Aina and Besalduch, Joan and Abello, Aina and Vogler, Oliver},
	doi = {10.2147/JBM.S64976},
	issn = {1179-2736},
	journal = {Journal of Blood Medicine},
	language = {en},
	month = jun,
	pages = {99},
	title = {Fluorescence resonance energy transfer-based real-time polymerase chain reaction method without {DNA} extraction for the genotyping of {F}5, {F}2, {F}12, {MTHFR}, and {HFE}},
	urldate = {2017-09-05},
	year = {2014}
}

@book{mackay_real_time_2007,
	abstract = {Real-time PCR has established itself as a sensitive and specific qualitative and quantitative technique that has become important to all areas of microbiology. This invaluable book describes and explains some of the more complex aspects of real-time PCR presenting a background for the novice, a theoretical reference for the experienced user, and useful discussions of future developments. Chapters address the basics of PCR history, nucleotide design, target preparation, standardisation, quantification, various applications, and future challenges. The final chapter is presented in the format of a roundtable discussion providing an insightful, topical and interesting discourse with contributions from over 30 authorities and experts on real-time PCR. The editor and authors have produced an excellent book that will be extremely useful for all microbiologists. It is a recommended book for all microbiology laboratories.},
	author = {Mackay, Ian Maxwell},
	isbn = {978-1-904455-18-9},
	keywords = {Science / Life Sciences / Microbiology, Science / Research \& Methodology},
	language = {en},
	note = {Google-Books-ID: WKs13RhcEJAC},
	publisher = {Horizon Scientific Press},
	shorttitle = {Real-time {PCR} in {Microbiology}},
	title = {Real-time {PCR} in {Microbiology}: {From} {Diagnosis} to {Characterization}},
	year = {2007}
}

@article{kemperman_mircomp-shiny:_2017,
	author = {Kemperman, Lauren and McCall, Matthew N.},
	file = {miRcomp-Shiny\: Interactive assessment of qPCR-based microRNA quantification and quality control algorithms - F1000Research:/home/tux/Work/Literatur/Zotero_DB/zotero/storage/5TMP29PM/6-2046.html:text/html},
	issn = {2046-1402},
	journal = {F1000Research},
	language = {en},
	month = nov,
	pages = {2046},
	shorttitle = {{miRcomp}-{Shiny}},
	title = {{miRcomp}-{Shiny}: {Interactive} assessment of {qPCR}-based {microRNA} quantification and quality control algorithms},
	url = {https://f1000research.com/articles/6-2046/v1},
	urldate = {2017-12-10},
	volume = {6},
	year = {2017}
}

@book{savidge_tor_microbial_2004,
	abstract = {Recent advances in molecular technology have provided new microbial imaging tools, not only complementing more classical methods, but in many cases significantly enhancing the sensitivity and efficiency in which studies may be conducted. These technologies are applicable to a wide range of problems in contemporary microbiology, including strain selection, understanding microbial structure, function and pathophysiology, as well as in the development of anti-microbial agents and vaccines. This volume emphasizes detailed methodology, provides a theoretical background and lists potential applications of specific imaging tools.* Edited by two experts in the field* Applicable to a broad Microbiology readership* Highly illustrated* Provides in-depth accounts from scientists working with cutting edge technologies* Facilitates researchers who involve Microbial Imaging in their work},
	author = {{Savidge, Tor} and {Pothulakis, Charalabos}},
	isbn = {978-0-08-092504-2},
	keywords = {Science / Life Sciences / Microbiology},
	language = {en},
	month = dec,
	note = {Google-Books-ID: tnQI8mjr9joC},
	publisher = {Academic Press},
	title = {Microbial {Imaging}},
	volume = {34},
	year = {2004}
}

@article{whittle_quadruplex_2008,
	author = {Whittle, Martin R. and Sumita, Denilce R.},
	doi = {10.1016/j.fsigss.2007.08.012},
	issn = {18751768},
	journal = {Forensic Science International: Genetics Supplement Series},
	language = {en},
	month = aug,
	number = {1},
	pages = {86–88},
	title = {Quadruplex real-time {PCR} for forensic {DNA} quantitation},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1875176808002618},
	urldate = {2017-09-11},
	volume = {1},
	year = {2008}
}

@article{roediger2015r,
	author = {Rödiger, Stefan and Burdukiewicz, Michał and Blagodatskikh, Konstantin A. and Schierack, Peter},
	journal = {The R Journal},
	number = {2},
	pages = {127–150},
	title = {R as an {Environment} for the {Reproducible} {Analysis} of {DNA} {Amplification} {Experiments}},
	url = {http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf},
	volume = {7},
	year = {2015}
}

@article{roediger2015chippcr,
	abstract = {Motivation: Both the quantitative real-time polymerase chain reaction (qPCR) and quantitative isothermal amplification (qIA) are standard methods for nucleic acid quantification. Numerous real-time read-out technologies have been developed. Despite the continuous interest in amplification-based techniques, there are only few tools for pre-processing of amplification data. However, a transparent tool for precise control of raw data is indispensable in several scenarios, for example, during the development of new instruments. Results: chipPCR is an R package for the pre-processing and quality analysis of raw data of amplification curves. The package takes advantage of R’s S4 object model and offers an extensible environment. chipPCR contains tools for raw data exploration: normalization, baselining, imputation of missing values, a powerful wrapper for amplification curve smoothing and a function to detect the start and end of an amplification curve. The capabilities of the software are enhanced by the implementation of algorithms unavailable in R, such as a 5-point stencil for derivative interpolation. Simulation tools, statistical tests, plots for data quality management, amplification efficiency/quantification cycle calculation, and datasets from qPCR and qIA experiments are part of the package. Core functionalities are integrated in GUIs (web-based and standalone shiny applications), thus streamlining analysis and report generation. Availability and implementation: http://cran.r-project.org/web/packages/chipPCR. Source code: https://github.com/michbur/chipPCR. Contact: stefan.roediger@b-tu.de Supplementary information: Supplementary data are available at Bioinformatics online.},
	author = {Rödiger, Stefan and Burdukiewicz, Michał and Schierack, Peter},
	doi = {10.1093/bioinformatics/btv205},
	issn = {1367-4803, 1460-2059},
	journal = {Bioinformatics},
	language = {en},
	month = sep,
	number = {17},
	pages = {2900–2902},
	pmid = {25913204},
	shorttitle = {{chipPCR}},
	title = {{chipPCR}: an {R} package to pre-process raw data of amplification curves},
	url = {http://bioinformatics.oxfordjournals.org/content/31/17/2900},
	urldate = {2015-09-08},
	volume = {31},
	year = {2015}
}

@article{roediger_enabling_2017,
	abstract = {Motivation: Reproducibility, a cornerstone of research, requires defined data formats, which include the setup and output of experiments. The real-time PCR data markup language (RDML) is a recommended standard of the minimum information for publication of quantitative real-time PCR experiments guidelines. Despite the popularity of the RDML format for analysis of quantitative PCR data, handling of RDML files is not yet widely supported in all PCR curve analysis softwares.Results: This study describes the open-source RDML package for the statistical computing language R. RDML is compatible with RDML versions ≤ 1.2 and provides functionality to (i) import RDML data; (ii) extract sample information (e.g. targets and concentration); (iii) transform data to various formats of the R environment; (iv) generate human-readable run summaries; and (v) to create RDML files from user data. In addition, RDML offers a graphical user interface to read, edit and create RDML files.Availability and implementation:https://cran.r-project.org/package=RDML. rdmlEdit server http://shtest.evrogen.net/rdmlEdit/. Documentation: http://kablag.github.io/RDML/.Contact:k.blag@yandex.ruSupplementary information:Supplementary data are available at Bioinformatics online.},
	author = {Rödiger, Stefan and Burdukiewicz, Michał and Spiess, Andrej-Nikolai and Blagodatskikh, Konstantin},
	doi = {10.1093/bioinformatics/btx528},
	journal = {Bioinformatics},
	month = aug,
	shorttitle = {Enabling reproducible real-time quantitative {PCR} research},
	title = {Enabling reproducible real-time quantitative {PCR} research: the {RDML} package},
	url = {https://academic.oup.com/bioinformatics/article/doi/10.1093/bioinformatics/btx528/4095640/Enabling-reproducible-real-time-quantitative-PCR},
	urldate = {2017-09-09},
	year = {2017}
}

@article{pabinger_survey_2014,
	abstract = {Real-time quantitative polymerase-chain-reaction (qPCR) is a standard technique in most laboratories used for various applications in basic research. Analysis of qPCR data is a crucial part of the entire experiment, which has led to the development of a plethora of methods. The released tools either cover specific parts of the workflow or provide complete analysis solutions. Here, we surveyed 27 open-access software packages and tools for the analysis of qPCR data. The survey includes 8 Microsoft Windows, 5 web-based, 9 R-based and 5 tools from other platforms. Reviewed packages and tools support the analysis of different qPCR applications, such as RNA quantification, DNA methylation, genotyping, identification of copy number variations, and digital PCR. We report an overview of the functionality, features and specific requirements of the individual software tools, such as data exchange formats, availability of a graphical user interface, included procedures for graphical data presentation, and offered statistical methods. In addition, we provide an overview about quantification strategies, and report various applications of qPCR. Our comprehensive survey showed that most tools use their own file format and only a fraction of the currently existing tools support the standardized data exchange format RDML. To allow a more streamlined and comparable analysis of qPCR data, more vendors and tools need to adapt the standardized format to encourage the exchange of data between instrument software, analysis tools, and researchers.},
	author = {Pabinger, Stephan and Rödiger, Stefan and Kriegner, Albert and Vierlinger, Klemens and Weinhäusel, Andreas},
	doi = {10.1016/j.bdq.2014.08.002},
	issn = {2214-7535},
	journal = {Biomolecular Detection and Quantification},
	keywords = {Data analysis, MIQE, qPCR, RDML, Software, Tools},
	month = sep,
	note = {00003},
	number = {1},
	pages = {23–33},
	title = {A survey of tools for the analysis of quantitative {PCR} ({qPCR}) data},
	url = {http://www.sciencedirect.com/science/article/pii/S2214753514000059},
	urldate = {2015-04-02},
	volume = {1},
	year = {2014}
}

@article{Ritz2008,
	abstract = {Summary: The qpcR library is an add-on to the free R statistical environment performing sigmoidal model selection in real-time quantitative polymerase chain reaction (PCR) data analysis. Additionally, the package implements the most commonly used algorithms for real-time PCR data analysis and is capable of extensive statistical comparison for the selection and evaluation of the different models based on several measures of goodness of fit. Availability: www.dr-spiess.de/qpcR.html. Contact: a.spiess@uke.uni-hamburg.de Supplementary Information: Statistical evaluations of the implemented methods can be found at www.dr-spiess.de under ‘Supplemental Data’.},
	author = {Ritz, Christian and Spiess, Andrej-Nikolai},
	doi = {10.1093/bioinformatics/btn227},
	issn = {1367-4803, 1460-2059},
	journal = {Bioinformatics},
	language = {en},
	month = jul,
	number = {13},
	pages = {1549–1551},
	pmid = {18482995},
	shorttitle = {{qpcR}},
	title = {{qpcR}: an {R} package for sigmoidal model selection in quantitative real-time polymerase chain reaction analysis},
	url = {http://bioinformatics.oxfordjournals.org/content/24/13/1549},
	urldate = {2014-04-07},
	volume = {24},
	year = {2008}
}

@article{isaac_essentials_2009,
	author = {Isaac, Peter G.},
	doi = {10.1093/aob/mcp135},
	issn = {1095-8290, 0305-7364},
	journal = {Annals of Botany},
	language = {en},
	month = aug,
	number = {2},
	pages = {vi–vi},
	shorttitle = {Essentials of nucleic acid analysis},
	title = {Essentials of nucleic acid analysis: a robust approach},
	url = {https://academic.oup.com/aob/article-lookup/doi/10.1093/aob/mcp135},
	urldate = {2017-09-05},
	volume = {104},
	year = {2009}
}

@article{spiess_impact_2015,
	abstract = {BACKGROUND: Quantification cycle (Cq) and amplification efficiency (AE) are parameters mathematically extracted from raw data to characterize quantitative PCR (qPCR) reactions and quantify the copy number in a sample. Little attention has been paid to the effects of preprocessing and the use of smoothing or filtering approaches to compensate for noisy data. Existing algorithms largely are taken for granted, and it is unclear which of the various methods is most informative. We investigated the effect of smoothing and filtering algorithms on amplification curve data. METHODS: We obtained published high-replicate qPCR data sets from standard block thermocyclers and other cycler platforms and statistically evaluated the impact of smoothing on Cq and AE. RESULTS: Our results indicate that selected smoothing algorithms affect estimates of Cq and AE considerably. The commonly used moving average filter performed worst in all qPCR scenarios. The Savitzky–Golay smoother, cubic splines, and Whittaker smoother resulted overall in the least bias in our setting and exhibited low sensitivity to differences in qPCR AE, whereas other smoothers, such as running mean, introduced an AE-dependent bias. CONCLUSIONS: The selection of a smoothing algorithm is an important step in developing data analysis pipelines for real-time PCR experiments. We offer guidelines for selection of an appropriate smoothing algorithm in diagnostic qPCR applications. The findings of our study were implemented in the R packages chipPCR and qpcR as a basis for the implementation of an analytical strategy.},
	author = {Spiess, Andrej-Nikolai and Deutschmann, Claudia and Burdukiewicz, Michał and Himmelreich, Ralf and Klat, Katharina and Schierack, Peter and Rödiger, Stefan},
	doi = {10.1373/clinchem.2014.230656},
	issn = {0009-9147, 1530-8561},
	journal = {Clinical Chemistry},
	language = {en},
	month = feb,
	number = {2},
	pages = {379–388},
	title = {Impact of {Smoothing} on {Parameter} {Estimation} in {Quantitative} {DNA} {Amplification} {Experiments}},
	urldate = {2016-12-03},
	volume = {61},
	year = {2015}
}

@article{ruijter_amplification_2009,
	abstract = {Despite the central role of quantitative PCR (qPCR) in the quantification of mRNA transcripts, most analyses of qPCR data are still delegated to the software that comes with the qPCR apparatus. This is especially true for the handling of the fluorescence baseline. This article shows that baseline estimation errors are directly reflected in the observed PCR efficiency values and are thus propagated exponentially in the estimated starting concentrations as well as 'fold-difference' results. Because of the unknown origin and kinetics of the baseline fluorescence, the fluorescence values monitored in the initial cycles of the PCR reaction cannot be used to estimate a useful baseline value. An algorithm that estimates the baseline by reconstructing the log-linear phase downward from the early plateau phase of the PCR reaction was developed and shown to lead to very reproducible PCR efficiency values. PCR efficiency values were determined per sample by fitting a regression line to a subset of data points in the log-linear phase. The variability, as well as the bias, in qPCR results was significantly reduced when the mean of these PCR efficiencies per amplicon was used in the calculation of an estimate of the starting concentration per sample.},
	author = {Ruijter, J M and Ramakers, C and Hoogaars, W M H and Karlen, Y and Bakker, O and van den Hoff, M J B and Moorman, A F M},
	doi = {10.1093/nar/gkp045},
	issn = {1362-4962},
	journal = {Nucleic acids research},
	keywords = {Algorithms, Animals, Chick Embryo, Fluorescence, Linear Models, Reverse Transcriptase Polymerase Chain Reaction},
	language = {eng},
	month = apr,
	number = {6},
	pages = {e45},
	pmcid = {PMC2665230},
	pmid = {19237396},
	shorttitle = {Amplification efficiency},
	title = {Amplification efficiency: linking baseline and bias in the analysis of quantitative {PCR} data},
	volume = {37},
	year = {2009}
}

@article{lefever_rdml_2009,
	abstract = {The XML-based Real-Time PCR Data Markup Language (RDML) has been developed by the RDML consortium (http://www.rdml.org) to enable straightforward exchange of qPCR data and related information between qPCR instruments and third party data analysis software, between colleagues and collaborators and between experimenters and journals or public repositories. We here also propose data related guidelines as a subset of the Minimum Information for Publication of Quantitative Real-Time PCR Experiments (MIQE) to guarantee inclusion of key data information when reporting experimental results.},
	author = {Lefever, Steve and Hellemans, Jan and Pattyn, Filip and Przybylski, Daniel R. and Taylor, Chris and Geurts, René and Untergasser, Andreas and Vandesompele, Jo and Consortium, on behalf of the RDML},
	doi = {10.1093/nar/gkp056},
	issn = {0305-1048, 1362-4962},
	journal = {Nucleic Acids Research},
	language = {en},
	month = apr,
	note = {00097},
	number = {7},
	pages = {2065–2069},
	pmid = {19223324},
	shorttitle = {{RDML}},
	title = {{RDML}: structured language and reporting guidelines for real-time quantitative {PCR} data},
	url = {http://nar.oxfordjournals.org/content/37/7/2065},
	urldate = {2015-04-01},
	volume = {37},
	year = {2009}
}

@article{ruijter_rdml-ninja_2015,
	abstract = {BackgroundThe universal qPCR data exchange file format RDML is today well accepted by the scientific community, part of the MIQE guidelines and implemented in many qPCR instruments. With the increased use of RDML new challenges emerge. The flexibility of the RDML format resulted in some implementations that did not meet the expectations of the consortium in the level of support or the use of elements.ResultsIn the current RDML version 1.2 the description of the elements was sharpened. The open source editor RDML-Ninja was released (http://sourceforge.net/projects/qpcr-ninja/). RDML-Ninja allows to visualize, edit and validate RDML files and thus clarifies the use of RDML elements. Furthermore RDML-Ninja serves as reference implementation for RDML and enables migration between RDML versions independent of the instrument software. The database RDMLdb will serve as an online repository for RDML files and facilitate the exchange of RDML data (http://www.rdmldb.org). Authors can upload their RDML files and reference them in publications by the unique identifier provided by RDMLdb. The MIQE guidelines propose a rich set of information required to document each qPCR run. RDML provides the vehicle to store and maintain this information and current development aims at further integration of MIQE requirements into the RDML format.ConclusionsThe editor RDML-Ninja and the database RDMLdb enable scientists to evaluate and exchange qPCR data in the instrument-independent RDML format. We are confident that this infrastructure will build the foundation for standardized qPCR data exchange among scientists, research groups, and during publication.},
	author = {Ruijter, Jan M. and Lefever, Steve and Anckaert, Jasper and Hellemans, Jan and Pfaffl, Michael W. and Benes, Vladimir and Bustin, Stephen A. and Vandesompele, Jo and Untergasser, Andreas and Consortium, on behalf of the RDML},
	doi = {10.1186/s12859-015-0637-6},
	issn = {1471-2105},
	journal = {BMC Bioinformatics},
	language = {en},
	month = dec,
	number = {1},
	pages = {197},
	title = {{RDML}-{Ninja} and {RDMLdb} for standardized exchange of {qPCR} data},
	urldate = {2017-09-04},
	volume = {16},
	year = {2015}
}

@article{perkins_readqpcr_2012,
	abstract = {Measuring gene transcription using real-time reverse transcription polymerase chain reaction (RT-qPCR) technology is a mainstay of molecular biology. Technologies now exist to measure the abundance of many transcripts in parallel. The selection of the optimal reference gene for the normalisation of this data is a recurring problem, and several algorithms have been developed in order to solve it. So far nothing in R exists to unite these methods, together with other functions to read in and normalise the data using the chosen reference gene(s). PMID: 22748112},
	author = {Perkins, James R. and Dawes, John M. and McMahon, Steve B. and Bennett, David LH and Orengo, Christine and Kohl, Matthias},
	copyright = {2012 Perkins et al.; licensee BioMed Central Ltd.},
	doi = {10.1186/1471-2164-13-296},
	issn = {1471-2164},
	journal = {BMC Genomics},
	language = {en},
	month = jul,
	number = {1},
	pages = {296},
	pmid = {22748112},
	shorttitle = {{ReadqPCR} and {NormqPCR}},
	title = {{ReadqPCR} and {NormqPCR}: {R} packages for the reading, quality checking and normalisation of {RT}-{qPCR} quantification cycle ({Cq}) data},
	url = {http://www.biomedcentral.com/1471-2164/13/296/abstract},
	urldate = {2014-04-27},
	volume = {13},
	year = {2012}
}

@article{pabinger_qpcr:_2009,
	abstract = {Since its introduction quantitative real-time polymerase chain reaction (qPCR) has become the standard method for quantification of gene expression. Its high sensitivity, large dynamic range, and accuracy led to the development of numerous applications with an increasing number of samples to be analyzed. Data analysis consists of a number of steps, which have to be carried out in several different applications. Currently, no single tool is available which incorporates storage, management, and multiple methods covering the complete analysis pipeline. PMID: 19712446},
	author = {Pabinger, Stephan and Thallinger, Gerhard G. and Snajder, René and Eichhorn, Heiko and Rader, Robert and Trajanoski, Zlatko},
	copyright = {2009 Pabinger et al; licensee BioMed Central Ltd.},
	doi = {10.1186/1471-2105-10-268},
	issn = {1471-2105},
	journal = {BMC Bioinformatics},
	language = {en},
	month = aug,
	number = {1},
	pages = {268},
	pmid = {19712446},
	shorttitle = {{QPCR}},
	title = {{QPCR}: {Application} for real-time {PCR} data management and analysis},
	url = {http://www.biomedcentral.com/1471-2105/10/268/abstract},
	urldate = {2014-07-01},
	volume = {10},
	year = {2009}
}

@article{neve_unifiedwmwqpcr:_2014,
	abstract = {Motivation: Recently, De Neve et al. proposed a modification of the Wilcoxon–Mann–Whitney (WMW) test for assessing differential expression based on RT-qPCR data. Their test, referred to as the unified WMW (uWMW) test, incorporates a robust and intuitive normalization and quantifies the probability that the expression from one treatment group exceeds the expression from another treatment group. However, no software package for this test was available yet. Results: We have developed a Bioconductor package for analyzing RT-qPCR data with the uWMW test. The package also provides graphical tools for visualizing the effect sizes. Availability and implementation: The unifiedWMWqPCR package and its user documentation can be obtained through Bioconductor. Contact: JanR.DeNeve@UGent.be},
	author = {Neve, Jan De and Meys, Joris and Ottoy, Jean-Pierre and Clement, Lieven and Thas, Olivier},
	doi = {10.1093/bioinformatics/btu313},
	issn = {1367-4803, 1460-2059},
	journal = {Bioinformatics},
	language = {en},
	month = sep,
	number = {17},
	pages = {2494–2495},
	pmid = {24794933},
	shorttitle = {{unifiedWMWqPCR}},
	title = {{unifiedWMWqPCR}: the unified {Wilcoxon}–{Mann}–{Whitney} test for analyzing {RT}-{qPCR} data in {R}},
	url = {http://bioinformatics.oxfordjournals.org/content/30/17/2494},
	urldate = {2014-09-21},
	volume = {30},
	year = {2014}
}

@article{feuer_lemming:_2015,
	abstract = {Background Gene expression analysis is an essential part of biological and medical investigations. Quantitative real-time PCR (qPCR) is characterized with excellent sensitivity, dynamic range, reproducibility and is still regarded to be the gold standard for quantifying transcripts abundance. Parallelization of qPCR such as by microfluidic Taqman Fluidigm Biomark Platform enables evaluation of multiple transcripts in samples treated under various conditions. Despite advanced technologies, correct evaluation of the measurements remains challenging. Most widely used methods for evaluating or calculating gene expression data include geNorm and ΔΔ C t , respectively. They rely on one or several stable reference genes (RGs) for normalization, thus potentially causing biased results. We therefore applied multivariable regression with a tailored error model to overcome the necessity of stable RGs. Results We developed a RG independent data normalization approach based on a tailored l inear e rror m odel for parallel qPCR data, called LEMming. It uses the assumption that the mean C t values within samples of similarly treated groups are equal. Performance of LEMming was evaluated in three data sets with different stability patterns of RGs and compared to the results of geNorm normalization. Data set 1 showed that both methods gave similar results if stable RGs are available. Data set 2 included RGs which are stable according to geNorm criteria, but became differentially expressed in normalized data evaluated by a t-test. geNorm -normalized data showed an effect of a shifted mean per gene per condition whereas LEMming-normalized data did not. Comparing the decrease of standard deviation from raw data to geNorm and to LEMming, the latter was superior. In data set 3 according to geNorm calculated average expression stability and pairwise variation, stable RGs were available, but t-tests of raw data contradicted this. Normalization with RGs resulted in distorted data contradicting literature, while LEMming normalized data did not. Conclusions If RGs are coexpressed but are not independent of the experimental conditions the stability criteria based on inter- and intragroup variation fail. The linear error model developed, LEMming, overcomes the dependency of using RGs for parallel qPCR measurements, besides resolving biases of both technical and biological nature in qPCR. However, to distinguish systematic errors per treated group from a global treatment effect an additional measurement is needed. Quantification of total cDNA content per sample helps to identify systematic errors.},
	author = {Feuer, Ronny and Vlaic, Sebastian and Arlt, Janine and Sawodny, Oliver and Dahmen, Uta and Zanger, Ulrich M. and Thomas, Maria},
	doi = {10.1371/journal.pone.0135852},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Complementary DNA, Data processing, Gene Expression, Microfluidics, Polymerase chain reaction, Reverse Transcription, RNA extraction, RNA synthesis},
	month = sep,
	number = {9},
	pages = {e0135852},
	shorttitle = {{LEMming}},
	title = {{LEMming}: {A} {Linear} {Error} {Model} to {Normalize} {Parallel} {Quantitative} {Real}-{Time} {PCR} ({qPCR}) {Data} as an {Alternative} to {Reference} {Gene} {Based} {Methods}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0135852},
	urldate = {2016-06-15},
	volume = {10},
	year = {2015}
}

@article{mccall_non-detects_2014,
	abstract = {Motivation: Quantitative real-time PCR (qPCR) is one of the most widely used methods to measure gene expression. Despite extensive research in qPCR laboratory protocols, normalization and statistical analysis, little attention has been given to qPCR non-detects—those reactions failing to produce a minimum amount of signal., Results: We show that the common methods of handling qPCR non-detects lead to biased inference. Furthermore, we show that non-detects do not represent data missing completely at random and likely represent missing data occurring not at random. We propose a model of the missing data mechanism and develop a method to directly model non-detects as missing data. Finally, we show that our approach results in a sizeable reduction in bias when estimating both absolute and differential gene expression., Availability and implementation: The proposed algorithm is implemented in the R package, nondetects. This package also contains the raw data for the three example datasets used in this manuscript. The package is freely available at http://mnmccall.com/software and as part of the Bioconductor project., Contact: mccallm@gmail.com},
	author = {McCall, Matthew N. and McMurray, Helene R. and Land, Hartmut and Almudevar, Anthony},
	doi = {10.1093/bioinformatics/btu239},
	issn = {1367-4803},
	journal = {Bioinformatics},
	month = aug,
	number = {16},
	pages = {2310–2316},
	pmcid = {PMC4133581},
	pmid = {24764462},
	title = {On non-detects in {qPCR} data},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4133581/},
	urldate = {2016-09-28},
	volume = {30},
	year = {2014}
}

@article{ruijter_removal_2015,
	abstract = {Quantitative PCR (qPCR) is the method of choice in gene expression analysis. However, the number of groups or treatments, target genes and technical replicates quickly exceeds the capacity of a single run on a qPCR machine and the measurements have to be spread over more than 1 plate. Such multi-plate measurements often show similar proportional differences between experimental conditions, but different absolute values, even though the measurements were technically carried out with identical procedures. Removal of this between-plate variation will enhance the power of the statistical analysis on the resulting data. Inclusion and application of calibrator samples, with replicate measurements distributed over the plates, assumes a multiplicative difference between plates. However, random and technical errors in these calibrators will propagate to all samples on the plate. To avoid this effect, the systematic bias between plates can be removed with a correction factor based on all overlapping technical and biological replicates between plates. This approach removes the requirement for all calibrator samples to be measured successfully on every plate. This paper extends an already published factor correction method to the use in multi-plate qPCR experiments. The between-run correction factor is derived from the target quantities which are calculated from the quantification threshold, PCR efficiency and observed Cq value. To enable further statistical analysis in existing qPCR software packages, an efficiency-corrected Cq value is reported, based on the corrected target quantity and a PCR efficiency per target. The latter is calculated as the mean of the PCR efficiencies taking the number of reactions per amplicon per plate into account. Export to the RDML format completes an RDML-supported analysis pipeline of qPCR data ranging from raw fluorescence data, amplification curve analysis and application of reference genes to statistical analysis.},
	author = {Ruijter, Jan M. and {Ruiz Villalba}, Adrián and Hellemans, Jan and Untergasser, Andreas and van den Hoff, Maurice J. B.},
	doi = {10.1016/j.bdq.2015.07.001},
	issn = {2214-7535},
	journal = {Biomolecular Detection and Quantification},
	keywords = {Between-plate correction, Between-run variation, Multi-plate experiment, qPCR, RDML, Software},
	month = sep,
	pages = {10–14},
	series = {Special {Issue}: {Advanced} {Molecular} {Diagnostics} for {Biomarker} {Discovery} – {Part} {I}},
	title = {Removal of between-run variation in a multi-plate {qPCR} experiment},
	url = {http://www.sciencedirect.com/science/article/pii/S2214753515300012},
	urldate = {2016-11-08},
	volume = {5},
	year = {2015}
}

@article{dvinge_htqpcr:_2009,
	abstract = {Motivation: Quantitative real-time polymerase chain reaction (qPCR) is routinely used for RNA expression profiling, validation of microarray hybridization data and clinical diagnostic assays. Although numerous statistical tools are available in the public domain for the analysis of microarray experiments, this is not the case for qPCR. Proprietary software is typically provided by instrument manufacturers, but these solutions are not amenable to the tandem analysis of multiple assays. This is problematic when an experiment involves more than a simple comparison between a control and treatment sample, or when many qPCR datasets are to be analyzed in a high-throughput facility. Results: We have developed HTqPCR, a package for the R statistical computing environment, to enable the processing and analysis of qPCR data across multiple conditions and replicates. Availability: HTqPCR and user documentation can be obtained through Bioconductor or at http://www.ebi.ac.uk/bertone/software. Contact: bertone\{at\}ebi.ac.uk},
	author = {Dvinge, Heidi and Bertone, Paul},
	doi = {10.1093/bioinformatics/btp578},
	issn = {1367-4803, 1460-2059},
	journal = {Bioinformatics},
	language = {en},
	month = dec,
	number = {24},
	pages = {3325–3326},
	pmid = {19808880},
	shorttitle = {{HTqPCR}},
	title = {{HTqPCR}: high-throughput analysis and visualization of quantitative real-time {PCR} data in {R}},
	url = {http://bioinformatics.oxfordjournals.org/content/25/24/3325},
	urldate = {2017-01-03},
	volume = {25},
	year = {2009}
}

@article{ronde_practical_2017,
	abstract = {Since numerous miRNAs have been shown to be present in circulation, these so-called circulating miRNAs have emerged as potential biomarkers for disease. However, results of qPCR studies on circulating miRNA biomarkers vary greatly and many experiments cannot be reproduced. Missing data in qPCR experiments often occur due to off-target amplification, nonanalyzable qPCR curves and discordance between replicates. The low concentration of most miRNAs leads to most, but not all missing data. Therefore, failure to distinguish between missing data due to a low concentration and missing data due to randomly occurring technical errors partly explains the variation within and between otherwise similar studies. Based on qPCR kinetics, an analysis pipeline was developed to distinguish missing data due to technical errors from missing data due to a low concentration of the miRNA-equivalent cDNA in the PCR reaction. Furthermore, this pipeline incorporates a method to statistically decide whether concentrations from replicates are sufficiently concordant, which improves stability of results and avoids unnecessary data loss. By going through the pipeline's steps, the result of each measurement is categorized as “valid, invalid, or undetectable.” Together with a set of imputation rules, the pipeline leads to more robust and reproducible data as was confirmed experimentally. Using two validation approaches, in two cohorts totaling 2214 heart failure patients, we showed that this pipeline increases both the accuracy and precision of qPCR measurements. In conclusion, this statistical data handling pipeline improves the performance of qPCR studies on low-expressed targets such as circulating miRNAs.},
	author = {Ronde, Maurice W. J. de and Ruijter, Jan M. and Lanfear, David and Bayes-Genis, Antoni and Kok, Maayke G. M. and Creemers, Esther E. and Pinto, Yigal M. and Pinto-Sietsma, Sara-Joan},
	doi = {10.1261/rna.059063.116},
	issn = {1355-8382, 1469-9001},
	journal = {RNA},
	keywords = {Data analysis, MicroRNA, qPCR},
	language = {en},
	month = may,
	number = {5},
	pages = {811–821},
	pmid = {28202710},
	title = {Practical data handling pipeline improves performance of {qPCR}-based circulating {miRNA} measurements},
	url = {http://rnajournal.cshlp.org/content/23/5/811},
	urldate = {2017-06-14},
	volume = {23},
	year = {2017}
}

@article{mallona_pcrefficiency:_2011,
	abstract = {Relative calculation of differential gene expression in quantitative PCR reactions requires comparison between amplification experiments that include reference genes and genes under study. Ignoring the differences between their efficiencies may lead to miscalculation of gene expression even with the same starting amount of template. Although there are several tools performing PCR primer design, there is no tool available that predicts PCR efficiency for a given amplicon and primer pair.},
	author = {Mallona, Izaskun and Weiss, Julia and Egea-Cortines, Marcos},
	doi = {10.1186/1471-2105-12-404},
	issn = {1471-2105},
	journal = {BMC Bioinformatics},
	pages = {404},
	shorttitle = {{pcrEfficiency}},
	title = {{pcrEfficiency}: a {Web} tool for {PCR} amplification efficiency prediction},
	urldate = {2016-09-21},
	volume = {12},
	year = {2011}
}

@article{huggett_how_2014,
	author = {Huggett, Jim and O’Grady, Justin and Bustin, Stephen},
	doi = {10.1016/j.bdq.2014.09.001},
	issn = {2214-7535},
	journal = {Biomolecular Detection and Quantification},
	month = sep,
	note = {00000},
	number = {1},
	pages = {A1–A3},
	title = {How to make {Mathematics} {Biology}'s next and better microscope},
	url = {http://www.sciencedirect.com/science/article/pii/S2214753514000060},
	urldate = {2015-02-18},
	volume = {1},
	year = {2014}
}

@article{bustin_reproducibility_2014,
	abstract = {There is increasing concern about the reliability of biomedical research, with recent articles suggesting that up to 85\% of research funding is wasted. This article argues that an important reason for this is the inappropriate use of molecular techniques, particularly in the field of RNA biomarkers, coupled with a tendency to exaggerate the importance of research findings.},
	author = {Bustin, Stephen A.},
	doi = {10.1016/j.bdq.2015.01.002},
	issn = {2214-7535},
	journal = {Biomolecular Detection and Quantification},
	keywords = {Biomedicine, Cancer, Microarrays, Next generation sequencing, qPCR, Reproducibility},
	month = dec,
	pages = {35–42},
	shorttitle = {The reproducibility of biomedical research},
	title = {The reproducibility of biomedical research: {Sleepers} awake!},
	url = {http://www.sciencedirect.com/science/article/pii/S2214753515000030},
	urldate = {2016-10-05},
	volume = {2},
	year = {2014}
}

@article{bustin_continuing_2017,
	abstract = {Attendance at this year’s European Calcified Tissue Society’s (ECTS) Congress reveals that the methods used to obtain qPCR results continue to be significantly flawed and that and their reporting remain inadequate.},
	author = {Bustin, Stephen},
	doi = {10.1016/j.bdq.2017.05.001},
	issn = {2214-7535},
	journal = {Biomolecular Detection and Quantification},
	keywords = {Bone, Expression profiling, qPCR, Reverse Transcription, RNA},
	month = jun,
	pages = {7–9},
	title = {The continuing problem of poor transparency of reporting and use of inappropriate methods for {RT}-{qPCR}},
	url = {http://www.sciencedirect.com/science/article/pii/S2214753517302000},
	urldate = {2017-08-11},
	volume = {12},
	year = {2017}
}

@article{wilson_good_2016,
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = aug,
	title = {Good {Enough} {Practices} in {Scientific} {Computing}},
	url = {https://arxiv.org/abs/1609.00037},
	urldate = {2017-09-19},
	year = {2016}
}

@article{todorov_object-oriented_2009,
	author = {Todorov, Valentin and Filzmoser, Peter},
	issn = {1548-7660},
	journal = {Journal of Statistical Software},
	language = {en},
	number = {3},
	title = {An {Object}-{Oriented} {Framework} for {Robust} {Multivariate} {Analysis}},
	url = {http://www.jstatsoft.org/v32/i03/},
	urldate = {2017-09-21},
	volume = {32},
	year = {2009}
}

@article{mallona_chainy:_nodate,
	author = {Mallona, Izaskun and Díez-Villanueva, Anna and Martín, Berta and Peinado, Miguel A.},
	doi = {10.1093/bioinformatics/btw839},
	journal = {Bioinformatics},
	shorttitle = {Chainy},
	title = {Chainy: an universal tool for standardized relative quantification in real-time {PCR}},
	urldate = {2017-04-23},
	year = {2017}
}

@article{kuhn_building_2008,
	author = {Kuhn, Max},
	issn = {1548-7660},
	journal = {Journal of Statistical Software},
	language = {en},
	number = {5},
	title = {Building {Predictive} {Models} in {R} {Using} the caret {Package}},
	url = {http://www.jstatsoft.org/v28/i05/},
	urldate = {2017-09-30},
	volume = {28},
	year = {2008}
}

@inproceedings{gunay_machine_2016,
	author = {Gunay, Melih and Goceri, Evgin and Balasubramaniyan, Rajarajeswari},
	booktitle = {Machine {Learning} and {Applications} ({ICMLA}), 2016 15th {IEEE} {International} {Conference} on Machine Learning and Applications (ICMLA)},
	doi = {10.1109/ICMLA.2016.0103},
	pages = {588–592},
	publisher = {IEEE},
	title = {Machine {Learning} for {Optimum} {CT}-{Prediction} for {qPCR}},
	url = {http://ieeexplore.ieee.org/abstract/document/7838207/},
	urldate = {2017-10-03},
	year = {2016}
}

@article{sauer_differentiation_2016,
	author = {Sauer, Eva and Reinke, Ann-Kathrin and Courts, Cornelius},
	doi = {10.1016/j.fsigen.2016.01.018},
	issn = {18724973},
	journal = {Forensic Science International: Genetics},
	language = {en},
	month = may,
	pages = {89–99},
	title = {Differentiation of five body fluids from forensic samples by expression analysis of four {microRNAs} using quantitative {PCR}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1872497316300187},
	urldate = {2016-08-16},
	volume = {22},
	year = {2016}
}

@article{martins_dna_2015,
	author = {Martins, C. and Lima, G. and Carvalho, Mr. and Cainé, L. and Porto, Mj.},
	doi = {10.1016/j.fsigss.2015.09.215},
	issn = {18751768},
	journal = {Forensic Science International: Genetics Supplement Series},
	language = {en},
	month = dec,
	pages = {e545–e546},
	title = {{DNA} quantification by real-time {PCR} in different forensic samples},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1875176815301335},
	urldate = {2016-12-22},
	volume = {5},
	year = {2015}
}

@article{baebler_quantgenius:_2017,
	author = {Baebler, Špela and Svalina, Miha and Petek, Marko and Stare, Katja and Rotter, Ana and Pompe-Novak, Maruša and Gruden, Kristina},
	doi = {10.1186/s12859-017-1688-7},
	issn = {1471-2105},
	journal = {BMC Bioinformatics},
	language = {en},
	month = dec,
	number = {1},
	shorttitle = {{quantGenius}},
	title = {{quantGenius}: implementation of a decision support system for {qPCR}-based gene quantification},
	urldate = {2017-09-26},
	volume = {18},
	year = {2017}
}

@article{brenner_variation_1997,
	author = {Brenner, Hermann and Gefeller, Olaf},
	journal = {Statistics in medicine},
	number = {9},
	pages = {981–991},
	title = {Variation of sensitivity, specificity, likelihood ratios and predictive values with disease prevalence},
	url = {http://www.floppybunny.org/robin/web/virtualclassroom/stats/basics/articles/odds_risks/odds_sensitivity)likelihood_ratios_validity_brenner_1997.pdf},
	urldate = {2017-09-30},
	volume = {16},
	year = {1997}
}

@article{erdman_bcp:_2007,
	author = {Erdman, Chandra and Emerson, John W. and {others}},
	journal = {Journal of Statistical Software},
	number = {3},
	pages = {1–13},
	shorttitle = {bcp},
	title = {{bcp}: an {R} package for performing a {Bayesian} analysis of change point problems},
	url = {https://www.jstatsoft.org/article/view/v023i03/v23i03.pdf},
	urldate = {2017-08-13},
	volume = {23},
	year = {2007}
}

@article{Febrero_Bande_2012,
	author = {Febrero-Bande, Manuel and {Oviedo de la Fuente}, Manuel},
	journal = {Journal of Statistical Software},
	number = {4},
	pages = {1–28},
	shorttitle = {Statistical computing in functional data analysis},
	title = {Statistical Computing in Functional Data Analysis: {The} {R} Package {fda.usc}},
	url = {http://www.jstatsoft.org/v51/i04/},
	volume = {51},
	year = {2012}
}

@article{james_ecp:_2013,
	author = {James, Nicholas A. and Matteson, David S.},
	journal = {arXiv preprint arXiv:1309.3295},
	shorttitle = {ecp},
	title = {{ecp}: {An} {R} package for nonparametric multiple change point analysis of multivariate data},
	url = {https://arxiv.org/abs/1309.3295},
	urldate = {2017-06-25},
	year = {2013}
}

@article{roediger_RJ_2013,
	author = {Rödiger, Stefan and Böhm, Alexander and Schimke, Ingolf},
	journal = {The R Journal},
	number = {2},
	pages = {37–53},
	title = {Surface Melting Curve Analysis with {R}},
	url = {http://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf},
	volume = {5},
	year = {2013}
}

@article{rodiger_highly_2013_2,
	abstract = {The analysis of different biomolecules is of prime importance for life science research and medical diagnostics. Due to the discovery of new molecules and new emerging bioanalytical problems, there is an ongoing demand for a technology platform that provides a broad range of assays with a user-friendly flexibility and rapid adaptability to new applications. Here we describe a highly versatile microscopy platform, VideoScan, for the rapid and simultaneous analysis of various assay formats based on fluorescence microscopic detection. The technological design is equally suitable for assays in solution, microbead-based assays and cell pattern recognition. The multiplex real-time capability for tracking of changes under dynamic heating conditions makes it a useful tool for PCR applications and nucleic acid hybridization, enabling kinetic data acquisition impossible to obtain by other technologies using endpoint detection. The paper discusses the technological principle of the platform regarding data acquisition and processing. Microbead-based and solution applications for the detection of diverse biomolecules, including antigens, antibodies, peptides, oligonucleotides and amplicons in small reaction volumes, are presented together with a high-content detection of autoimmune antibodies using a HEp-2 cell assay. Its adaptiveness and versatility gives VideoScan a competitive edge over other bioanalytical technologies.},
	author = {Rödiger, Stefan and Schierack, Peter and Böhm, Alexander and Nitschke, Jörg and Berger, Ingo and Frömmel, Ulrike and Schmidt, Carsten and Ruhland, Mirko and Schimke, Ingolf and Roggenbuck, Dirk and Lehmann, Werner and Schröder, Christian},
	doi = {10.1007/10_2011_132},
	issn = {0724-6145},
	journal = {Advances in Biochemical Engineering/Biotechnology},
	keywords = {Antibodies},
	language = {eng},
	pages = {35–74},
	pmid = {22437246},
	title = {A highly versatile microscope imaging technology platform for the multiplex real-time detection of biomolecules and autoimmune antibodies},
	volume = {133},
	year = {2013}
}

@article{ruijter_evaluation_2013,
	author = {Ruijter, Jan M. and Pfaffl, Michael W. and Zhao, Sheng and Spiess, Andrej N. and Boggy, Gregory and Blom, Jochen and Rutledge, Robert G. and Sisti, Davide and Lievens, Antoon and {De Preter}, Katleen and Derveaux, Stefaan and Hellemans, Jan and Vandesompele, Jo},
	doi = {10.1016/j.ymeth.2012.08.011},
	issn = {10462023},
	journal = {Methods},
	keywords = {Benchmark, Bias, Precision, qPCR curve analysis, Resolution, Transcriptional biomarker},
	language = {en},
	month = jan,
	number = {1},
	pages = {32–46},
	shorttitle = {Evaluation of {qPCR} curve analysis methods for reliable biomarker discovery},
	title = {Evaluation of {qPCR} curve analysis methods for reliable biomarker discovery: {Bias}, resolution, precision, and implications},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1046202312002290},
	urldate = {2016-10-05},
	volume = {59},
	year = {2013}
}

@article{spiess_system-specific_2016,
	author = {Spiess, Andrej-Nikolai and Rödiger, Stefan and Burdukiewicz, Michał and Volksdorf, Thomas and Tellinghuisen, Joel},
	doi = {10.1038/srep38951},
	issn = {2045-2322},
	journal = {Scientific Reports},
	month = dec,
	pages = {38951},
	title = {System-specific periodicity in quantitative real-time polymerase chain reaction data questions threshold-based quantitation},
	url = {http://www.nature.com/articles/srep38951},
	urldate = {2016-12-14},
	volume = {6},
	year = {2016}
}

@manual{R_language,
	address = {Vienna, Austria},
	author = {{R Core Team}},
	organization = {R Foundation for Statistical Computing},
	title = {R: A Language and Environment for Statistical Computing},
	url = {https://www.R-project.org/},
	year = {2017}
}

@article{Tierney2017,
	author = {Tierney, Nicholas},
	journal = {The Journal of Open Source Software},
	month = {aug},
	number = {16},
	publisher = {The Open Journal},
	title = {{visdat}: Visualising Whole Data Frames},
	volume = {2},
	year = {2017}
}

@manual{pracma,
	author = {Borchers, Hans Werner},
	note = {R package version 2.0.7},
	title = {{pracma}: Practical Numerical Math Functions},
	url = {https://CRAN.R-project.org/package=pracma},
	year = {2017}
}

@article{baath_state_2012,
	author = {Bååth, Rasmus},
	journal = {The R Journal},
	month = dec,
	number = {2},
	pages = {74–75},
	title = {The {State} of {Naming} {Conventions} in {R}},
	url = {http://journal.r-project.org/archive/2012-2/RJournal_2012-2_Baaaath.pdf},
	volume = {4},
	year = {2012}
}

@book{james_introduction_2013,
	address = {New York, NY},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	isbn = {978-1-4614-7137-0 978-1-4614-7138-7},
	note = {DOI: 10.1007/978-1-4614-7138-7},
	publisher = {Springer New York},
	series = {Springer {Texts} in {Statistics}},
	title = {An {Introduction} to {Statistical} {Learning}},
	url = {http://link.springer.com/10.1007/978-1-4614-7138-7},
	urldate = {2017-10-12},
	volume = {103},
	year = {2013}
}

@inproceedings{charpiat_shape_2003,
	author = {Charpiat, Guillaume and Faugeras, Olivier and Keriven, Renaud},
	booktitle = {Image {Processing}, 2003. {ICIP} 2003. {Proceedings}. 2003 {International} {Conference} on},
	pages = {II–627},
	publisher = {IEEE},
	title = {Shape metrics, warping and statistics},
	url = {http://ieeexplore.ieee.org/abstract/document/1246758/},
	urldate = {2017-07-30},
	volume = {2},
	year = {2003}
}

@article{porzelius_easier_2009,
	author = {Porzelius, Christine and Knaus, Harald Binder Jochen and Schwarzer, Guido},
	journal = {The R Journal},
	month = jun,
	number = {1},
	pages = {54–59},
	title = {Easier {Parallel} {Computing} in {R} with snowfall and {sfCluster}},
	url = {http://journal.r-project.org/archive/2009-1/RJournal_2009-1_Knaus+et+al.pdf},
	volume = {1},
	year = {2009}
}

@article{schmidberger_2009,
	author = {Schmidberger, Markus and Morgan, Martin and Eddelbuettel, Dirk and Yu, Hao and Tierney, Luke and Mansmann, Ulrich},
	journal = {Journal of Statistical Software},
	number = {1},
	title = {State-of-the-art in {Parallel} {Computing} with {R}},
	volume = {47},
	year = {2009}
}

@article{eddelbuettel_cran_2017,
	author = {Eddelbuettel, Dirk},
	month = sep,
	shorttitle = {{CRAN} {Task} {View}},
	title = {{CRAN} {Task} {View}: {High}-{Performance} and {Parallel} {Computing} with {R}},
	url = {https://CRAN.R-project.org/view=HighPerformanceComputing},
	urldate = {2017-11-03},
	year = {2017}
}

@manual{FFTrees_package,
	author = {Phillips, Nathaniel and Neth, Hansjoerg and Woike, Jan and Gaissmaer, Wolfgang},
	note = {R package version 1.3.5},
	title = {FFTrees: Generate, Visualise, and Evaluate Fast-and-Frugal Decision Trees},
	url = {https://CRAN.R-project.org/package=FFTrees},
	year = {2017}
}

@article{quinlan_induction_1986,
	author = {Quinlan, J. Ross},
	journal = {Machine learning},
	number = {1},
	pages = {81–106},
	title = {Induction of decision trees},
	url = {http://link.springer.com/article/10.1007/BF00116251},
	urldate = {2017-07-25},
	volume = {1},
	year = {1986}
}

@article{luan_signal-detection_2011,
	author = {Luan, Shenghua and Schooler, Lael J. and Gigerenzer, Gerd},
	doi = {10.1037/a0022684},
	issn = {1939-1471, 0033-295X},
	journal = {Psychological Review},
	language = {en},
	number = {2},
	pages = {316–338},
	title = {A signal-detection analysis of fast-and-frugal trees.},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0022684},
	urldate = {2017-11-10},
	volume = {118},
	year = {2011}
}

@article{spiess_highly_2008,
	abstract = {Fitting four-parameter sigmoidal models is one of the methods established in the analysis of quantitative real-time PCR (qPCR) data. We had observed that these models are not optimal in the fitting outcome due to the inherent constraint of symmetry around the point of inflection. Thus, we found it necessary to employ a mathematical algorithm that circumvents this problem and which utilizes an additional parameter for accommodating asymmetrical structures in sigmoidal qPCR data. PMID: 18445269},
	author = {Spiess, Andrej-Nikolai and Feig, Caroline and Ritz, Christian},
	copyright = {2008 Spiess et al; licensee BioMed Central Ltd.},
	doi = {10.1186/1471-2105-9-221},
	issn = {1471-2105},
	journal = {BMC Bioinformatics},
	language = {en},
	month = apr,
	number = {1},
	pages = {221},
	pmid = {18445269},
	title = {Highly accurate sigmoidal fitting of real-time {PCR} data by introducing a parameter for asymmetry},
	url = {http://www.biomedcentral.com/1471-2105/9/221/abstract},
	urldate = {2014-07-01},
	volume = {9},
	year = {2008}
}

@article{bustin_qpcr_2017,
	author = {Bustin, Stephen and Huggett, Jim},
	doi = {10.1016/j.bdq.2017.11.001},
	issn = {22147535},
	journal = {Biomolecular Detection and Quantification},
	language = {en},
	month = dec,
	pages = {19–28},
	title = {{qPCR} primer design revisited},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S221475351730181X},
	urldate = {2017-12-10},
	volume = {14},
	year = {2017}
}

@article{handt_digitale_2015,
	author = {Handt, Gordon and Menschikowski, Mario and Lehmann, Werner and Schierack, Peter and Rödiger, Stefan},
	doi = {10.1007/s12268-015-0610-y},
	file = {465_531_BIOsp_0515_SD_- - 12268-015-0610-y.pdf:/home/tux/Work/Literatur/Zotero_DB/zotero/storage/652JTZ43/12268-015-0610-y.pdf:application/pdf},
	issn = {0947-0867, 1868-6249},
	journal = {BIOspektrum},
	language = {de},
	month = sep,
	number = {5},
	pages = {507–510},
	title = {Digitale {PCR} in der {Labordiagnostik}},
	url = {http://link.springer.com/10.1007/s12268-015-0610-y},
	urldate = {2017-06-18},
	volume = {21},
	year = {2015}
}

@article{rodiger_mikropartikelsysteme_2013,
	abstract = {PCR is a simplistic and robust laboratory technology for nucleic acid detection. However, for research and diagnostics processing multiple targets within one reaction in an automatic fashion is a demanded feature. Combining two multiplex read out technologies, such as microarray and microbeads, the VideoScan platform was designed. This microscope imaging technology enables an automatable high throughput multiplex measurement of genetic material from biological and patient samples.},
	author = {Rödiger, Stefan and Lehmann, Werner and Schröder, Christian and Schierack, Peter},
	doi = {10.1007/s12268-013-0287-z},
	file = {Full Text PDF:/home/tux/Work/Literatur/Zotero_DB/zotero/storage/J4AIZHQT/Rödiger et al. - 2013 - Mikropartikelsysteme für die Nukleinsäurediagnosti.pdf:application/pdf;Snapshot:/home/tux/Work/Literatur/Zotero_DB/zotero/storage/VSX4MFUV/s12268-013-0287-z.html:text/html},
	issn = {0947-0867, 1868-6249},
	journal = {BIOspektrum},
	keywords = {Life Sciences, general, Biochemistry, general, Human Genetics, Microbiology, Developmental Biology, Pharmacology/Toxicology},
	language = {de},
	month = apr,
	note = {00000},
	number = {2},
	pages = {153–156},
	title = {Mikropartikelsysteme für die {Nukleinsäurediagnostik}},
	url = {http://link.springer.com/article/10.1007/s12268-013-0287-z},
	urldate = {2015-06-01},
	volume = {19},
	year = {2013}
}

@article{nolan_2006,
	author = {Nolan, Tania and Hands, Rebecca E. and Bustin, Stephen A.},
	journal = {Nature Protocols},
	month = nov,
	pages = {1559},
	title = {Quantification of {mRNA} using real-time {RT}-{PCR}},
	url = {http://dx.doi.org/10.1038/nprot.2006.236},
	volume = {1},
	year = {2006}
}

@article{spiess_system-specific_2016_2,
	author = {Spiess, A. N. and Rodiger, S. and Burdukiewicz, M. and Volksdorf, T. and Tellinghuisen, J.},
	journal = {Sci Rep},
	month = {Dec},
	pages = {38951},
	title = {{S}ystem-specific periodicity in quantitative real-time polymerase chain reaction data questions threshold-based quantitation},
	volume = {6},
	year = {2016}
}

@article{Tichopad_2003,
	author = {Tichopad, A. and Dilger, M. and Schwarz, G. and Pfaffl, M. W.},
	journal = {Nucleic Acids Res.},
	month = {Oct},
	number = {20},
	pages = {e122},
	title = {{S}tandardized determination of real-time {P}{C}{R} efficiency from a single reaction set-up},
	volume = {31},
	year = {2003}
}

@article{Zhao_2005,
	author = {Zhao, S. and Fernald, R. D.},
	journal = {J. Comput. Biol.},
	month = {Oct},
	number = {8},
	pages = {1047–1064},
	title = {{C}omprehensive algorithm for quantitative real-time polymerase chain reaction},
	volume = {12},
	year = {2005}
}

@article{Ramakers_2003,
	author = {Ramakers, C. and Ruijter, J. M. and Deprez, R. H. and Moorman, A. F.},
	journal = {Neurosci. Lett.},
	month = {Mar},
	number = {1},
	pages = {62–66},
	title = {{A}ssumption-free analysis of quantitative real-time polymerase chain reaction ({P}{C}{R}) data},
	volume = {339},
	year = {2003}
}

